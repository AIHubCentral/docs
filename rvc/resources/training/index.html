<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-36D5RK6Y12"></script>
    <script data-cfasync="false">window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('config', 'G-36D5RK6Y12');</script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="turbo-cache-control" content="no-cache" data-turbo-track="reload" data-track-token="3.9.0.802213793238">

    <!-- See retype.com -->
    <meta name="generator" content="Retype 3.9.0">

    <!-- Primary Meta Tags -->
    <title>Training</title>
    <meta name="title" content="Training">
    <meta name="description" content="Last update: May 5, 2025">

    <!-- Canonical -->
    <link rel="canonical" href="https://docs.aihub.gg/rvc/resources/training/">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://docs.aihub.gg/rvc/resources/training/">
    <meta property="og:title" content="Training">
    <meta property="og:description" content="Last update: May 5, 2025">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://docs.aihub.gg/rvc/resources/training/">
    <meta property="twitter:title" content="Training">
    <meta property="twitter:description" content="Last update: May 5, 2025">

    <script data-cfasync="false">(function(){var cl=document.documentElement.classList,ls=localStorage.getItem("retype_scheme"),hd=cl.contains("dark"),hl=cl.contains("light"),wm=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches;if(ls==="dark"||(!ls&&wm&&!hd&&!hl)){cl.remove("light");cl.add("dark")}else if(ls==="light"||(!ls&&!wm&&!hd&&!hl)){cl.remove("dark");cl.add("light")}})();</script>

    <link href="../../../img/b.png" rel="icon">
    <link href="../../../resources/css/retype.css?v=3.9.0.802213793238" rel="stylesheet">

    <script data-cfasync="false" src="../../../resources/js/config.js?v=3.9.0.802213793238" data-turbo-eval="false" defer></script>
    <script data-cfasync="false" src="../../../resources/js/retype.js?v=3.9.0" data-turbo-eval="false" defer></script>
    <script id="lunr-js" data-cfasync="false" src="../../../resources/js/lunr.js?v=3.9.0.802213793238" data-turbo-eval="false" defer></script>
</head>
<body>
    <div id="docs-app" class="relative text-base antialiased text-gray-700 bg-white font-body dark:bg-dark-850 dark:text-dark-300">
        <div class="absolute bottom-0 left-0 bg-gray-100 dark:bg-dark-800" style="top: 5rem; right: 50%"></div>
    
        <header id="docs-site-header" class="sticky top-0 z-30 flex w-full h-16 bg-white border-b border-gray-200 md:h-20 dark:bg-dark-850 dark:border-dark-650">
            <div class="container relative flex items-center justify-between pr-6 grow md:justify-start">
                <!-- Mobile menu button skeleton -->
                <button v-cloak class="skeleton docs-mobile-menu-button flex items-center justify-center shrink-0 overflow-hidden dark:text-white focus:outline-none rounded-full w-10 h-10 ml-3.5 md:hidden"><svg xmlns="http://www.w3.org/2000/svg" class="mb-px shrink-0" width="24" height="24" viewBox="0 0 24 24" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor"><path d="M2 4h20v2H2zM2 11h20v2H2zM2 18h20v2H2z"></path></g></svg></button>
                <div v-cloak id="docs-sidebar-toggle"></div>
        
                <!-- Logo -->
                <div class="flex items-center justify-between h-full py-2 md:w-75">
                    <div class="flex items-center px-2 md:px-6">
                        <a id="docs-site-logo" href="../../../" class="flex items-center leading-snug text-2xl">
                            <span class="grow-0 shrink-0 overflow-hidden">
                                <img class="max-h-10 dark:hidden md:inline-block" src="../../../img/a.png">
                                <img class="max-h-10 hidden dark:inline-block" src="../../../img/a.png">
                            </span>
                        </a>
                    </div>
        
                    <span class="hidden h-8 border-r md:inline-block dark:border-dark-650"></span>
                </div>
        
                <div class="flex justify-between md:grow">
                    <!-- Top Nav -->
                    <nav class="hidden md:flex">
                        <ul class="flex flex-col mb-4 md:pl-16 md:mb-0 md:flex-row md:items-center">
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://discord.gg/aihub">
                                    <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                                        <g fill="currentColor">
                                            <path d="M10.97 8.265a1.45 1.45 0 0 0-.487.57.75.75 0 0 1-1.341-.67c.2-.402.513-.826.997-1.148C10.627 6.69 11.244 6.5 12 6.5c.658 0 1.369.195 1.934.619a2.45 2.45 0 0 1 1.004 2.006c0 1.033-.513 1.72-1.027 2.215-.19.183-.399.358-.579.508l-.147.123a4.329 4.329 0 0 0-.435.409v1.37a.75.75 0 1 1-1.5 0v-1.473c0-.237.067-.504.247-.736.22-.28.486-.517.718-.714l.183-.153.001-.001c.172-.143.324-.27.47-.412.368-.355.569-.676.569-1.136a.953.953 0 0 0-.404-.806C12.766 8.118 12.384 8 12 8c-.494 0-.814.121-1.03.265ZM13 17a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"/><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1ZM2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5 9.5 9.5 0 0 0 2.5 12Z"/>
                                        </g>
                                    </svg>
                                    <span>Need Help?</span>
                                </a>
                            </li>
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://docs.aihub.gg/#contributions">
                                    <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                                        <g fill="currentColor">
                                            <path d="M12 7a.75.75 0 0 1 .75.75v4.5a.75.75 0 0 1-1.5 0v-4.5A.75.75 0 0 1 12 7Zm0 10a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z"/><path d="M7.328 1.47a.749.749 0 0 1 .53-.22h8.284c.199 0 .389.079.53.22l5.858 5.858c.141.14.22.33.22.53v8.284a.749.749 0 0 1-.22.53l-5.858 5.858a.749.749 0 0 1-.53.22H7.858a.749.749 0 0 1-.53-.22L1.47 16.672a.749.749 0 0 1-.22-.53V7.858c0-.199.079-.389.22-.53Zm.84 1.28L2.75 8.169v7.662l5.419 5.419h7.662l5.419-5.418V8.168L15.832 2.75Z"/>
                                        </g>
                                    </svg>
                                    <span>Report Issues</span>
                                </a>
                            </li>
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://github.com/AIHubCentral/docs">
                                    <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                                        <g fill="currentColor">
                                            <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"/>
                                        </g>
                                    </svg>
                                    <span>GitHub</span>
                                </a>
                            </li>
        
                        </ul>
                    </nav>
        
                    <!-- Header Right Skeleton -->
                    <div v-cloak class="flex justify-end grow skeleton">
        
                        <!-- Search input mock -->
                        <div class="relative hidden w-40 lg:block lg:max-w-sm lg:ml-auto">
                            <div class="absolute flex items-center justify-center h-full pl-3 dark:text-dark-300">
                                <svg xmlns="http://www.w3.org/2000/svg" class="icon-base" width="16" height="16" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 1px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                            </div>
                            <input class="w-full h-10 placeholder-gray-400 transition-colors duration-200 ease-in bg-gray-200 border border-transparent rounded md:text-sm hover:bg-white hover:border-gray-300 focus:outline-none focus:bg-white focus:border-gray-500 dark:bg-dark-600 dark:border-dark-600 dark:placeholder-dark-400" style="padding: 0.625rem 0.75rem 0.625rem 2rem" type="text" placeholder="Search">
                        </div>
        
                        <!-- Mobile search button -->
                        <div class="flex items-center justify-center w-10 h-10 lg:hidden">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="20" height="20" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                        </div>
        
                        <!-- Dark mode switch placeholder -->
                        <div class="w-10 h-10 lg:ml-2"></div>
        
                        <!-- History button -->
                        <div class="flex items-center justify-center w-10 h-10" style="margin-right: -0.625rem;">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="22" height="22" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><g ><path d="M12.01 6.01c-.55 0-1 .45-1 1V12a1 1 0 00.4.8l3 2.22a.985.985 0 001.39-.2.996.996 0 00-.21-1.4l-2.6-1.92V7.01c.02-.55-.43-1-.98-1z"></path><path d="M12.01 1.91c-5.33 0-9.69 4.16-10.05 9.4l-.29-.26a.997.997 0 10-1.34 1.48l1.97 1.79c.19.17.43.26.67.26s.48-.09.67-.26l1.97-1.79a.997.997 0 10-1.34-1.48l-.31.28c.34-4.14 3.82-7.41 8.05-7.41 4.46 0 8.08 3.63 8.08 8.09s-3.63 8.08-8.08 8.08c-2.18 0-4.22-.85-5.75-2.4a.996.996 0 10-1.42 1.4 10.02 10.02 0 007.17 2.99c5.56 0 10.08-4.52 10.08-10.08.01-5.56-4.52-10.09-10.08-10.09z"></path></g></g></svg>
                        </div>
                    </div>
        
                    <div v-cloak class="flex justify-end grow">
                        <div id="docs-mobile-search-button"></div>
                        <doc-search-desktop></doc-search-desktop>
        
                        <doc-theme-switch class="lg:ml-2"></doc-theme-switch>
                        <doc-history></doc-history>
                    </div>
                </div>
            </div>
        </header>
    
        <div class="container relative flex bg-white">
            <!-- Sidebar Skeleton -->
            <div v-cloak class="fixed flex flex-col shrink-0 duration-300 ease-in-out bg-white border-gray-200 sidebar top-20 w-75 border-r h-screen md:sticky transition-transform skeleton dark:bg-dark-800 dark:border-dark-650">
            
                <div class="flex items-center h-16 px-6">
                    <input class="w-full h-8 px-3 py-2 transition-colors duration-200 ease-linear bg-white border border-gray-200 rounded shadow-none text-sm focus:outline-none focus:border-gray-600 dark:bg-dark-600 dark:border-dark-600" type="text" placeholder="Filter">
                </div>
            
                <div class="pl-6 mt-1 mb-4">
                    <div class="w-32 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-48 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-40 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-32 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-48 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-40 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                </div>
            
                <div class="shrink-0 mt-auto bg-transparent dark:border-dark-650">
                    <a class="flex items-center justify-center flex-nowrap h-16 text-gray-400 dark:text-dark-400 hover:text-gray-700 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                        <span class="text-xs whitespace-nowrap">Powered by</span>
                        <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                    </a>
                </div>
            </div>
            
            <!-- Sidebar component -->
            <doc-sidebar v-cloak>
                <template #sidebar-footer>
                    <div class="shrink-0 mt-auto border-t md:bg-transparent md:border-none dark:border-dark-650">
            
                        <div class="py-3 px-6 md:hidden border-b dark:border-dark-650">
                            <nav>
                                <ul class="flex flex-wrap justify-center items-center">
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://discord.gg/aihub">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                                                <g fill="currentColor">
                                                    <path d="M10.97 8.265a1.45 1.45 0 0 0-.487.57.75.75 0 0 1-1.341-.67c.2-.402.513-.826.997-1.148C10.627 6.69 11.244 6.5 12 6.5c.658 0 1.369.195 1.934.619a2.45 2.45 0 0 1 1.004 2.006c0 1.033-.513 1.72-1.027 2.215-.19.183-.399.358-.579.508l-.147.123a4.329 4.329 0 0 0-.435.409v1.37a.75.75 0 1 1-1.5 0v-1.473c0-.237.067-.504.247-.736.22-.28.486-.517.718-.714l.183-.153.001-.001c.172-.143.324-.27.47-.412.368-.355.569-.676.569-1.136a.953.953 0 0 0-.404-.806C12.766 8.118 12.384 8 12 8c-.494 0-.814.121-1.03.265ZM13 17a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"/><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1ZM2.5 12a9.5 9.5 0 0 0 9.5 9.5 9.5 9.5 0 0 0 9.5-9.5A9.5 9.5 0 0 0 12 2.5 9.5 9.5 0 0 0 2.5 12Z"/>
                                                </g>
                                            </svg>
                                            <span>Need Help?</span>
                                        </a>
                                    </li>
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://docs.aihub.gg/#contributions">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                                                <g fill="currentColor">
                                                    <path d="M12 7a.75.75 0 0 1 .75.75v4.5a.75.75 0 0 1-1.5 0v-4.5A.75.75 0 0 1 12 7Zm0 10a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z"/><path d="M7.328 1.47a.749.749 0 0 1 .53-.22h8.284c.199 0 .389.079.53.22l5.858 5.858c.141.14.22.33.22.53v8.284a.749.749 0 0 1-.22.53l-5.858 5.858a.749.749 0 0 1-.53.22H7.858a.749.749 0 0 1-.53-.22L1.47 16.672a.749.749 0 0 1-.22-.53V7.858c0-.199.079-.389.22-.53Zm.84 1.28L2.75 8.169v7.662l5.419 5.419h7.662l5.419-5.418V8.168L15.832 2.75Z"/>
                                                </g>
                                            </svg>
                                            <span>Report Issues</span>
                                        </a>
                                    </li>
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://github.com/AIHubCentral/docs">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                                                <g fill="currentColor">
                                                    <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"/>
                                                </g>
                                            </svg>
                                            <span>GitHub</span>
                                        </a>
                                    </li>
            
                                </ul>
                            </nav>
                        </div>
            
                        <a class="flex items-center justify-center flex-nowrap h-16 text-gray-400 dark:text-dark-400 hover:text-gray-700 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                            <span class="text-xs whitespace-nowrap">Powered by</span>
                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                        </a>
                    </div>
                </template>
            </doc-sidebar>
    
            <div class="grow min-w-0 dark:bg-dark-850">
                <!-- Render "toolbar" template here on api pages --><!-- Render page content -->
                <div class="flex">
                    <div class="min-w-0 p-4 grow md:px-16">
                        <main class="relative pb-12 lg:pt-2">
                            <div class="docs-markdown" id="docs-content">
                                <!-- Rendered if sidebar right is enabled -->
                                <div id="docs-sidebar-right-toggle"></div>
                                <!-- Page content  -->
<doc-anchor-target id="training" class="break-words">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#training">#</doc-anchor-trigger>
        <span>Training</span>
    </h1>
</doc-anchor-target>
<p><code v-pre>Last update: May 5, 2025</code></p>
<hr>
<div class="content-center"><doc-anchor-target id="introduction">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#introduction">#</doc-anchor-trigger>
        <span>Introduction</span>
    </h2>
</doc-anchor-target>
</div>
<ul>
<li><p>In this guide it will be explained how to <strong>properly</strong> train a model from start to finish.</p>
</li>
<li><p><strong>Properly</strong> training a model is just as important as having a great dataset.</p>
</li>
<li><p>It won&#x27;t be explained how to prosess a dataset and how to acutally train a model since that is difference from fork to fork, please look at the guide for your fork to find this info.</p>
</li>
</ul>
<hr>
<div class="content-center"><doc-anchor-target id="epochs--overtraining">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#epochs--overtraining">#</doc-anchor-trigger>
        <span>Epochs &amp; Overtraining</span>
    </h2>
</doc-anchor-target>
</div>
<ul>
<li><p>&quot;Epoch&quot; is a unit of measuring the training cycles of an AI model.</p>
</li>
<li><p>In other words, the amount of times the model went over its <u><a href="https://docs.aihub.gg/rvc/resources/datasets/">dataset</a></u> and learned from it.</p>
</li>
</ul>
<doc-anchor-target id="how-many-epochs-should-i-use-for-my-dataset">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#how-many-epochs-should-i-use-for-my-dataset">#</doc-anchor-trigger>
        <span><em><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"/></g></g></svg> How many epochs should I use for my dataset?</em></span>
    </h4>
</doc-anchor-target>
<ul>
<li><p><strong>There isn&#x27;t a way to know the right amount previous to training.</strong> It depends on the length, quality and diversity of the dataset.</p>
</li>
<li><p>If you aim towards a quality model, it&#x27;s not convenient to input a semi-arbitrary amount of epochs, as it makes it prone to underfitting/overtraining. (explained later)</p>
</li>
<li><p>So it&#x27;s best to use TensorBoard. With it you can determine <strong>exactly</strong> for how long you should train. (explained later)</p>
</li>
</ul>
<doc-anchor-target id="do-more-epochs-equal-a-better-model">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#do-more-epochs-equal-a-better-model">#</doc-anchor-trigger>
        <span><em><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"/></g></g></svg> Do more epochs equal a better model?</em></span>
    </h4>
</doc-anchor-target>
<ul>
<li><p><strong>No it doesn&#x27;t</strong>, since using a disproportionate amount will overtrain the model, which will affect the quality of it.</p>
</li>
<li><p>In the field of AI, is when an AI model learns its <u><a href="https://docs.aihub.gg/rvc/resources/datasets/">dataset</a></u> too well, to the point where it centers too much around it &amp; starts replicating undesired data.</p>
</li>
<li><p>The model performs very well with data of the dataset, but poorly with new data, as it has lost its ability to replicate anything that deviates from it.</p>
</li>
<li><p>It happens when the model is trained for <strong>too long</strong>/is too complex. So to avoid this, RVC users use a tool called <em><strong>TensorBoard</strong></em>.</p>
</li>
</ul>
<doc-anchor-target id="what-is-overtraining">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#what-is-overtraining">#</doc-anchor-trigger>
        <span><em><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"/></g></g></svg> What is overtraining?</em></span>
    </h4>
</doc-anchor-target>
<ul>
<li><p>Overtraining also know as overfitting is where the model doesn&#x27;t actually learn the underlying patterns of the data and memorizes them instead.</p>
</li>
<li><p>Some signs of overfitting are when the sibilances are robotic, when the graphs in the <u><a href="https://docs.aihub.gg/rvc/resources/training/#tensorboard">Tensorboard</a></u> are going up or when the model is unable to produce high end harmonics because it&#x27;s learning your dataset to well and your dataset doesn&#x27;t have these high end harmonics.</p>
</li>
</ul>
<p><img src="../tensorboard-img/overtrained.png" alt="image" width="1000" height="700">‎</p>
<p>This image is a bit extreme but it gives you a good idea. If you notice your model is poorly creating high end harmonics try using a model several epochs back.</p>
<hr>
<div class="content-center"><doc-anchor-target id="batch-size">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#batch-size">#</doc-anchor-trigger>
        <span>Batch Size</span>
    </h2>
</doc-anchor-target>
</div>
<p>A batch size is the number of training examples used in one iteration before updaing the model&#x27;s parameters. For 30+ minutes of data batch size 8 is recommended and for less than 30 minutes batch size 4 is recommended.</p>
<ul>
<li>Smaller batch size:
<ul>
<li>Promotes noisier, less stable gradients.</li>
<li>More suitable when your dataset is small, less diverse or repetitive.</li>
<li>Can lead to instability / divergence or noisy graphs.</li>
<li>Generalization might be improved.
‎</li>
</ul>
</li>
<li>Bigger batch size:
<ul>
<li>Promotes smoother, more stable gradients.</li>
<li>Can beneficial in cases where your dataset is big and diverse.</li>
<li>Can lead to early overtraining or flat / &#x27;stuck&#x27; graphs.</li>
<li>Generalization might be worsened.</li>
</ul>
</li>
</ul>
<hr>
<div class="content-center"><doc-anchor-target id="pretrains">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#pretrains">#</doc-anchor-trigger>
        <span>Pretrains</span>
    </h2>
</doc-anchor-target>
</div>
<p>Pretrains are an integral part of making a model, they are basically models that have been trained with many different types of voices, genders, ages, languages, manor of speech and are much longer then normal models. The objective of pretrains is to reduce training time and increase the quality of your model. To make a model without a pretrain you would need several hours of data to make anything decent.</p>
 <img src="../pretrain-img/pretrain.png" alt="image" width="1000" height="auto">
<ul>
<li>There are three types of pretrains:
<ul>
<li>Scratch: Trained with no previous pretrain.</li>
<li>Finetune: Trained with a pretrain.</li>
<li>Merge: Made by merging pretrains. (These are considered the worst)</li>
</ul>
</li>
</ul>
<hr>
<doc-anchor-target id="section">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section">#</doc-anchor-trigger>
        <span>‎</span>
    </h6>
</doc-anchor-target>
<doc-anchor-target id="how-do-i-use-pretrains">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#how-do-i-use-pretrains">#</doc-anchor-trigger>
        <span>How do i use Pretrains?</span>
    </h3>
</doc-anchor-target>
<p><span class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-green-700 bg-green-100 h-8 px-4 text-base rounded-md">
    <span>Applio</span>
</span></p>
<ul>
<li>Go into the training tab and check the &#x27;Custom Pretrained&#x27; box and use the drop down to select the pretrain&#x27;s D and G file.
<ul>
<li>If you dont see a pretrain in the dropdown that means you need to download a pretrain, go into the &#x27;Downloads&#x27; tab then go to &#x27;Download Pretrained Models&#x27; then use the dropdown to select your sample rate and what pretrain you would like to download, then finally click download.</li>
<li>If you want to upload pretrains manually go into your Applio folder then go to <code v-pre>rvc\models\pretraineds\pretraineds_custom</code> and place your D and G files there.</li>
</ul>
</li>
</ul>
<p><span class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-blue-600 bg-blue-100 h-8 px-4 text-base rounded-md">
    <span>Mainline</span>
</span></p>
<ul>
<li>Asssuming you have the pretrain you want to use go into your mainline folder then go to <code v-pre>assets\pretrained_v2</code> and place you D and G files there.</li>
<li>Then in the &#x27;Train&#x27; tab near the train button you can input the location of your pretrain, replace the ending so it&#x27;s the name of the pretrain you put in <code v-pre>pretrained_v2</code>.</li>
</ul>
<img src="../pretrain-img/pretrain-mainline.png" alt="image" width="200" height="auto">
<hr>
<doc-anchor-target id="section-1">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section-1">#</doc-anchor-trigger>
        <span>‎</span>
    </h6>
</doc-anchor-target>
<doc-anchor-target id="where-do-i-find-pretrains">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#where-do-i-find-pretrains">#</doc-anchor-trigger>
        <span>Where do i find Pretrains?</span>
    </h3>
</doc-anchor-target>
<p>You can find all of the community made pretrains in the &quot;pretrain-models&quot; channel in <u><a href="https://discord.gg/aihub">AI HUB</a></u>.</p>
<p>Here is a list of all publicly available pretrains:</p>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>DMR V1 by Razer</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>This is a fine-tuned based on the original RVC V2 pretrained and made with a 11.3 hour dataset aimed towards e-girl, soft male/female and deep male/female voices. This model was trained with Mangio-Crepe/Crepe (Applio) therefore it is advisable to use this extraction algorithm with a 128 hop length or below and have a clean dataset due to the sensitivity to noise of this algorithm.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/Razer112/DMR_Pretrain/resolve/main/D_DMR-V1.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/Razer112/DMR_Pretrain/resolve/main/G_DMR-V1.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>DMR V2 by Razer</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>This is a fine-tuned based on the original RVC V2 pretrained and made with 22 hours of dataset aimed towards e-girl, soft male/female and deep male/female voices.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/Razer112/DMR_Pretrain/resolve/main/D_DMR-V2.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/Razer112/DMR_Pretrain/resolve/main/G_DMR-V2.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>GuideVocalPretrain by Essid</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>GuideVocalPretrain is a fine-tuned pretrain based on the original pretrain. This contains 58 hours of Korean speech with the goal being to improve Korean speech.</p>
<ul>
<li><strong>48k Download:</strong>
<ul>
<li><u> <a href="https://huggingface.co/Essid/GuideVocalPretrain/resolve/main/D_GuideVocalPretrain.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u> <a href="https://huggingface.co/Essid/GuideVocalPretrain/resolve/main/G_GuideVocalPretrain.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>Itaila V1.0 by Ilaria</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>This is a fine-tuned pretrain based on the original pretrains and was made with 10 hours of Italian speech. Itaila was made to improve Italian speech.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/TheStinger/itaila/resolve/main/ItaIla_32k_D.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/TheStinger/itaila/resolve/main/ItaIla_32k_G.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>IMA by Loren85</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>This is a fine-tuned pretrain based on the original pretrains and was made with 2 hours of robotic speech which aims to make robotic voices better.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/Loren85/IMA-TEST-V1/resolve/main/D_2333333.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/Loren85/IMA-TEST-V1/resolve/main/G_2333333.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>KLM 4.1 by SeoulStreamingStation</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>KLM 4.1 is a fine-tuned based on KLM V7 pretrained and made with around 100 hours dataset (Korean vocal/speech, Japanese vocal/speech and English speech), so it will work better with those languages. Unlike typical pretrained models KLM is a pretrained model created to make vocal guides using short voice recordings from a studio, this means that even with short dataset high pitch information it is possible to implement high-pitched sounds but it is sensitive to noise so it is recommended to use it with high quality datasets</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM4.1/resolve/main/D_KLM41_32k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM4.1/resolve/main/G_KLM41_32k.pth?download=true"><strong>G Download</strong></a></u>
‎</li>
</ul>
</li>
<li><strong>48k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM4.1/resolve/main/D_KLM41_48k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM4.1/resolve/main/G_KLM41_48k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>KLM 4.2 by SeoulStreamingStation</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>KLM 4.2 maintains the same highly extensive pitch range as before and was developed to be able to handle high-pitched vocal inference even without having the corresponding vocal data of the model you wish to generate. KLM 4.2 was trained with 146 hours of data which mostly contains Korean, Japanese and some English.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM4.2/resolve/main/D_KLM42_32k_x10.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM4.2/resolve/main/G_KLM42_32k_x10.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>KLM 4 by SeoulStreamingStation <svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="m12.672.668 3.059 6.197 6.838.993a.75.75 0 0 1 .416 1.28l-4.948 4.823 1.168 6.812a.75.75 0 0 1-1.088.79L12 18.347l-6.116 3.216a.75.75 0 0 1-1.088-.791l1.168-6.811-4.948-4.823a.749.749 0 0 1 .416-1.279l6.838-.994L11.327.668a.75.75 0 0 1 1.345 0Z"/></g></g></svg></span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>KLM 4 is the final HiFi-GAN pretrain that is going to be made by SSS. This version of klm is like all of the others but it follows the original structure of training and contains noise in the dataset so it can handle it better. This was trained with 800 hours of data, with a large portion of it being in Korean.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM49_HFG/resolve/main/D_KLM_HFG_32k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM49_HFG/resolve/main/G_KLM_HFG_32k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>40k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM49_HFG/resolve/main/D_KLM_HFG_40k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM49_HFG/resolve/main/G_KLM_HFG_40k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>48k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM49_HFG/resolve/main/D_KLM_HFG_48k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM49_HFG/resolve/main/G_KLM_HFG_48k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>KLM BeatzForge by SeoulStreamingStation</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>This is a fine-tuned pretrain based on the original pretrain that improves drum models.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM_BEATMASTER/resolve/main/D_BeatzForge_V2_32k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/SeoulStreamingStation/KLM_BEATMASTER/resolve/main/G_BeatzForge_V2_32k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>Nanashi V1.7 by shiromiya</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>Nanashi V1.7 is a fine-tuned based on TITAN pretrained and made with 11 hours of Brazilian music, so it will work better with this language but it can work with other languages without any problems, like TITAN, it allows models to be trained with few epochs and handles the noise better.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/shiromiya/nanashi-pretrain/resolve/main/v1.7/D_nanashi_v1_7.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/shiromiya/nanashi-pretrain/resolve/main/v1.7/G_nanashi_v1_7.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>Nanashi Anime v1 by shiromiya</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>This is a fine-tuned pretrain based off of the original pretrain which aims to improve anime-style speech. This was train with 11 hours of speech.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/shiromiya/nanashi-pretrain/resolve/main/v1_anime/normal/D_nanashi_anime_384e.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/shiromiya/nanashi-pretrain/resolve/main/v1_anime/normal/G_nanashi_anime_384e.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>Nezox V1 by noxty</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>Nezox is a fine-tuned pretrain based on the original pretrain. This pretrain contains 43 hours of Indonesian speech with the goal of the pretrain to make Indonesian speech better.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/theNeofr/Nezox/resolve/main/Nezox_32k_D.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/theNeofr/Nezox/resolve/main/Nezox_32k_G.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>OV2 Super by SimplCup</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>Ov2Super is a fine-tuned based on the original RVC V2 pretrained and made with 30 minutes dataset, works well for small datasets and English language, this pretrained was trained on a precisely chosen clean speech and singing dataset, with bright and emotional voices. Additionally, it allows models to train with very few epochs compared to regular pretrains.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kD.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/poiqazwsx/Ov2Super32kfix/resolve/main/f0Ov2Super32kG.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>40k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kD.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/ORVC/Ov2Super/resolve/main/f0Ov2Super40kG.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>RIN_E3 by MUSTAR</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>This pretrain is made from scratch with a 140 hour dataset. It is suggested to use this with high quality datasets due to its sensitivity to noise.</p>
<ul>
<li><strong>40k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/RIN_E3/resolve/main/RIN_E3_D.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/RIN_E3/resolve/main/RIN_E3_G.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>Rigel by MUSTAR</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>Rigel is a fine-tuned pretrain based on Rigel Base. Rigel Base has 1921 of speech from most langauges, Rigel fine-tuned has 102 of high quality speech also from a ton of langauges. The goal of this pretrain is to be a better base then the original pretrain.</p>
<ul>
<li><strong>Base 32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/Rigel-rvc-base-pretrained-model/resolve/main/Rigel_32k_Base_and_FineTuned/Base-model_32k_fp32/D_Rigel_32k_3890220.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/Rigel-rvc-base-pretrained-model/resolve/main/Rigel_32k_Base_and_FineTuned/Base-model_32k_fp32/G_Rigel_32k_3890220.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>Fine-Tuned 32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/Rigel-rvc-base-pretrained-model/resolve/main/Rigel_32k_Base_and_FineTuned/FineTuned-model_32k_fp32/D_Rigel_32k_fp32_2854856.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/Rigel-rvc-base-pretrained-model/resolve/main/Rigel_32k_Base_and_FineTuned/FineTuned-model_32k_fp32/G_Rigel_32k_fp32_2854856.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>SingerPreTrain by Sztef</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>SingerPetrain is a fine-tuned based on Ov2 Super pretrained and made with 14 hours dataset (English singers). It is most suitable for training singers but it works for everything, the vocal range dataset is c1 to db7 so it works well with bass, baritone, tenor, alto, mezzo-soprano, soprano voices.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/Sztef/SingerPreTrained/resolve/main/update/f0D_SingerPreTrain.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/Sztef/SingerPreTrained/resolve/main/update/f0G_SingerPreTrain.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>Snowie by MUSTAR</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>Snowie is a fine-tuned pretrain based on the original pretrain. This pretrain&#x27;s goal is to improve Russian speech without effecting English speech. This was trained with 21 hours of Russian speech.</p>
<ul>
<li><strong>40k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/SnowyRuPretrain_EnP_40k/resolve/main/D_Snowie_RuPretrain_EnP.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/SnowyRuPretrain_EnP_40k/resolve/main/G_Snowie_RuPretrain_EnP.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>48k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/SnowyRuPretrain_EnP_48k/resolve/main/D_Snowie_Rupretrain_48k_V1.2.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/SnowyRuPretrain_EnP_48k/resolve/main/G_Snowie_Rupretrain_48k_V1.2.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>SnowieV3 X RIN_E3 by MUSTAR</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>SnowieV3 X RIN_E3 continues the training with Snowie dataset and then finetuned with additional data, so it will work better with English, Russian and Japanese language and also helps models of other languages to pronounce them well.</p>
<ul>
<li><strong>40k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/SnowieV3.1-X-RinE3-40K/resolve/main/D_Snowie-X-Rin_40k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/SnowieV3.1-X-RinE3-40K/resolve/main/G_Snowie-X-Rin_40k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>SnowieV3.1 by MUSTAR</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>SnowieV3.1 is a fine-tuned based on Snowie base pretrained (not publicly available) and made with 58 hours dataset (Russian and Japanese), so it will work better with those languages and also helps models of other languages to pronounce them well.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/SnowieV3.1-32k/resolve/main/D_SnowieV3.1_32k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/SnowieV3.1-32k/resolve/main/G_SnowieV3.1_32k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>40k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/SnowieV3.1-40k/resolve/main/D_SnowieV3.1_40k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/SnowieV3.1-40k/resolve/main/G_SnowieV3.1_40k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>48k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/MUSTAR/SnowieV3.1-48k/resolve/main/D_SnowieV3.1_48k.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/MUSTAR/SnowieV3.1-48k/resolve/main/G_SnowieV3.1_48k.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>TITAN by blaise-tk</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>TITAN is a fine-tuned based on the original RVC V2 pretrained, leveraging an 11.15-hours dataset sourced from Expresso. It gives cleaner results compared to the original pretrained, also handles the accent and noise better due to its robustness, being able to generate high quality results. Like Ov2 Super, it allows models to be trained with few epochs.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/32k/pretrained/D-f032k-TITAN-Medium.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/32k/pretrained/G-f032k-TITAN-Medium.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>40k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/40k/pretrained/D-f040k-TITAN-Medium.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/40k/pretrained/G-f040k-TITAN-Medium.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
<li><strong>48k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/48k/pretrained/D-f048k-TITAN-Medium.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/blaise-tk/TITAN/resolve/main/models/medium/48k/pretrained/G-f048k-TITAN-Medium.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<div class="mb-6 overflow-hidden border rounded-md docs-columns dark:border-dark-650" style="grid-template-columns: repeat(1, minmax(0, 1fr));">
    <div class="flex items-center px-5 py-3 font-medium leading-snug text-gray-900 border-b border-gray-200 dark:border-dark-650 dark:text-white">
        <span>UKA by PlasmaTi</span>
    </div>
    <div class="px-5 py-3 docs-columns-content">
<p>UKA is a fine-tuned pretrain based on the original pretrain. This pretrain has 8 hours of english speech all containing the British accent.</p>
<ul>
<li><strong>32k Download:</strong>
<ul>
<li><u><a href="https://huggingface.co/Plasmati/Pretrains/resolve/main/UKA-Pretrain-D.pth?download=true"><strong>D Download</strong></a></u></li>
<li><u><a href="https://huggingface.co/Plasmati/Pretrains/resolve/main/UKA-Pretrain-G.pth?download=true"><strong>G Download</strong></a></u></li>
</ul>
</li>
</ul>
    </div>
</div>
<hr>
<doc-anchor-target id="section-2">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section-2">#</doc-anchor-trigger>
        <span>‎</span>
    </h6>
</doc-anchor-target>
<doc-anchor-target id="how-do-i-make-pretrain">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#how-do-i-make-pretrain">#</doc-anchor-trigger>
        <span>How do i make Pretrain?</span>
    </h3>
</doc-anchor-target>
<p>Creating a pretrain is pretty much the same as training a normal model but the dataset is bigger and longer.</p>
<p>There are two ways of making a pretrain the first being:</p>
<ul>
<li>From scratch which means you don&#x27;t use a pretrain when training this. To make a decent from scratch pretrain you are going to need at <strong>least</strong> 50 hours of low, mid and high quality speech with many different speakers.
The second way being:</li>
<li>Finetuning which means you use a pretrain to train this pretrain. To make a good you are going to need at <strong>least</strong> 10 hours of high quality speech with many speakers.
<ul>
<li>The big pro of making a Finetune is that you can tailor it to anything, like you can tailor it to improve a certain language, improve accents, types of speech and more. It can even improve the graphs (like grads, g/total etc.) if trained properly.</li>
</ul>
</li>
</ul>
<hr>
<doc-anchor-target id="section-3">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section-3">#</doc-anchor-trigger>
        <span></span>
    </h6>
</doc-anchor-target>
<doc-anchor-target id="misc">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#misc">#</doc-anchor-trigger>
        <span>Misc</span>
    </h3>
</doc-anchor-target>
<p>This section contains miscellaneous information about pretrains.</p>
<doc-tabs>
<doc-tab v-cloak id="gpu">
<template #title>GPU</template>
<p>To make a pretrain you are going to need a pretty good GPU, because without one it will take a very long time to train. Here is a GPU tier list for training pretrains:</p>
<ul>
<li>S Tier:
<ul>
<li>H100</li>
<li>A100 (80gb and 40gb)</li>
</ul>
</li>
<li>A Tier:
<ul>
<li>L40S</li>
<li>4090</li>
<li>4080 (Super)</li>
</ul>
</li>
<li>B Tier:
<ul>
<li>4070 (Ti) (Super)</li>
<li>V 100</li>
<li>3090 (Ti)</li>
<li>A40</li>
</ul>
</li>
<li>C Tier:
<ul>
<li>4070 (Ti)</li>
<li>3080 (Ti)</li>
<li>3070 (Ti)</li>
<li>P 100</li>
</ul>
</li>
<li>D Tier:
<ul>
<li>L4</li>
<li>A10, T4</li>
<li>4060 (Ti) (8/16gb)</li>
<li>3060 (Ti)</li>
</ul>
</li>
</ul>
</doc-tab>
<doc-tab v-cloak id="qa">
<template #title>Q&amp;A</template>
<p>Q: What is the best pretrain?</p>
<p>A: There is no &quot;best pretrain&quot; it all depends on your needs and what you&#x27;re ok with sacrificing to get those benefits.</p>
</doc-tab>
</doc-tabs>
<hr>
<div class="content-center"><doc-anchor-target id="vocoders">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#vocoders">#</doc-anchor-trigger>
        <span>Vocoders</span>
    </h2>
</doc-anchor-target>
</div>
<ul>
<li>In Applio and Codenames Fork you are given the choice between three vocoders:
<ul>
<li>HiFi-GAN</li>
<li>MRF HiFi-GAN</li>
<li>RefineGAN</li>
</ul>
</li>
</ul>
<p>Each of these are different in fidelity and require their own pretrains to use.</p>
<doc-anchor-target id="hifi-gan">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#hifi-gan">#</doc-anchor-trigger>
        <span>HiFI-GAN</span>
    </h3>
</doc-anchor-target>
<p>The first vocoder choice is HiFi-GAN the original GAN used in RVC which is combatible with all version of RVC and forks. HiFI-GAN is pretty basic and has muddy high ends.</p>
<doc-anchor-target id="mrf-hifi-gan">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#mrf-hifi-gan">#</doc-anchor-trigger>
        <span>MRF HiFI-GAN</span>
    </h3>
</doc-anchor-target>
<p>The second choice is MRF HiFI-GAN, this is a modfied version of HiFi-GAN with MRF instead of MPD, new loss functions and non-simplified version of the resolution block.</p>
<ul>
<li>Pros:
<ul>
<li>Higher fidelity</li>
<li>44.1k Training</li>
</ul>
</li>
<li>Cons:
<ul>
<li>Only a slight upgrade from Hifi-GAN</li>
<li>Not many pretrains for it</li>
</ul>
</li>
</ul>
<doc-anchor-target id="refinegan">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#refinegan">#</doc-anchor-trigger>
        <span>RefineGAN</span>
    </h3>
</doc-anchor-target>
<p>The third and final choice is RefineGAN, this is an entirely different GAN then HiFi. This GAN uses noise to fill in the gaps and has a different resolution block.</p>
<ul>
<li>Pros:
<ul>
<li>Higher fidelity and quality</li>
<li>44.1k Training</li>
</ul>
</li>
</ul>
<hr>
<div class="content-center"><doc-anchor-target id="tensorboard">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#tensorboard">#</doc-anchor-trigger>
        <span>Tensorboard</span>
    </h2>
</doc-anchor-target>
</div>
<ul>
<li><p>TensorBoard is a tool that allows you to visualize &amp; measure the training of an AI model, through graphs &amp; metrics.</p>
</li>
<li><p>It&#x27;s specially useful for determining when to stop training a voice model, since with it you can detect when the <u><u><a href="https://docs.aihub.gg/rvc/resources/training/#epochs--overtraining">overtraining</u></a></u> point begins.</p>
</li>
<li><p>Because of this, TB is the most convenient tool for RVC users for perfecting a voice model.</p>
</li>
</ul>
<hr>
<doc-anchor-target id="section-4">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section-4">#</doc-anchor-trigger>
        <span>‎</span>
    </h6>
</doc-anchor-target>
<doc-anchor-target id="installing--opening">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#installing--opening">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M5.22 8.22a.749.749 0 0 0 0 1.06l6.25 6.25a.749.749 0 0 0 1.06 0l6.25-6.25a.749.749 0 1 0-1.06-1.06L12 13.939 6.28 8.22a.749.749 0 0 0-1.06 0Z"/></g></g></svg> Installing &amp; Opening</span>
    </h3>
</doc-anchor-target>
<div class="flex mb-6">
    <div class="shrink-0 w-1.5 rounded-tl-lg rounded-bl-lg bg-blue-500 dark:bg-blue-400"></div>
    <div class="flex w-full py-4 border border-l-0 border-gray-300 rounded-tr-lg rounded-br-lg doc-callout bg-white dark:bg-dark-700 dark:border-dark-700" role="alert">
        <div class="flex items-center ml-4 h-7">
            <svg xmlns="http://www.w3.org/2000/svg" class="mb-px text-blue-500 dark:text-blue-400" width="22" height="22" viewBox="0 0 24 24" role="presentation">
                <g fill="currentColor"><g>
                    <path d="M12 1C5.93 1 1 5.93 1 12s4.93 11 11 11 11-4.93 11-11S18.07 1 12 1zm0 20c-4.96 0-9-4.04-9-9s4.04-9 9-9 9 4.04 9 9-4.04 9-9 9z"></path>
                    <path d="M12 11c-.55 0-1 .45-1 1v4c0 .55.45 1 1 1s1-.45 1-1v-4c0-.55-.45-1-1-1zM12.01 7c-.56 0-1 .45-1 1s.45 1 1 1 1-.45 1-1-.45-1-1-1z"></path>
                    <path fill="none" d="M0 0h24v24H0z"></path>
                </g></g>
            </svg>
        </div>
        <div class="pr-5 ml-3 w-full">
            <h5>Applio Users</h5>
<doc-anchor-target id="if-you-use-applio-you-dont-have-to-follow-these-installation-steps-just-run-run-tensorboardbat-these-installation-steps-are-only-for-local-mainline-rvc-users">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#if-you-use-applio-you-dont-have-to-follow-these-installation-steps-just-run-run-tensorboardbat-these-installation-steps-are-only-for-local-mainline-rvc-users">#</doc-anchor-trigger>
        <span>If you use Applio you don&#x27;t have to follow these installation steps. Just run <code v-pre>run-tensorboard.bat</code>. These installation steps are only for local mainline RVC users.</span>
    </h4>
</doc-anchor-target>
        </div>
    </div>
</div>
<doc-anchor-target id="section-5">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section-5">#</doc-anchor-trigger>
        <span>‎</span>
    </h6>
</doc-anchor-target>
<ol>
<li><p>Download this file &amp; move it inside mainline RVC&#x27;s folder. Ensure the file path doesn&#x27;t contain spaces/special characters.</p>
<p>
<div class="mb-6 px-5 py-4 flex justify-between relative border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded transition-colors duration-150">
    <div class="flex items-center text-blue-500 dark:text-blue-400">
        <span class="inline-block mb-px">
            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" role="presentation" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M21 14c-.55 0-1 .45-1 1v4c0 .55-.45 1-1 1H5c-.55 0-1-.45-1-1v-4c0-.55-.45-1-1-1s-1 .45-1 1v4c0 1.65 1.35 3 3 3h14c1.65 0 3-1.35 3-3v-4c0-.55-.45-1-1-1z"/><path d="M11.29 15.71c.09.09.2.17.33.22.12.04.25.07.38.07s.26-.03.38-.08.23-.12.33-.22l5-5a.996.996 0 10-1.41-1.41l-3.3 3.3V3c0-.55-.45-1-1-1s-1 .45-1 1v9.59l-3.29-3.3A.996.996 0 106.3 10.7l4.99 5.01z"/></svg>
        </span>
        <span class="inline-block font-medium ml-2">TensorVENV.bat</span>
    </div>
    <div class="flex items-center text-xs text-gray-400 dark:text-dark-400">
        <span>TensorVENV.bat</span>
        <span class="inline-block ml-2">1.57KB</span>
    </div>
    <a href="../tensorboardfiles/tensorvenv.bat" class="absolute block inset-0" target="_blank" download="TensorVENV.bat"></a>
</div>
</p>
</li>
</ol>
<doc-anchor-target id="section-6">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section-6">#</doc-anchor-trigger>
        <span>‎</span>
    </h6>
</doc-anchor-target>
<ol start="2">
<li>Now execute it. It will open a console window &amp; create some folders inside RVC.
<ul>
<li>If you get the <code v-pre>Windows protected your PC</code> issue, click <u><strong>More info</strong></u> &amp; <strong>Run anyway</strong>.<br />
‎</li>
</ul>
</li>
<li>Once it&#x27;s done, your default browser should open with TensorBoard app.<br />
‎
<ul>
<li>If it doesn&#x27;t, copy the address of the console at the bottom, and paste it in your browser.<br />
Said address will say &quot;<strong>https://localhost</strong>&quot; followed by some numbers.<br />
‎<br />
<img src="../tensorboard-img/11.png" alt="image" width="500" height="auto"></li>
</ul>
</li>
</ol>
<hr>
<doc-anchor-target id="section-7">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section-7">#</doc-anchor-trigger>
        <span>‎</span>
    </h6>
</doc-anchor-target>
<doc-anchor-target id="usage-guide">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#usage-guide">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M5.22 8.22a.749.749 0 0 0 0 1.06l6.25 6.25a.749.749 0 0 0 1.06 0l6.25-6.25a.749.749 0 1 0-1.06-1.06L12 13.939 6.28 8.22a.749.749 0 0 0-1.06 0Z"/></g></g></svg> Usage Guide</span>
    </h3>
</doc-anchor-target>
<doc-tabs>
<doc-tab v-cloak id="simple-guide">
<template #title>Simple Guide</template>
<doc-anchor-target id="section-8">
    <h6>
        <doc-anchor-trigger class="header-anchor-trigger" to="#section-8">#</doc-anchor-trigger>
        <span>‎</span>
    </h6>
</doc-anchor-target>
<doc-anchor-target id="setting-up">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#setting-up">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M5.22 8.22a.749.749 0 0 0 0 1.06l6.25 6.25a.749.749 0 0 0 1.06 0l6.25-6.25a.749.749 0 1 0-1.06-1.06L12 13.939 6.28 8.22a.749.749 0 0 0-1.06 0Z"/></g></g></svg> <u>SETTING UP</u></span>
    </h4>
</doc-anchor-target>
<hr>
<ul>
<li><p>Open TB &amp; begin training in RVC.</p>
<ul>
<li><p>If you get the <code v-pre>No dashboards are active</code> issue, select <code v-pre>SCALARS</code> in the top right corner dropdown.</p>
<p><img src="../tensorboard-img/17.png" alt="image" width="230" height="auto">‎<br />
‎</p>
</li>
</ul>
</li>
<li><p>First ensure <strong>auto-refresh</strong> is on, so the graphs update constantly.</p>
<p>Click the gear (<svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M16 12a4 4 0 1 1-8 0 4 4 0 0 1 8 0Zm-1.5 0a2.5 2.5 0 1 0-5 0 2.5 2.5 0 0 0 5 0Z"/><path d="M12 1c.266 0 .532.009.797.028.763.055 1.345.617 1.512 1.304l.352 1.45c.019.078.09.171.225.221.247.089.49.19.728.302.13.061.246.044.315.002l1.275-.776c.603-.368 1.411-.353 1.99.147.402.349.78.726 1.128 1.129.501.578.515 1.386.147 1.99l-.776 1.274c-.042.069-.058.185.002.315.112.238.213.481.303.728.048.135.142.205.22.225l1.45.352c.687.167 1.249.749 1.303 1.512.038.531.038 1.063 0 1.594-.054.763-.616 1.345-1.303 1.512l-1.45.352c-.078.019-.171.09-.221.225-.089.248-.19.491-.302.728-.061.13-.044.246-.002.315l.776 1.275c.368.603.353 1.411-.147 1.99-.349.402-.726.78-1.129 1.128-.578.501-1.386.515-1.99.147l-1.274-.776c-.069-.042-.185-.058-.314.002a8.606 8.606 0 0 1-.729.303c-.135.048-.205.142-.225.22l-.352 1.45c-.167.687-.749 1.249-1.512 1.303-.531.038-1.063.038-1.594 0-.763-.054-1.345-.616-1.512-1.303l-.352-1.45c-.019-.078-.09-.171-.225-.221a8.138 8.138 0 0 1-.728-.302c-.13-.061-.246-.044-.315-.002l-1.275.776c-.603.368-1.411.353-1.99-.147-.402-.349-.78-.726-1.128-1.129-.501-.578-.515-1.386-.147-1.99l.776-1.274c.042-.069.058-.185-.002-.314a8.606 8.606 0 0 1-.303-.729c-.048-.135-.142-.205-.22-.225l-1.45-.352c-.687-.167-1.249-.749-1.304-1.512a11.158 11.158 0 0 1 0-1.594c.055-.763.617-1.345 1.304-1.512l1.45-.352c.078-.019.171-.09.221-.225.089-.248.19-.491.302-.728.061-.13.044-.246.002-.315l-.776-1.275c-.368-.603-.353-1.411.147-1.99.349-.402.726-.78 1.129-1.128.578-.501 1.386-.515 1.99-.147l1.274.776c.069.042.185.058.315-.002.238-.112.481-.213.728-.303.135-.048.205-.142.225-.22l.352-1.45c.167-.687.749-1.249 1.512-1.304C11.466 1.01 11.732 1 12 1Zm-.69 1.525c-.055.004-.135.05-.161.161l-.353 1.45a1.832 1.832 0 0 1-1.172 1.277 7.147 7.147 0 0 0-.6.249 1.833 1.833 0 0 1-1.734-.074l-1.274-.776c-.098-.06-.186-.036-.228 0a9.774 9.774 0 0 0-.976.976c-.036.042-.06.131 0 .228l.776 1.274c.314.529.342 1.18.074 1.734a7.147 7.147 0 0 0-.249.6 1.831 1.831 0 0 1-1.278 1.173l-1.45.351c-.11.027-.156.107-.16.162a9.63 9.63 0 0 0 0 1.38c.004.055.05.135.161.161l1.45.353a1.832 1.832 0 0 1 1.277 1.172c.074.204.157.404.249.6.268.553.24 1.204-.074 1.733l-.776 1.275c-.06.098-.036.186 0 .228.301.348.628.675.976.976.042.036.131.06.228 0l1.274-.776a1.83 1.83 0 0 1 1.734-.075c.196.093.396.176.6.25a1.831 1.831 0 0 1 1.173 1.278l.351 1.45c.027.11.107.156.162.16a9.63 9.63 0 0 0 1.38 0c.055-.004.135-.05.161-.161l.353-1.45a1.834 1.834 0 0 1 1.172-1.278 6.82 6.82 0 0 0 .6-.248 1.831 1.831 0 0 1 1.733.074l1.275.776c.098.06.186.036.228 0 .348-.301.675-.628.976-.976.036-.042.06-.131 0-.228l-.776-1.275a1.834 1.834 0 0 1-.075-1.733c.093-.196.176-.396.25-.6a1.831 1.831 0 0 1 1.278-1.173l1.45-.351c.11-.027.156-.107.16-.162a9.63 9.63 0 0 0 0-1.38c-.004-.055-.05-.135-.161-.161l-1.45-.353c-.626-.152-1.08-.625-1.278-1.172a6.576 6.576 0 0 0-.248-.6 1.833 1.833 0 0 1 .074-1.734l.776-1.274c.06-.098.036-.186 0-.228a9.774 9.774 0 0 0-.976-.976c-.042-.036-.131-.06-.228 0l-1.275.776a1.831 1.831 0 0 1-1.733.074 6.88 6.88 0 0 0-.6-.249 1.835 1.835 0 0 1-1.173-1.278l-.351-1.45c-.027-.11-.107-.156-.162-.16a9.63 9.63 0 0 0-1.38 0Z"/></g></g></svg>) in the top left corner &amp; turn on <strong><code v-pre>Reload data</code></strong>.<br />
You can always manually refresh with the refresh symbol (<span class="docs-emoji">&#x1F504;</span>) in the top right.</p>
  <img src="../tensorboard-img/2.png" alt="image" width="280" height="auto">
<p>‎</p>
</li>
<li><p>Go to the <code v-pre>SCALARS</code> tab.<br />
‎<br />
<img src="../tensorboard-img/12.png" alt="image" width="280" height="auto"><br />
‎</p>
</li>
</ul>
<hr>
<doc-anchor-target id="graph">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#graph">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M5.22 8.22a.749.749 0 0 0 0 1.06l6.25 6.25a.749.749 0 0 0 1.06 0l6.25-6.25a.749.749 0 1 0-1.06-1.06L12 13.939 6.28 8.22a.749.749 0 0 0-1.06 0Z"/></g></g></svg> <u>GRAPH</u></span>
    </h4>
</doc-anchor-target>
<hr>
<ul>
<li><doc-anchor-target id="in-the-left-panel">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#in-the-left-panel">#</doc-anchor-trigger>
        <span>In the left panel:</span>
    </h4>
</doc-anchor-target>
<ol>
<li><p>Activate <code v-pre>Ignore outliers in chart scaling</code>.</p>
</li>
<li><p>Set <strong>Smoothing</strong> to <code v-pre>0.987</code>.</p>
</li>
<li><p>Select your model in the <code v-pre>Runs</code> section below. The models you tick will show in the graphs. (untick <code v-pre>/eval</code> if you want)<br />
‎<br />
<img src="../tensorboard-img/18.png" alt="image" width="240" height="auto">‎<br />
‎</p>
</li>
</ol>
</li>
<li>In the search bar, type &quot;<strong>g/total</strong>&quot; then look for the avg graph. This will be the graph you&#x27;ll monitor.<br />
‎<br />
<img src="../tensorboard-img/19.png" alt="image" width="390" height="auto">‎<br />
‎<br />
‎</li>
<li>Each graph has three buttons in the corner:
<ul>
<li>Left one is for going <strong>fullscreen</strong>.</li>
<li>Middle one to <strong>disable</strong> Y axis, for a fuller view.</li>
<li>And the right one is to <strong>center</strong> the view.<br />
‎<br />
<img src="../tensorboard-img/15.png" alt="image" width="300" height="auto">‎<br />
‎</li>
</ul>
</li>
<li>To <strong>zoom</strong> in &amp; out the graphs, press the ALT key + mouse wheel. Remember to center the view after moving around, and after the graph updates.</li>
</ul>
<hr>
<doc-anchor-target id="monitoring">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#monitoring">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M5.22 8.22a.749.749 0 0 0 0 1.06l6.25 6.25a.749.749 0 0 0 1.06 0l6.25-6.25a.749.749 0 1 0-1.06-1.06L12 13.939 6.28 8.22a.749.749 0 0 0-1.06 0Z"/></g></g></svg> <u> MONITORING</u></span>
    </h4>
</doc-anchor-target>
<hr>
<ul>
<li><p>Now let the training go for some time.</p>
</li>
<li><p>You&#x27;ll detect <strong>OT</strong> (overtraining) when the graph hits the <strong>lowest point</strong>, then stay <strong>flat</strong>/<strong>rising</strong> indefinitely.<br />
‎<br />
<strong><u>Example of OT:</u></strong></p>
<p><img src="../tensorboard-img/10.png" alt="image" width="370" height="auto">‎<br />
‎</p>
</li>
<li><p>There will be various low points, one after the other, so don&#x27;t get too anxious if it&#x27;s OT or not. You can always use a previous checkpoint either way.</p>
</li>
<li><p>If it reaches a low point, let it run for <strong>longer</strong> until it&#x27;s <strong>very clear</strong> it&#x27;s OT.</p>
</li>
<li><p>Then zoom out &amp; lower the smoothening. Then in the avg graph look for low points around where it started to overtrain.</p>
</li>
<li><p>Then over your mouse over these low points and take note of the step counts. Since this is using the avg graphs you may not find the exact epoch connected to the step count so just choose the closest point.</p>
<p><img src="../tensorboard-img/avg.png" alt="image" width="1000" height="auto">‎</p>
</li>
<li><p>As you can see in the image above there is an area with several low points, so in this scenario you would try several epochs in that area to find the best sounding epoch.</p>
</li>
</ul>
<blockquote>
<p>If you want you can just use the lowest avg g/total point.</p>
</blockquote>
</doc-tab>
<doc-tab v-cloak id="advanced-guide-">
<template #title>Advanced Guide ‎</template>
<doc-anchor-target id="other-graphs">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#other-graphs">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M5.22 8.22a.749.749 0 0 0 0 1.06l6.25 6.25a.749.749 0 0 0 1.06 0l6.25-6.25a.749.749 0 1 0-1.06-1.06L12 13.939 6.28 8.22a.749.749 0 0 0-1.06 0Z"/></g></g></svg> <u>Other Graphs</u></span>
    </h4>
</doc-anchor-target>
<hr>
<doc-anchor-target id="fm-feature-matching">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#fm-feature-matching">#</doc-anchor-trigger>
        <span><code v-pre>FM</code> Feature Matching:</span>
    </h4>
</doc-anchor-target>
<p>FM shows how well the generator is able to make synthetic data that has similar features to the dataset.</p>
<p>If the graph is increasing that indicates that the generator is able to make audio that has similar features to the dataset.</p>
<blockquote>
<p>you can think of this as how well the model can match timbral, spatial and temporal characteristics.</p>
</blockquote>
<hr>
<doc-anchor-target id="kl-kullback-leibler">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#kl-kullback-leibler">#</doc-anchor-trigger>
        <span><code v-pre>KL</code> Kullback-Leibler:</span>
    </h4>
</doc-anchor-target>
<p>KL makes the generator create similar distribution of latest variables to real data. The KL loss ensures that the generator is not just memorizing real data but it&#x27;s learning to capture the underlying patterns in the data.</p>
<p>If the graph is decreasing that shows that the generator is making audio with similar distribution of latent variables to real data.</p>
<blockquote>
<p>You can think of this as how well it can replicate the speakers style.</p>
</blockquote>
<hr>
<doc-anchor-target id="mel-mel-spectrogram">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#mel-mel-spectrogram">#</doc-anchor-trigger>
        <span><code v-pre>Mel</code> Mel Spectrogram:</span>
    </h4>
</doc-anchor-target>
<p>The mel spectrogram loss compares both the real and synthetic mel spectrograms. This loss encourages the generator to produce audio that sounds similar to the dataset.</p>
<p>If the graph is decreasing that shows that the generator is producing audio with similar spectral distribution to the dataset.</p>
<blockquote>
<p>you can think of this as clarity / fidelity.</p>
</blockquote>
<hr>
<doc-anchor-target id="dtotal-discriminator-loss">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#dtotal-discriminator-loss">#</doc-anchor-trigger>
        <span><code v-pre>d/total</code> Discriminator Loss:</span>
    </h4>
</doc-anchor-target>
<p>d/total shows how well the discriminator is able to differentiate between real and generated audio.</p>
<p>If the graph is decreasing that means the discriminator is becoming better at distinguishing between real and synthetic data which usually means that the generator is producing realistic audio.</p>
<hr>
<doc-anchor-target id="grad_norm_g-gradient-norm-for-the-generator">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#grad_norm_g-gradient-norm-for-the-generator">#</doc-anchor-trigger>
        <span><code v-pre>grad_norm_g</code> Gradient norm for the generator:</span>
    </h4>
</doc-anchor-target>
<p>grad_norm_g shows the magnitude of gradients during training. If the gradients are becoming too large (over 1,000 for fintuning) that can cause some training instabilities and if they are becoming small that can lead to slow learning.</p>
<blockquote>
<p>If you&#x27;re fintuning it&#x27;s best if the gradients don&#x27;t go above 1,000.</p>
</blockquote>
<hr>
<doc-anchor-target id="grad_norm_d-gradient-norm-for-the-discriminator">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#grad_norm_d-gradient-norm-for-the-discriminator">#</doc-anchor-trigger>
        <span><code v-pre>grad_norm_d</code> Gradient norm for the discriminator:</span>
    </h4>
</doc-anchor-target>
<p>grad_norm_d shows the magnitude of gradients during training. If the gradients are becoming too large (over 100 for fintuning) that can cause some training instabilities and if they are becoming small that can lead to slow learning.</p>
<blockquote>
<p>If you&#x27;re fintuning it&#x27;s best if the gradients don&#x27;t go above 100.</p>
</blockquote>
<hr>
<hr>
<doc-anchor-target id="mel-images">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#mel-images">#</doc-anchor-trigger>
        <span><svg xmlns="http://www.w3.org/2000/svg" class="docs-icon" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><g><path d="M5.22 8.22a.749.749 0 0 0 0 1.06l6.25 6.25a.749.749 0 0 0 1.06 0l6.25-6.25a.749.749 0 1 0-1.06-1.06L12 13.939 6.28 8.22a.749.749 0 0 0-1.06 0Z"/></g></g></svg> <u>Mel Images</u></span>
    </h4>
</doc-anchor-target>
<hr>
<p>While looking through the Tensor Board you may come across <code v-pre>slice/mel_gen</code> and <code v-pre>slice/mel_org</code>.</p>
<doc-anchor-target id="slicemel_gen">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#slicemel_gen">#</doc-anchor-trigger>
        <span>slice/mel_gen:</span>
    </h4>
</doc-anchor-target>
<p>Is a mel spectrogram view of audio that the generator created in attempt to make it match <code v-pre>mel_org</code>.
<img src="../tensorboard-img/mel_gen.png" alt="image" width="700" height="700">‎</p>
<hr>
<doc-anchor-target id="slicemel_org">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#slicemel_org">#</doc-anchor-trigger>
        <span>slice/mel_org:</span>
    </h4>
</doc-anchor-target>
<p>Is a mel spectrogram view of audio from your dataset.
<img src="../tensorboard-img/mel_og.png" alt="image" width="700" height="700">‎</p>
<hr>
</doc-tab>
</doc-tabs>
<div class="content-center"><doc-anchor-target id="you-have-reached-the-end">
    <h4>
        <doc-anchor-trigger class="header-anchor-trigger" to="#you-have-reached-the-end">#</doc-anchor-trigger>
        <span><code v-pre>You have reached the end.</code></span>
    </h4>
</doc-anchor-target>
<p><a href="https://docs.aihub.gg/contributions/" class="no-link inline-flex align-middle items-center justify-center font-medium leading-none whitespace-nowrap text-blue-500 dark:text-blue-400 border border-blue-500 dark:border-blue-400 hover:bg-blue-100 dark:hover:bg-transparent dark:hover:border-blue-200 dark:hover:text-blue-200 transition-colors duration-200 ease-out h-8 px-4 text-base rounded-full">
    <span>Report Issues</span>
    <span><svg xmlns="http://www.w3.org/2000/svg" class="mb-px inline-flex ml-2" width="22" height="22" viewBox="0 0 24 24" role="presentation"><g fill="currentColor"><path d="M1.513 1.96a1.374 1.374 0 0 1 1.499-.21l19.335 9.215a1.147 1.147 0 0 1 0 2.07L3.012 22.25a1.374 1.374 0 0 1-1.947-1.46L2.49 12 1.065 3.21a1.375 1.375 0 0 1 .448-1.25Zm2.375 10.79-1.304 8.042L21.031 12 2.584 3.208l1.304 8.042h7.362a.75.75 0 0 1 0 1.5Z"/></g></svg></span>
</a></p>
</div>

                                
                                <!-- Required only on API pages -->
                                <doc-toolbar-member-filter-no-results></doc-toolbar-member-filter-no-results>
                            </div>
                            <footer class="clear-both">
                            
                                <nav class="print:hidden flex mt-14">
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 h-full flex items-center break-normal font-medium text-blue-500 dark:text-blue-400 border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded-l-lg transition-colors duration-150 relative hover:z-5" href="../../../rvc/resources/dataset-isolation/">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mr-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19 11H7.41l5.29-5.29a.996.996 0 10-1.41-1.41l-7 7a1 1 0 000 1.42l7 7a1.024 1.024 0 001.42-.01.996.996 0 000-1.41L7.41 13H19c.55 0 1-.45 1-1s-.45-1-1-1z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                            <span>
                                                <span class="block text-xs font-normal text-gray-400 dark:text-dark-400">Previous</span>
                                                <span class="block mt-1">Dataset & Isolation</span>
                                            </span>
                                        </a>
                                    </div>
                            
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 -mx-px h-full flex items-center justify-end break-normal font-medium text-blue-500 dark:text-blue-400 border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded-r-lg transition-colors duration-150 relative hover:z-5" href="../../../rvc/resources/inference-settings/">
                                            <span>
                                                <span class="block text-xs font-normal text-right text-gray-400 dark:text-dark-400">Next</span>
                                                <span class="block mt-1">Inference Settings</span>
                                            </span>
                                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19.92 12.38a1 1 0 00-.22-1.09l-7-7a.996.996 0 10-1.41 1.41l5.3 5.3H5c-.55 0-1 .45-1 1s.45 1 1 1h11.59l-5.29 5.29a.996.996 0 000 1.41c.19.2.44.3.7.3s.51-.1.71-.29l7-7c.09-.09.16-.21.21-.33z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                        </a>
                                    </div>
                                </nav>
                            </footer>
                        </main>
                
                        <div class="print:border-none border-t dark:border-dark-650 pt-6 mb-8">
                            <footer class="flex flex-wrap items-center justify-between print:justify-center">
                                <div class="print:hidden">
                                    <ul class="flex flex-wrap items-center text-sm">
                                    </ul>
                                </div>
                                <div class="print:justify-center docs-copyright py-2 text-gray-500 dark:text-dark-350 text-sm leading-relaxed"><p>© Copyright 2025. All rights reserved.</p></div>
                            </footer>
                        </div>
                    </div>
                
                    <!-- Rendered if sidebar right is enabled -->
                    <!-- Sidebar right skeleton-->
                    <div v-cloak class="fixed top-0 bottom-0 right-0 translate-x-full bg-white border-gray-200 lg:sticky lg:border-l lg:shrink-0 lg:pt-6 lg:transform-none sm:w-1/2 lg:w-64 lg:z-0 md:w-104 sidebar-right skeleton dark:bg-dark-850 dark:border-dark-650">
                        <div class="pl-5">
                            <div class="w-32 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                            <div class="w-48 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                            <div class="w-40 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                        </div>
                    </div>
                
                    <!-- User should be able to hide sidebar right -->
                    <doc-sidebar-right v-cloak></doc-sidebar-right>
                </div>

            </div>
        </div>
    
        <doc-search-mobile></doc-search-mobile>
        <doc-back-to-top></doc-back-to-top>
    </div>


    <div id="docs-overlay-target"></div>

    <script data-cfasync="false">window.__DOCS__ = { "title": "Training", level: 3, icon: "file", hasPrism: false, hasMermaid: false, hasMath: false, tocDepth: 23 }</script>
</body>
</html>

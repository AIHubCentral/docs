[[{"l":"Home","p":["Last update: Mar 10, 2024"]},{"i":"section-2","l":"‎"},{"l":"Introduction","p":["This site is a documentation of AI tools, mostly RVC-related apps. Made by members of AI HUB.","See simple & convenient guides regarding model training, inference, audio isolation, datasets, TensorBoard, & more. Verified by the experts & for all devices."]},{"i":"section-3","l":"‎"},{"l":"Contributions","p":["We'll appreciate any feedback, big or small. You can directly contact us in AI Hub: @eddycrack864- @ailen2091","Leave suggestions in the #suggestions channel. To report issues, use #help-forum.","You can also send an issue/pull request to our GitHub page."]},{"i":"section-4","l":"‎"},{"l":"Credits","p":["Lead by: Julia & Eddy","General Help: Poopmaster Raid, Light, Faze Masta, Alexolotl, Delik","Reviewing: Faze Masta, Alexolotl, SimplCup, Delik, Litsa","OG Guides: Litsa, Angetyde, LollenApe, Faze Masta, MrM0dz, FDG, Eddy, Julia, Nick","Backend: Eddy & Yui","Branding: Grvyscale & Cthulhu"]},{"i":"section-5","l":"‎"},{"l":"To-Do","p":["EasyGUI","Advanced training","Advanced dataset cleaning","Pretrains","Kaggle"]}],[{"l":"How to Make AI Cover"},{"i":"--simple-ai-cover-tutorial-using-rvc--","l":"- Simple AI cover tutorial, using RVC -"},{"i":"section","l":"‎"},{"l":"1. Extract vocals","p":["Have the audio file of your song ready, & let's extract the vocals from it with an audio isolation software.","RVC is designed to work with voices only, so to get the best results the sample must be clean, with no undesired noises."]},{"i":"section-1","l":"‎"},{"l":"2. Get voice model","p":["Learn about them & how to search one here. Be sure to leave credits to the model maker.","In case the model doesn't exist, click here."]},{"i":"section-2","l":"‎"},{"l":"3. Convert the vocals","p":["After obtaining the vocals & model, it's time to set up RVC & do inference.","There are plenty of versions of RVC, but these are the best ones for beginners. Pick according to your needs:"]},{"i":"section-3","l":"‎","p":["For local users, first ensure you meet the minimum requirements."]},{"i":"section-4","l":"‎"},{"l":"Tips","p":["‎","Add delay if the original vocals had it.","Add reverb to the vocals (not to the instrumental), to the same level as the original one.","Congratulations, you've made it to the final part. Now it's to mix the song.‎","Convert them using Mangio-Crepe with a higher hop length.","For presence and clarity, increase the high range a bit.","Last update: Mar 1, 2024","Make vocals from scratch using a voice synthesizer (like SynthV) & convert them with RVC.","Match the volume of the vocals to the same level as the original ones.","Normalize the audio.","Recommendations for the mix:","Record yourself singing them & convert the audio with RVC.","Regarding what to do with the backing vocals, you have 4 options:","Remove the very low frequencies, ranging from 20 to 100.","Simply leave the original ones in.","Use compressor on vocals.‎","You're free to use any DAW, but we recommend FL Studio or BandLab, as they are beginner-friendly. You can start by searching some of their mixing tutorials on YouTube.‎"]}],[{"l":"How to Make Voice Models"},{"i":"--simple-model-training-tutorial-using-rvc--","l":"- Simple model training tutorial, using RVC -"},{"i":"section","l":"‎"},{"l":"1. Prepare dataset","p":["In the context of RVC, the dataset is an audio file containing the voice the model will replicate. It can be either speaking or singing.","For the best results, having a clean dataset is crucial, so take the time to remove any undesired noises."]},{"i":"section-1","l":"‎"},{"l":"2. Set up RVC","p":["With your dataset ready, it's time to set up RVC to train the model.","There are plenty of versions of RVC, but these are the best ones for beginners. Pick according to your needs:"]},{"i":"section-2","l":"‎","p":["For local users, first ensure you meet the minimum requirements."]},{"i":"section-3","l":"‎"},{"l":"3. Train the model","p":["Before you start training, we inform you that the training guides are oriented around using TensorBoard. Read about it & install it after setting up RVC.","Good luck & remember to be patient! As this won't be an instant process.","Last update: Mar 10, 2024","‎"]}],[{"l":"Voice Models","p":["Last update: Apr 01, 2024","‎","In the field of AI, is a program that was trained to recognize certain patterns or make certain decisions.","In this case, voice models are models trained to replicate a voice, and with AI they apply it to the input audio.","There are plenty of them uploaded to the internet, made by the public. And the best way to make them is with RVC."]},{"i":"section","l":"‎"},{"l":"Voice Model Files"},{"i":"they-are-made-up-of-two-files","l":"*They are made up of two files:*","p":["Contains data regarding the voice's accent and speech manner.","File is additional, but usually crucial for the quality of the model.","While training, RVC generates two .INDEX file, but the right one will be named added_ by default.","This file is the model itself.","Contains data regarding pitch.","While training, RVC generates other .PTHs named D_ and G_, but these are the checkpoints, not usable models.","As people sometimes upload them incorrectly."]},{"i":"section-3","l":"‎"},{"i":"section-4","l":"‎","p":["‎‎","‎ ‎ ‎ ‎ ‎ ‎ ‎","\uD83D\uDC40‎ If there are multiple models, click the Select a result bar to see the others.","\uD83D\uDC4D‎ Press the Like to support the creator & offer feedback.","\uD83D\uDCBE‎ With the Save one the bot will DM you said search result.","\uD83D\uDCE4‎ Click Download to download it.","\uD83D\uDD17‎ To get its link, right-click Download Model& tap Copy link.","Access guides, the HF space, and the Applio API featuring 21k+ free models.","Access the website here& login by clicking the icon on the top right corner.","Check the description, likes or tags, this can give you a slight idea of how good the model is.","Check the description, likes, comments, & audio sample. Feedback can help you know how great the model is.","Click on Download model. This will download a .ZIP file of it.‎‎‎","Click the Hugging Face link to download the model, or copy it if that's what you need.","Click the model & go to the Files and versions tab.","Download the correct files of the model. Then if you need its link, upload it to HF.","Go to the models page& search the model in the Filter by name bar.","Head over to the #search-models channel.","Here's where people usually store their RVC models.","If it only exists in weights.gg, download the .ZIP & upload it to HF.","If you get models from different years, remember, the person's voice changes overtime.","If you haven't already, join AI Hub here.","If you need a link for it, use the other methods.","If you're curious about the epochs, learn more here.","If you're curious about the epochs, you can learn more here.","In the upper search bar, search your model & click the post.","It searches the models uploaded on every RVC/AI Hub Discord server.","Models uploaded in AI Hub& AI Hub France get automatically stored here too.","Reminder: Models from kits.ai can't be downloaded.","Searching here is specially useful if you need the model as a link, as the posts include one.","Select the Applio command","Send the message","Share, favorite, and integrate with Applio (RVC) for direct model downloads to your PC.","Tap the three dots & Download model. It will download a .ZIP file of it.‎‎‎","The sample of the gender & vocal style according to the model gives the most accurate representation.","Then go to the #voice-models channel.","There's also its web version. Has less models but offers direct download & the Hugging Face link.","This a website where people can upload voice models.","This is a Discord bot developed by the IA Hispano team.","This is a forum channel in AI Hub where people upload their own voice models.","This is a free & open-source platform for storing AI models, interactive AI apps, & datasets.","This is a website where people can upload voice models.","This step is especially useful if you get multiple results from the same model.","This step is specially useful if you get multiple results of the same model.","To download it, click the download symbol ( ) on the right of the .ZIP file. If you need its link, right-click it and copy the address.","Type /search","Type the model","Type the name of the model in the Search bar & click a result.","User-friendly UI","Users can read/share feedback about the models through comments & likes.","You can listen to the audio sample to get a preview of the it."]},{"i":"section-21","l":"‎"},{"i":"if-you-couldnt-find-one-you-have-3-options","l":"If you couldn't find one, you have 3 options:","p":["Make the model yourself","Pick a different one","Comission a model maker to make it for you"]},{"i":"section-22","l":"‎"},{"l":"1. Zip the model","p":["Select the correct .PTH & .INDEX& zip them into a .ZIP file.","Ensure it's .ZIP & not .RAR or .7ZIP."]},{"i":"section-23","l":"‎"},{"l":"2. Log in","p":["If you haven't already, create an account& log in."]},{"i":"section-24","l":"‎"},{"l":"3. Make repository","p":["Once logged in, tap your profile on the upper right corner, & then New Model.","‎","In Model name you name the repo as you want.","Make sure License is set as openrail& the repo is set as Public.","Once done, hit Create model."]},{"i":"section-25","l":"‎"},{"l":"4. Upload model","p":["It will redirect you to the repo. Go to the Files and versions tab on the center, click + Add file on the right & then Upload files.","‎‎","Tap the upload box & submit the ZIP. Or just drag & drop.","Tap on Commit changes to main& the model will begin to upload."]},{"i":"section-26","l":"‎"},{"i":"5-copy-link-optional","l":"5. Copy link (optional)","p":["Once it's done, it will redirect you to the files list.","So if you need its link, right-click the download button ( ) of the .ZIP file on the right, and click Copy Link."]},{"i":"section-27","l":"‎"}],[{"i":"whats-rvc","l":"What's RVC","p":["Last update: Mar 1, 2024"]},{"l":"Introduction","p":["RVC ( Retrieval-Based Voice Conversion) is an advanced AI voice cloning software, developed by the RVC-Project team. It's considered the best free & open-source one to date.","It was designed for desktop, requiring great specs to run it effectively, specially GPU for training models (specifically NVIDIA).","Though it can be executed through the cloud& be used in any device, in case you don't meet the previous requirement.‎"]},{"l":"Forks","p":["A fork is a copy of a main GitHub project. It aims to make a different version of the project, with improvements, new features & modifications.","RVC has quite a few forks made by the community, each one meeting different needs for the user, and with its pros & cons.","These are the main ones, along with their cloud-based counterparts:","‎"]},{"l":"FAQ"},{"i":"frequently-asked-questions","l":"Frequently asked questions."},{"i":"what-s-the-best-fork","l":"*What's the best fork?*","p":["As explained before, it depends on your needs. It's best to try them yourself.","For local users, Mainline is a great starting point. For cloud users, the Applio Colab."]},{"i":"what-are-the-requirements-for-rvc-locally","l":"*What are the requirements for RVC locally?*","p":["16GB","30 GB","6 GB","8GB","For inference, the storage requirement varies depending on the fork. It can be around 5 to 9 GB","GPU","If you don't meet these requirements, it's more convenient to use RVC on the cloud.","NVIDIA GTX 1050ti","NVIDIA RTX 2060ti","Operating System","RAM","Regarding GPUs, RVC is only compatible with NVIDIA. Learn below why.","REQUIREMENT","SPEC","Storage","The minimum specs vary depending if it's for training models or inference.","Windows 10"]},{"i":"can-i-use-it-on-my-intel-amd-gpu","l":"*Can I use it on my Intel/AMD GPU?*","p":["You can, but it's not recommended, as they aren't compatible with AI software.","Therefore RVC will be more prone to errors & rely on your CPU, slowing down the process significantly.","So it's more convenient using RVC through the cloud."]},{"i":"how-long-does-it-take-to-train","l":"*How long does it take to train?*","p":["The total time depends on a lot of factors, like dataset length, batch size, pretrains, specs, etc.","A 10 min dataset with RMVPE may take around 1 to 2 hours."]},{"i":"can-i-run-it-on-a-mac","l":"*Can I run it on a Mac?*","p":["Yes, on Macs of recent generations.","But you can only do inference& it's a little unstable."]},{"i":"do-i-need-internet-to-use-it","l":"*Do I need internet to use it?*","p":["If you're using RVC locally, no.","If you're using it through the cloud, then yes."]},{"i":"section-9","l":"‎"}],[{"l":"Applio","p":["Last update: Apr 01, 2024"]},{"i":"section","l":"‎","p":["Applio is a VITS-based Voice Conversion Tool developed by the IA Hispano team.","It's liked for its great UI& lots of extra features, such as TTS (with RVC models too), plugins, automatic model upload, customizable theme & more.","Because of its user-friendly experience & active development, it's considered to be one of the best forks.","It also has a cloud version, in case you don't meet the requirements to run it locally.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"*Learn more*","p":["Very complete","Has an active development","Currently stable","Very fast","TTS features","Automatic model upload","Has Mangio-Crepe","User-friendly UI","TensorBoard included","Extra features: (plugins, model fusion, etc)","Issues when downloading to external drives"]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎","p":["Make sure that you place Applio inside a folder on C drive.","Don't put it in a folder with privileged access.","Don't run the run-install.bat as an administrator.","Make sure the path does not contain any spaces or special characters.","Deactivate your antivirus and firewall to avoid missing dependencies.","The easiest way to download Applio is by going to Applio's Hugging Face repo, and clicking the [download] button on the right-hand side.","Unzip the folder. It may take a few minutes.","Open Applio's folder & execute run-applio.bat.","‎‎","A console tab will appear, and after a moment your default browser, with Applio ready to use.‎"]},{"i":"section-3","l":"‎"},{"i":"section-4","l":"‎","p":["If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-5","l":"‎"},{"i":"section-6","l":"‎"},{"i":"1-upload-voice-model","l":"1. Upload voice model.","p":["Go to the Download tab. You have two ways of uploading it: through its link or manually inputting its files.","Go to the Download tab & paste the link of the model in the Model Link bar. It must be from Hugging Face or Google Drive.‎‎","Press Download Model.","Drag & drop the model's .PTH in the Drop files box below.‎‎","Then drag the .INDEX.","‎"]},{"i":"2-select-voice-model","l":"2. Select voice model.","p":["Return to the Inference tab & click the Refresh button on the right.","‎","Select your model in the Voice Model dropdown."]},{"i":"section-7","l":"‎"},{"i":"3-input-vocals","l":"3. Input vocals.","p":["With Applio you can convert audios individually or in batches:","Drag & drop the audio or click the upload box to search it.‎‎","Then select it in the dropdown below.‎","Go to the Batch tab.‎","In the Input Folder bar, paste the path folder containing the audios.","In Output Folder you can paste a path folder for the results.","Ensure the paths don't contain spaces/special characters.","‎"]},{"i":"4-modify-settings-optional","l":"4. Modify settings. (optional)","p":["Unfold Advanced Settings if you wish to modify the inference settings for better results, or to determine the output folder.","‎"]},{"i":"section-8","l":"‎"},{"i":"5-convert","l":"5. Convert.","p":["Click Convert at the bottom. The audio will begin to process. The processing time will mainly depend on your specs, length of audio & the algorithm picked.","Once it's done, you can hear the results in the Export Audio box below.","By default the output files will be in the \" audios\" folder: \\ApplioV3.0.7\\assets\\audios"]},{"i":"section-9","l":"‎"},{"i":"section-10","l":"‎","p":["The training guide will be centered around using TensorBoard. Read about it first if you haven't already. If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-12","l":"‎"},{"l":"1. PREPROCESS","p":["Go to the Train tab. Input a name for your model in Model Name. Don't include spaces/special characters.","‎","Paste the path file of your dataset in the Dataset Path bar. Ensure the path doesn't contain spaces/special characters.","Select your dataset's sample rate. If you don't know the amount, click here.","Ensure RVC Version is set as V2& click Preprocess Dataset.","It'll finish when the output box says preprocessed successfully."]},{"l":"2. EXTRACT","p":["Select the algorithm you want. Use either Crepe or RMVPE, as the rest are outdated.","If you chose Crepe, you can modify its hop length.","Press Extract Features. It'll finish when it says extracted successfully."]},{"l":"3. TRAIN","p":["If you are a newbie, use 8. But in case your dataset is short (around 2 minutes or less), use 4.","Frequency of the saving checkpoints, based on the epochs.‎","If you are a newbie, simply leave it at 15.","‎‎‎","E.g: with a value of 10, they will be saved after the epoch 10, 20, 30, etc.","Input the total amount of epochs(training cycles) for the model.‎","But since we'll use TensorBoard, use an arbitrarily large value like 1000","‎","If you have multiple GPUs, tick GPU Settings to use a specific one for the training.","Click Generate Index. This will create the model's .INDEX file.","Press Start Training to begin the training process.‎","To open TB, execute run-tensorboard in Applio's folder. Remember to monitor it, as well as the console just in case.‎","The latter will show you errors if they happen, and information about the epochs & checkpoints."]},{"l":"4. FINAL STEP","p":["When you're very sure of overtraining, you can stop training by going to the Settings tab & press Restart Applio.","‎","Create a new folder anywhere named as the model.‎","Open Applio's folder, go to logs, and open the folder named as the model.‎","Select the .INDEX named added_& move it to your newly made folder.‎‎‎","In said folder you'll also find all the checkpoints.‎","Select the one closest to before the overtraining point, and move it to the new folder.","The checkpoints will be organized with this format: ModelName_Epoch_Step.pth Example: arianagrande_e60_s120.pth","‎‎","And that's all, have fun with your model. To test it, do a normal inference as usual."]},{"l":"5. RESUMING","p":["In case the training finished but the model still needed training, you don't have to start from scratch.‎","Simply enter the same settings & criteria that you've previously inserted. You don't have to do the preprocess or train the .INDEX again.‎","You can change the save frequency, or increase the Total Epoch amount in case you didn't input enough before.‎","Begin training again & remember to monitor TB & console like before."]},{"i":"section-45","l":"‎"},{"i":"section-46","l":"‎"},{"i":"section-47","l":"‎","p":["+ with any RVC model"]},{"i":"section-48","l":"‎","p":["Applio is also known for having one TTS tool by default, with plenty of voices to choose for.","You can also use it with RVC models& apply the inference settings if you wish.","Aditionally, you can download the Eleven Labs TTS plugin."]},{"i":"section-49","l":"‎"},{"i":"instructions","l":"Instructions:","p":["Go to the TTS tab.","‎"]},{"i":"section-50","l":"‎","p":["If you want to use an RVC model, download it, go to TTS, click Refresh& select it in Voice Model& Index File.","‎‎","To modify the inference settings or the output folder for the TTS/RVC audio, unfold Advanced Settings."]},{"i":"section-51","l":"‎","p":["In TTS Voices select the voice of your desired language, accent & gender.","In Text to Synthesize input your text. Then click Convert.","‎‎","If you are using an RVC model, select a voice that matches the model the most, to guarantee great results."]},{"i":"section-52","l":"‎","p":["Once it's done, you'll be able to hear the result in the Export Audio box. By default, the output audio will be in the \" audios\" folder. < \\ApplioV3.0.7\\assets\\audios>"]},{"i":"section-53","l":"‎"},{"i":"section-54","l":"‎"},{"i":"section-55","l":"‎","p":["Applio has an Extra menu, containing an audio analyzer, originally made by Ilaria.","Making it convenient for determining the sample rate of datasets when training models.","It also contains the model fusion tool, ideal for advanced users."]},{"i":"section-56","l":"‎"},{"i":"audio-analyzer","l":"Audio Analyzer:","p":["Go to the Extra tab & press the upload box to input your audio. Or simply drag & drop.","‎"]},{"i":"section-57","l":"‎","p":["Once it's done uploading, click Get information about the audio."]},{"i":"section-58","l":"‎","p":["In Sampling rate you'll see the audio's full sample rate. Use said value for training."]},{"i":"section-59","l":"‎","p":["If the frequencies don't reach the top of the spectrogram, see at which number peaks & multiply it by 2."]},{"i":"section-60","l":"‎","p":["‎‎","Here it reached 20 kHz. Doubling it gives 40kHz. Therefore the ideal target sample rate would be 40k"]},{"i":"section-61","l":"‎"},{"i":"section-62","l":"‎","p":["Plugins are components that you can add to Applio, that add new features & enhance your experience.","These are made by the public, and are free & easy to install.","You can find them on their GitHub page. More will be added in the future."]},{"i":"section-63","l":"‎"},{"i":"installation","l":"Installation:","p":["Access their GitHub page & click on the name of the plugin you want.","‎"]},{"i":"section-64","l":"‎","p":["Click on the ZIP file.","‎‎","Click on the download button on the right. This will download the ZIP file of the plugin."]},{"i":"section-65","l":"‎","p":["Open Applio & head over to the Plugins tab. Drag & drop the ZIP file to the upload box.","‎‎","You will be able to see its installation process in the console."]},{"i":"section-66","l":"‎","p":["Go to the settings tab & click Restart Applio at the bottom. Then you'll be able to see the plugin in the Plugins tab."]},{"i":"section-67","l":"‎"},{"i":"section-68","l":"‎"},{"i":"section-69","l":"‎"},{"i":"there-s-no-option-for-my-sample-rate","l":"*There's no option for my sample rate.*","p":["If it's lower than 32k: select 32k.‎","If it's 44.1k: select 40k.‎","If i'ts higher than 48k: select 48k."]},{"i":"the-voice-glitches-out","l":"*The voice glitches out.*","p":["This a phenomenon called artifacting. To fix it, read here."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-73","l":"‎"}],[{"l":"Mainline","p":["Last update: Mar 8, 2024"]},{"i":"section","l":"‎","p":["Mainline RVC is the base, original, & unmodified version of RVC. Made by the RVC-Project team.","It has less features compared to other forks, but still has the necessary tools to do a decent job.","It's specially liked because it's a little faster than other forks, as it's less bloated in a way.","Its actual name is not \"Mainline\", but it was given by the public to properly distinguish it from the other versions.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"unfold","l":"***Unfold***","p":["Easy to install.","Simpler to use.","A bit faster compared w/ other forks.","Has less features.","Doesn't include Mangio-Crepe.","Manual model upload."]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎","p":["Go to their download page here","Click the Download word. RVC will begin to download.‎‎","Once it's done, unzip the folder.","Open RVC's folder, find the \" go-web.bat\" file and execute it.‎‎ It will then open a console, & after a moment your default web browser with RVC ready to be used.‎‎‎‎","(Optional) To access RVC more easily, make a shortcut of the go-web file.‎"]},{"i":"section-3","l":"‎","p":["If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-4","l":"‎"},{"i":"1-upload-voice-model","l":"1. Upload voice model.","p":["Open RVC's folder, go to the assets folder and put your model's .PTH file inside the weights folder.‎‎","Return to the previous folder & put the model's .INDEX file in the logs folder."]},{"i":"section-5","l":"‎"},{"i":"2-select-voice-model","l":"2. Select voice model.","p":["In RVC, click the Refresh voice list and index path button.","‎","In its left, click Inferencing voice& select your model."]},{"i":"section-6","l":"‎"},{"i":"3-select-vocals","l":"3. Select vocals.","p":["In Enter the path of the audio file paste the path file of your audio. Ensure the path doesn't include spaces or special characters."]},{"i":"section-7","l":"‎"},{"i":"4-modify-settings-optional","l":"4. Modify settings. (optional)","p":["If you wish, modify the inference settings on display accordingly for better results."]},{"i":"section-8","l":"‎"},{"i":"5-convert","l":"5. Convert.","p":["Click the long Convert button at the bottom & it will begin to convert.","The processing time will mainly depend on your specs, length of audio, & the algorithm picked."]},{"i":"section-9","l":"‎"},{"i":"6-download-output","l":"6. Download output.","p":["Once it's done processing, a playable audio will pop up in the Export audio box. To download, click the three dots on the right & hit Download.","‎"]},{"i":"section-10","l":"‎","p":["The training guide will be centered around using TensorBoard. Read about it first if you haven't already.","If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-12","l":"‎"},{"i":"section-13","l":"‎"},{"i":"1-go-to-training-area","l":"1. Go to training area.","p":["Open RVC & head over to the Train tab."]},{"i":"section-14","l":"‎"},{"i":"2-name-the-model","l":"2. Name the model.","p":["In Enter the experiment name you insert a name for your model. Don't include special characters or spaces."]},{"i":"section-15","l":"‎"},{"i":"3-select-target-sample-rate","l":"3. Select Target Sample Rate.","p":["In Target sample rate select the number that matches your datasets' sample rate. Inputting an incorrect one might screw up the final quality."]},{"i":"section-16","l":"‎"},{"i":"section-17","l":"‎"},{"i":"4-select-dataset","l":"4. Select dataset.","p":["In Enter the path of the training folder paste the path file of your dataset. Ensure the path doesn't include special characters/spaces.","‎","If there's any text in the bar, delete it beforehand."]},{"i":"section-18","l":"‎"},{"i":"5-process-data","l":"5. Process data.","p":["Click the Process Data button on the center.","RVC will process the previous criteria for the training. But also the dataset file, which might take a moment depending on how big it is.","‎","It'll finish when the output box on the right says end preprocess."]},{"i":"section-19","l":"‎"},{"i":"section-20","l":"‎"},{"i":"6-select-gpus","l":"6. Select GPUs.","p":["In Enter the GPU index(es) determine which GPU(s) you'll use for training, by indicating the index followed by the dash (e.g: 0)."]},{"i":"section-21","l":"‎"},{"i":"7-select-pitch-extraction-algorithm","l":"7. Select pitch extraction algorithm.","p":["At the right select the Pitch extraction algorithm. Only use RMVPE_GPU or Crepe, as the rest are obsolete.","‎"]},{"i":"section-22","l":"‎","p":["Now click the Feature extraction button on the right.","‎‎‎ It'll finish when the output says all-feature-done."]},{"i":"section-23","l":"‎"},{"i":"8-create-index","l":"8. Create .INDEX.","p":["Press Train feature index at the bottom center. This will create the .INDEX file.","‎‎ It'll finish when the output box says something like this:"]},{"i":"section-24","l":"‎"},{"i":"section-25","l":"‎"},{"i":"9-select-save-frequency","l":"9. Select save frequency.","p":["Frequency of the saving checkpoints, based on the epochs.","If you are a newbie, simply leave it at 15.","E.g: with a value of 10, they will be saved after the epoch 10, 20, 30, etc.","‎"]},{"i":"section-26","l":"‎"},{"i":"10-input-epochs-amount","l":"10. Input epochs amount.","p":["In Total training epochs you determine the total amount of epochs(training cycles) for the model.","But since we'll use TensorBoard, use an arbitrarily large value like 2000."]},{"i":"section-27","l":"‎"},{"i":"11-select-batch-size","l":"11. Select batch size.","p":["Leave Batch size per GPU at 8 if you aren't familiar with it.","If your dataset is short (around 2 minutes or less), use 4 instead."]},{"i":"section-28","l":"‎"},{"i":"12-launch-tensorboard","l":"12. Launch TensorBoard.","p":["Now before you start training, open TB.","If you haven't already, start reading about it here here."]},{"i":"section-29","l":"‎"},{"i":"13-begin-training","l":"13. Begin training.","p":["Start training the model by clicking Train model.","‎‎‎ Remember to monitor TB, & also the console just in case. The latter will show you errors if they happen, and information about the epochs & checkpoints.‎"]},{"i":"section-30","l":"‎"},{"i":"14-stop-training","l":"14. Stop training.","p":["When you are very sure of overtraining, you can stop training by pressing the Stop training button where Train model used to be."]},{"i":"section-31","l":"‎"},{"i":"15-gather-models-files","l":"15. Gather model's files.","p":["Create a new folder anywhere named as your model.","Open RVC's folder, go to logs, and open the folder named with the model. Select the .INDEX named added_& move it to your newly made folder.","‎","Now go to the weights folder. Here you'll find the model's checkpoints.","Select the one closest to before the overtraining point, and move it to the new folder","These files will be organized with this format: ModelName_Epoch_Step.pth Example: kalomaze_e60_s120.pth","‎‎","And that's all. Have fun with your model. To test the model, do a normal inference as usual."]},{"i":"section-32","l":"‎"},{"i":"section-33","l":"‎","p":["If the training finished but the model still needed training, you don't have to start from scratch. Follow this procedure:","Simply enter the same settings and criteria that you previously inserted. Model name, sample rate, dataset, batch size, etc. You don't have to press Process Data or train the .INDEX again.","You can change the save frequency, or increase the epochs amount in case you didn't input enough before.","Begin training again & remember to monitor TB & console like before."]},{"i":"section-34","l":"‎"},{"i":"section-35","l":"‎"},{"i":"there-s-no-option-for-my-sample-rate","l":"*There's no option for my sample rate.*","p":["If it's lower than 32k: select 32k.‎","If it's 32k: on the right in Version, press v1& press v2 again. Ensure you leave it as v2. You should be able to see a 32k option now.‎","If it's 44.1k: select 40k.‎","If i'ts higher than 48k: select 48k."]},{"i":"the-voice-glitches-out","l":"*The voice glitches out.*","p":["This a phenomenon called artifacting. To fix it, read here."]},{"i":"i-don-t-see-the-stop-training-button","l":"*I don't see the Stop Training button.*","p":["This is a common bug. Close the console to stop RVC entirely."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-39","l":"‎"}],[{"l":"Mangio","p":["Last update: Mar 8, 2024"]},{"i":"section","l":"‎","p":["Mangio RVC is a fork of RVC, Mangio621, Kalomaze, & Alexolotl","Considered one of the best forks out there. Mainly because of it's extra features, inclusion of Mangio-Crepe, & its stability.","The project nowadays is a little abandoned, so don't expect many updates from the developers soon, unfortunately."]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"unfold","l":"***Unfold***","p":["Easy to install.","Includes Mangio-Crepe algorithm.","Nicer UI.","More features than Mainline.","Has hybrid training.","Lighter storage-wise if you install the inference)-only version.","A little slower than Mainline, since it's more bloated.","Will likely remain with no updates for a long time.","Manual model upload."]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎"},{"i":"section-3","l":"‎","p":["For exclusively inferencing, click here. For both inferencing & training, click here.","Once it's done downloading, unzip the folder.","Open RVC's folder, find the \" go-web.bat\" file and execute it.‎‎","‎ It will then open a console, & after a moment your default web browser with RVC ready to be used.‎‎‎","(Optional) To access RVC more easily, make a shortcut of the go-web file."]},{"i":"section-4","l":"‎"},{"i":"section-5","l":"‎","p":["If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-7","l":"‎"},{"i":"1-upload-voice-model","l":"1. Upload voice model.","p":["Open Mangio's folder & put your model's .PTH file inside the weights folder."]},{"i":"section-8","l":"‎","p":["Put the model's .INDEX file in the logs folder."]},{"i":"section-9","l":"‎"},{"i":"2-select-voice-model","l":"2. Select voice model.","p":["In RVC, click the upper Refresh voice list button.","‎","In its left, click Inferencing voice& select your model."]},{"i":"section-10","l":"‎"},{"i":"3-select-vocals","l":"3. Select vocals.","p":["In Specify path to an audio file paste the path file of your audio.","‎","If there are multiple audios in said path, click Select audio path from the dropdown& select the one you want."]},{"i":"section-11","l":"‎"},{"i":"4-modify-settings-optional","l":"4. Modify settings. (optional)","p":["If you wish, modify the inference settings on display accordingly for better results."]},{"i":"section-12","l":"‎"},{"i":"5-convert","l":"5. Convert.","p":["Click the long Convert button at the bottom & it will begin to convert.","The processing time will mainly depend on your specs, length of audio, & the algorithm picked."]},{"i":"section-13","l":"‎"},{"i":"6-locate-the-output","l":"6. Locate the output.","p":["Once it's done processing, a playable audio will pop up in the Export audio box. Your output audios will be located in Mangio's audio-outputs folder."]},{"i":"section-14","l":"‎"},{"i":"section-15","l":"‎","p":["The training guide will be centered around using TensorBoard. Read about it first if you haven't already.","If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-17","l":"‎"},{"i":"section-18","l":"‎"},{"i":"section-19","l":"‎"},{"i":"1-go-to-training-area","l":"1. Go to training area.","p":["Open RVC & head over to the Train tab."]},{"i":"section-20","l":"‎"},{"i":"2-name-the-model","l":"2. Name the model.","p":["In Enter the experiment name you insert a name for your model. Don't include special characters or spaces."]},{"i":"section-21","l":"‎"},{"i":"3-select-target-sample-rate","l":"3. Select Target Sample Rate.","p":["In Target sample rate select the number that matches your dataset's sample rate. Inputting an incorrect one might screw up the final quality."]},{"i":"section-22","l":"‎"},{"i":"section-23","l":"‎"},{"i":"4-select-dataset","l":"4. Select dataset.","p":["Open Mangio's folder, go to datasets folder & move your dataset there.","‎"]},{"i":"section-24","l":"‎"},{"i":"5-process-data","l":"5. Process data.","p":["Click the Process Data button on the center.","RVC will process the previous criteria for the training. But also the dataset file, which might take a moment depending on how big it is.","‎","It'll finish when the output box on the right says end preprocess."]},{"i":"section-25","l":"‎"},{"i":"6-select-gpus","l":"6. Select GPUs.","p":["In Enter the GPU index(es) determine which GPU(s) you'll use for training, by indicating the index followed by the dash (e.g: 0)."]},{"i":"section-26","l":"‎"},{"i":"7-select-pitch-extraction-algorithm","l":"7. Select pitch extraction algorithm.","p":["At the right select the Pitch extraction algorithm. Only use RMVPE, Crepe or Mangio-Crepe, as the rest are obsolete.","Now click the Feature extraction button on the right.","‎‎‎ It'll finish when the output says all-feature-done."]},{"i":"section-28","l":"‎"},{"i":"8-create-index-file","l":"8. Create .INDEX file.","p":["Now click the Train feature index button on the bottom. This will create the .INDEX file.","‎","It'll finish when the output box says Successful index Construction."]},{"i":"section-29","l":"‎"},{"i":"section-30","l":"‎"},{"i":"9-select-save-frequency","l":"9. Select save frequency.","p":["Frequency of the saving checkpoints, based on the epochs.","If you are a newbie, simply leave it at 15.","E.g: with a value of 10, they will be saved after the epoch 10, 20, 30, etc.‎"]},{"i":"section-31","l":"‎"},{"i":"10-input-epochs-amount","l":"10. Input epochs amount.","p":["In Total training epochs you determine the total amount of epochs(training cycles) for the model.","But since we'll use TensorBoard, use an arbitrarily large value like 2000."]},{"i":"section-32","l":"‎"},{"i":"11-select-batch-size","l":"11. Select batch size.","p":["Leave Batch size per GPU at 8 if you aren't familiar with it.","If your dataset is short (around 2 minutes or less), use 4 instead."]},{"i":"section-33","l":"‎"},{"i":"12-launch-tensorboard","l":"12. Launch TensorBoard.","p":["Now before you start training, open TB.","If you haven't already, start reading about it here here."]},{"i":"section-34","l":"‎"},{"i":"13-begin-training","l":"13. Begin training.","p":["Start training the model by clicking Train model.","‎‎","Remember to monitor TB, & also the console just in case. The latter will show you errors if they happen, and information about the epochs & checkpoints.happen.‎"]},{"i":"section-35","l":"‎"},{"i":"14-stop-training","l":"14. Stop training.","p":["When you are very sure of overtraining, you can stop training by pressing the Stop training button where Train model used to be."]},{"i":"section-36","l":"‎"},{"i":"15-gather-models-files","l":"15. Gather model's files.","p":["Create a new folder anywhere named as your model.","Open RVC's folder, go to logs, and open the folder named with the model. Select the .INDEX named added_& move it to your newly made folder.","‎","Now go to the weights folder. Here you'll find the model's checkpoints.","Select the one closest to before the overtraining point, and move it to the new folder","These files will be organized with this format: ModelName_Epoch_Step.pth","Example: kalomaze_e60_s120.pth","‎‎","And that's all. Have fun with your model. To test the model, do a normal inference as usual."]},{"i":"section-37","l":"‎"},{"i":"section-38","l":"‎","p":["If the training finished but the model still needed training, you don't have to start from scratch. Follow this procedure:","Simply enter the same settings and criteria that you previously inserted. Model name, sample rate, dataset, batch size, etc. You don't have to press Process Data or train the .INDEX again.","You can change the save frequency, or increase the epochs amount in case you didn't input enough before.","Begin training again & remember to monitor TB & console like before."]},{"i":"section-39","l":"‎"},{"i":"section-40","l":"‎"},{"i":"section-41","l":"‎"},{"i":"there-s-no-option-for-my-sample-rate","l":"*There's no option for my sample rate.*","p":["If it's lower than 32k: select 32k.‎","If it's 44.1k: select 40k.‎","If i'ts higher than 48k: select 48k."]},{"i":"the-voice-glitches-out","l":"*The voice glitches out.*","p":["This a phenomenon called artifacting. To fix it, read here."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-45","l":"‎"}],[{"l":"Ilaria RVC","p":["Last update: Mar 8, 2024‎"]},{"i":"section","l":"‎","p":["Ilaria RVC is a port of EasyGUI ( Mangio) to Google Colab. Made by Ilaria.","Works for inferencing only, has a pretty UI, huge speed, & the great tools that Mangio has (such as Mangio-Crepe algorithm).","And for this it's considered one of the best alternatives for doing inference through the cloud.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"***Learn more***","p":["Model download through links.","Two extra TTS tools.","Great UI.","Has Mangio-Crepe.","Doesn't take too long to load.","Very quick.","Usage limit for free users.","Takes 3 minutes to set up."]},{"i":"section-1","l":"‎","p":["If any issues arises, read the Troubleshooting chapter."]},{"i":"section-2","l":"‎"},{"i":"1-enter-the-space","l":"1. Enter the space.","p":["First log in to your Google account here.","Then access the Colab space."]},{"i":"section-3","l":"‎"},{"i":"2-set-up-space","l":"2. Set up space.","p":["Execute the Install Ilaria-RVC cell, by pressing the play button, then Run anyway.","Ilaria RVC will begin to set up.","‎ ‎ ‎‎‎","It'll finish when the cell says Done Cloning Repo.","‎‎","If red text appears showing errors, ignore it, it's normal."]},{"i":"section-4","l":"‎"},{"i":"3-open-gradio","l":"3. Open Gradio.","p":["Now execute the Start cell below.","After a bit it's going to show you two links. Open the gradio.live one in a separate tab.","‎","Otherwise you'll have to start again."]},{"i":"section-5","l":"‎"},{"i":"4-download-voice-model","l":"4. Download voice model.","p":["In the Gradio, go to the Download Voice Models tab.","Paste the link of the model in the Hugging Face Link bar. It must be a public link from either Hugging Face/ Google Drive.","In Name of the model, insert a name for it. Don't include spaces/special characters.","Then click Download."]},{"i":"section-6","l":"‎"},{"i":"5-select-model","l":"5. Select model.","p":["Return to the Inference tab & click the upper pink Refresh button.","Unfold the Choose the model dropdown & select your model."]},{"i":"section-7","l":"‎"},{"i":"6-select-your-audio","l":"6. Select your audio.","p":["Below it, in Drag your audio file and click refresh, click it to load your audio manually. Or just drag the file into it."]},{"i":"section-8","l":"‎"},{"i":"7-adjust-settings-optional","l":"7. Adjust settings. (optional)","p":["If you wish, you can modify the inference settings in Index Settings& Advanced Options for better results. Tap them to unfold.","‎‎"]},{"i":"section-9","l":"‎"},{"i":"8-convert","l":"8. Convert.","p":["Click the upper Convert button & wait for the inference to finish."]},{"i":"section-10","l":"‎"},{"i":"9-download-output","l":"9. Download output.","p":["Once it's done processing, there will be a playable audio in the Final Result! box.","Tap the three buttons on the right of the audio and then Download.","‎‎","‎","First access the Gradio. If you don't know how, follow the first three steps of the previous chapter.","Go to the IlariaTTS section.","If you want, you can use the other ElevenLabs / Google TTS.","In Voice pick a voice of the gender, language & accent that you wish. Under it, insert the text.","If you're going to use an RVC model, pick one that sounds similar to it.","Press Speak. The TTS will begin to process.","Once it's done processing, there will be a playable audio in the Final Result! box. At the right press the three dots & then Download.","To use an RVC model, simply upload the output to Ilaria RVC & convert it using your model. (Optional) If you don't know, learn here."]},{"i":"section-12","l":"‎"},{"i":"section-13","l":"‎"},{"i":"section-14","l":"‎"},{"i":"i-get-a-red-error-message","l":"*I get a red `Error` message.*","p":["It's normal. Try repeating your action.‎","If it persists, reload the Gradio page.‎","Ensure your audio is selected in the Choose the audio file. If it's not in the list, click Refresh on its right & select it.‎","If it's still persisting, restart the Colab space:","Go to the Colab space and press the downward arrow ( ) at the top.","Click Disconnect and delete all data.","Reload the page and load RVC again."]},{"i":"my-model-doesn-t-have-a-link-from-hf-gd","l":"*My model doesn't have a link from HF/GD.*","p":["You'll have to create the link yourself. Learn how here."]},{"i":"i-can-t-download-my-model","l":"*I can't download my model.*","p":["This could be due to a few reasons:","Link is private:","If it's from GD, ensure the General access is set as Anyone with the link.","If it's from HF, ensure the repo is set as Public. Learn more here.‎","Invalid HF link:","The HF link must contain the word \".zip\".","If it contains the word blob, replace it for resolve& paste it.‎","Incorrect files:","The model must be zipped in a .ZIP file. Not .RAR or .7ZIP.","It must contain its correct .PTH & .INDEX files. Learn more here."]},{"i":"the-voice-glitches-out","l":"*The voice glitches out.*","p":["This is an anomaly called \" artifacting\". Learn how to fix it here."]},{"i":"cannot-connect-to-gpu-backend","l":"*Cannot connect to GPU backend.*","p":["You have exhausted the GPU runtime of Colab."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-21","l":"‎"}],[{"l":"Applio Colab","p":["Last update: Apr 01, 2024"]},{"i":"section","l":"‎","p":["Applio is a VITS-based Voice Conversion Tool developed by the IA Hispano team.","It's liked for its great UI& lots of extra features, such as TTS (with RVC models too), plugins, automatic model upload, customizable theme & more.","Because of its user-friendly experience & active development, it's considered to be one of the best forks.","As this cloud version is hosted in Google Colab, remember that you have a runtime of 4 hours.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"*Learn more*","p":["Very complete","Has an active development","Currently stable","Very fast","TTS features","Automatic model upload","Has Mangio-Crepe","User-friendly UI","TensorBoard included","Extra features: (plugins, model fusion, etc)","Usage limit for free users"]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎","p":["Access the Colab space here. Then log in to your Google account."]},{"i":"section-3","l":"‎","p":["Execute the Install Applio cell. This will take around 2 minutes.","‎‎","It'll finish when you see a tick symbol on the left."]},{"i":"section-4","l":"‎","p":["If you are going to train models, upload your dataset to your Google Drive storage & run the Extra cell.","‎‎","To save time, unfold it & cancel the custom pretrain download, if you aren't going to use them."]},{"i":"section-5","l":"‎","p":["Grant the permissions to Google Drive.‎‎"]},{"i":"section-6","l":"‎","p":["Execute Start Applio.","‎‎","Then open the public URL."]},{"i":"section-7","l":"‎","p":["Be sure to read the Troubleshooting chapter if any issue arises."]},{"i":"section-8","l":"‎"},{"i":"1-upload-voice-model","l":"1. Upload voice model.","p":["Go to the Download tab. You have two ways of uploading it: through its link or manually inputting its files.","Go to the Download tab & paste the link in the Model Link bar. It must be from Hugging Face or Google Drive.‎‎","Press Download Model.","Below in Drop files, press the upload box & input the model's .PTH.‎‎","Then input the .INDEX.","‎"]},{"i":"2-select-voice-model","l":"2. Select voice model.","p":["Return to the Inference tab & click Refresh on the right.","‎","Select the model in the Voice Model& Index File dropdown."]},{"i":"section-9","l":"‎"},{"i":"3-input-vocals","l":"3. Input vocals.","p":["With Applio you can convert audios individually or in batches:","Press the upload box & input your audio.‎‎‎‎","Then select it in the dropdown below.‎","Go to the Batch tab.‎‎‎","Go to the file explorer in Colab. Go to drive, right-click the folder containing the audios & click Copy Path.","Paste the path in the Input Folder bar.","In Output Folder you can define the path folder for the results.","Ensure the paths don't contain spaces/special characters.","‎"]},{"i":"4-modify-settings-optional","l":"4. Modify settings. (optional)","p":["Unfold Advanced Settings if you wish to modify the inference settings for better results.","‎"]},{"i":"section-10","l":"‎"},{"i":"5-convert","l":"5. Convert.","p":["Click Convert at the bottom to process the audio.","Once it's done, you can hear the results in the Export Audio box below. To download it, press the download symbol on its right.","‎"]},{"i":"section-11","l":"‎"},{"i":"section-12","l":"‎"},{"l":"1. PREPROCESS","p":["Go to the Train tab. Input a name for your model in Model Name. Don't include spaces/special characters.","‎","Upload your dataset to your GD storage if you haven't already.‎","In Colab click the folder on the left ( ) & click the reload button.‎‎‎(For mobile users: tap the three lines on the top left & Show file browser)‎","Open drive, localize your dataset, right-click it & click Copy path.‎‎‎‎","Then paste it on the Dataset Path bar.‎‎","Select your dataset's sample rate. If you don't know the amount, click here.","Ensure RVC Version is set as V2& click Preprocess Dataset.","It'll finish when the output box says preprocessed successfully."]},{"l":"2. EXTRACT","p":["Select the algorithm you want. Use either Crepe or RMVPE, as the rest are outdated.","If you chose Crepe, you can modify its hop length.","Press Extract Features. It'll finish when it says extracted successfully."]},{"l":"3. TRAIN","p":["‎‎‎","‎","But since we'll use TensorBoard, use an arbitrarily large value like 1000","Click Generate Index. This will create the model's .INDEX file.","Disconnect from your Internet.","Don't solve the captchas that (might) pop up occasionally.","E.g: with a value of 10, they will be saved after the epoch 10, 20, 30, etc.","Frequency of the saving checkpoints, based on the epochs.‎","If after around 2:30 hours of training you don't detect OT download the model of the lowest point, in case it's already OT, and the .INDEX.‎","If you are a newbie, simply leave it at 15.","If you are a newbie, use 8. But in case your dataset is short (around 2 minutes or less), use 4.","Input the total amount of epochs(training cycles) for the model.‎","Press Start Training below to begin the training process.‎‎","Run out of GPU runtime.","Stay AFK for a long time.","TB will be available in the Colab. Remember to monitor it, as well as the cell's logs just in case.","The latter will show you errors if they happen, and information about the epochs & checkpoints.‎‎‎‎","Then once your GPU runtime resets, begin the retraining procedure.","Tick Save Only Latest"]},{"l":"4. DOWNLOAD","p":["When you're very sure of overtraining, you can stop training by going to the Settings tab & press Restart Applio.","‎‎","Come back to the Colab & open the new public URL.","Open the file explorer, go to logs, and open the folder named as the model.‎","Download the .INDEX named added_.‎‎‎","In said folder you'll also find all the checkpoints.‎","Select the one closest to before the overtraining point, and move it to the new folder.","The checkpoints will be organized with this format: ModelName_Epoch.pth Example: arianagrande_60e.pth‎‎‎‎","You can determine the Step number of the checkpoints by looking at its epoch number on the logs.","‎‎‎","And that's all, have fun with your model. To test it, do a normal inference as usual."]},{"l":"5. RESUMING","p":["In case the training finished but the model still needed training, you don't have to start from scratch.","Simply enter the same settings & criteria that you had previously inserted. You don't have to do preprocess, extract feature or train the .INDEX again.‎","You can change the save frequency or increase the Total Epoch amount, in case you didn't input enough before.‎","If you're resuming from a new session, unfold the Extra cell in Colab & input the model name you assigned before.‎‎‎","For this, the Auto Backup cell must've ran in the previous session.‎‎","Begin training again & remember to monitor TB as before."]},{"i":"section-47","l":"‎"},{"i":"section-48","l":"‎","p":["+ with any RVC model"]},{"i":"section-49","l":"‎","p":["Applio is also known for having one TTS tool by default, with plenty of voices to choose for.","You can also use it with RVC models& apply the inference settings if you wish.","Additionally, you can download the Eleven Labs TTS plugin."]},{"i":"section-50","l":"‎"},{"i":"instructions","l":"Instructions:","p":["Go to the TTS tab.","‎"]},{"i":"section-51","l":"‎","p":["If you want to use an RVC model, download it, go to TTS, click Refresh& select it in Voice Model& Index File.","‎‎","To modify the inference settings or the output folder for the TTS/RVC audio, unfold Advanced Settings."]},{"i":"section-52","l":"‎","p":["In TTS Voices select the voice of your desired language, accent & gender.","In Text to Synthesize input your text. Then click Convert.","‎‎","If you are using an RVC model, select a voice that matches the model the most, to guarantee great results."]},{"i":"section-53","l":"‎","p":["Once it's done, you'll be able to hear the result in the Export Audio box. To download it, click the download button on its right ( )."]},{"i":"section-54","l":"‎"},{"i":"section-55","l":"‎"},{"i":"section-56","l":"‎","p":["Applio has an Extra menu, containing an audio analyzer, originally made by Ilaria.","Making it convenient for determining the sample rate of datasets when training models.","It also contains the model fusion tool, ideal for advanced users."]},{"i":"section-57","l":"‎"},{"i":"audio-analyzer","l":"Audio Analyzer:","p":["Go to the Extra tab & press the upload box to input your audio.","‎"]},{"i":"section-58","l":"‎","p":["Once it's done uploading, click Get information about the audio."]},{"i":"section-59","l":"‎","p":["In Sampling rate you'll see the audio's full sample rate. Use said value for training."]},{"i":"section-60","l":"‎","p":["If the frequencies don't reach the top of the spectrogram, see at which number peaks & multiply it by 2."]},{"i":"section-61","l":"‎","p":["‎‎","Here it reached 20 kHz. Doubling it gives 40kHz. Therefore the ideal target sample rate would be 40k"]},{"i":"section-62","l":"‎"},{"i":"section-63","l":"‎","p":["Plugins are components that you can add to Applio, that add new features & enhance your experience.","These are made by the public, and are free & easy to install.","You can find them on their GitHub page. More will be added in the future."]},{"i":"section-64","l":"‎"},{"i":"installation","l":"Installation:","p":["Access their GitHub page & click on the name of the plugin you want.","‎"]},{"i":"section-65","l":"‎","p":["Click on the ZIP file.","‎‎","Click on the download button on the right. This will download the ZIP file of the plugin."]},{"i":"section-66","l":"‎","p":["Open Applio & head over to the Plugins tab. Press the upload box & upload the ZIP."]},{"i":"section-67","l":"‎","p":["Go to the Settings tab & click Restart Applio at the bottom. Go back to the Colab & open the new public URL.","Then you'll be able to see the plugin in the Plugins tab."]},{"i":"section-68","l":"‎"},{"i":"section-69","l":"‎"},{"i":"section-70","l":"‎"},{"i":"there-s-no-option-for-my-sample-rate","l":"*There's no option for my sample rate.*","p":["If it's lower than 32k: select 32k.‎","If it's 44.1k: select 40k.‎","If i'ts higher than 48k: select 48k."]},{"i":"the-voice-glitches-out","l":"*The voice glitches out.*","p":["This a phenomenon called artifacting. To fix it, read here."]},{"i":"cannot-connect-to-gpu-backend","l":"*Cannot connect to GPU backend.*","p":["You have exhausted the GPU runtime of Colab."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-75","l":"‎"}],[{"l":"RVC Disconnected","p":["Last update: Mar 8, 2024"]},{"i":"section","l":"‎"},{"i":"section-1","l":"‎","p":["RVC Disconnected (or RVC-D) is a port of Mangio to Google Colab, for exclusively training. Notebook made by Kit Lemonfoot.","It's free, includes all the necessary tools for a quality model, the TensorBoard, & it's the fastest Colab space for training.","Making it the go-to method for training for cloud RVC users. Pretty much the only big downside is the time limit (but you can switch to another account & continue).‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"***Learn more***","p":["Has TensorBoard.","Has Mangio-Crepe.","Option to save model to HF.","Includes the latest pretrains.","Inconvenient I.","Takes some time to set up.","You can't leave training unsupervised.","For free users:","It's slower compared to local RVC.","Can't train long datasets without pausing the process."]},{"i":"section-2","l":"‎","p":["1.‎ The guide is centered around the TensorBoard. Read it first if you haven't already. 2. Turn on third-party cookies, or TB might not work."]},{"i":"section-4","l":"‎"},{"l":"1. Prepare dataset","p":["Make a folder named after your model & move the dataset inside of it. Don't include spaces/special characters.","‎‎","Then zip the folder as a .ZIP file. .7ZIP and .RAR aren't compatible with RVC-D.","REMINDER: With modern versions of RVC, the dataset can be a single audio file. No need to split it."]},{"i":"section-5","l":"‎"},{"l":"2. Set up Colab","p":["Head over to the Colab space& Sign in to your Google account.","Execute the Dependencies cell & press Run anyways","‎‎","When this appears, press Connect to Google Drive& select your account.","Once the cell is done loading, in GD go to the rvcDisconnected folder, and place the dataset's .ZIP inside of it.","‎"]},{"i":"section-6","l":"‎"},{"i":"section-7","l":"‎"},{"i":"section-8","l":"‎"},{"l":"1. Training variables","p":["Go to the Set Training Variables cell.","‎‎","Name your model. Don't include spaces/special characters.","If you aren't familiar with pretrains, select original.","Select your dataset's sample rate.","The extraction method. Don't use Harvest, as it's obsolete.","If you chose Mangio-Crepe, this defines the Hop Length."]},{"i":"section-9","l":"‎"},{"l":"2. Set the environment","p":["‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎‎","Go to Load Dataset cell. In the dataset bar type the dataset's .ZIP name followed by .zip, then execute the cell. Example: kalomaze.zip","Below, execute Preprocessing, Feature Extraction, & Save preprocessed dataset files to Google Drive.","‎"]},{"i":"section-10","l":"‎"},{"l":"3. Train Index","p":["Run Index Training to create the model's .INDEX file.","‎‎","To download it, in GD open rvcDisconnected& the folder named after the model. Download the .INDEX named added.","‎"]},{"i":"section-11","l":"‎"},{"l":"4. Set Training","p":["Go to the Training cell.","‎‎","Frequency of the saving checkpoints, based on the epochs. If you're a newbie, simply leave it at 15. E.g: with a value of 10, it will be saved after the epoch 10, 20, 30, etc.","The total amount of epochs for the model. But since we'll use TensorBoard, use an arbitrarily large number like 2000.","Use 8 if you are a newbie. But if your dataset is small (around 2 minutes or less), use 4."]},{"i":"section-12","l":"‎"},{"l":"5. Begin training","p":["Execute the Training cell to begin training. TB will open up after a few seconds, & the graphs will take a minute to appear.‎","Remember to monitor it, as well as the cell's logs. The latter will show you errors if they happen, and information about the epochs & checkpoints.‎","While training, you might get disconnected if you:","Stay AFK for a long time.","Disconnect from your Internet.","Don't solve the captchas that (might) pop up occasionally.","Run out of GPU runtime."]},{"i":"section-13","l":"‎"},{"l":"6. Export model","p":["If after around 2:30 hours of training you don't detect overtraining, you must save the files so you can resume later, before the GPU runtime ends.","For this, first download the model of the lowest point ( Step 7b) in case you are already overtraining.","Stop training by pressing the stop button of the Training cell.","Run the Export Model from Notebook to Drive cell.","‎‎","Once your GPU runtime resets, begin the retraining procedure.","After exporting, you are free to resume training until runtime is exhausted or close the session."]},{"i":"section-14","l":"‎"},{"i":"7-download-model","l":"7. Download model.","p":["When you're very sure of overtraining, you can stop training by pressing the stop button of the Training cell.","Click the folder symbol on the left.(For mobile users: tap the three lines on the top left & Show file browser)","Open the Mangio-RVC-Fork folder, then weights. You'll find the checkpoints.","‎‎","Right-click the one that's closest to before the overtraining point, and press Download.","The models will be organized with this format: Name_Epoch_Step.pth. E.g: arianagrande_e60_s120.pth‎","And that's all. To test it, do a normal inference as usual."]},{"i":"section-17","l":"‎","p":["If the training stops but the model still needed training, you don't have to start from scratch.","You can resume from the latest checkpoint. But for this, the cell Save preprocessed dataset files to Google Drive must have executed prior to training.","And if you're resuming from a new session, you should've ran the Export Model from Notebook to Drive cell in the previous session."]},{"i":"section-18","l":"‎"},{"i":"instructions","l":"Instructions:","p":["Go to the Colab space, input the same criteria as before & execute the cells like normal, except Preprocessing & Feature Extraction.","Execute the Load preprocessed dataset files cell.","‎","Go to the Import Model from Drive to Notebook cell. In STEPCOUNT introduce 2333333& execute it.","You can change the save frequency or increase the total epochs, in case you didn't input enough before.","Run the Training cell to retrain. Remember to monitor TB as before."]},{"i":"section-19","l":"‎"}],[{"l":"AICoverGen","p":["Last update: Mar 4, 2024‎"]},{"i":"section","l":"‎","p":["The AICoverGen Colabs are a port of the AICoverGen RVC fork to Google Colab.","These are ideal for users who want ' quick & dirty' AI covers, as the whole process of inputting audio, vocal isolation & song mixing is automated.","The pitch control is limiting & inconvenient, so if you want a Colab with more control over it, use Ilaria RVC instead."]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎"},{"l":"Description","p":["This is the version of the port that doesn't have the premade user interface. Credits to Eddy & Raid. Base notebook by Ardha27.","It's an upgrade from the original Colab space, bringing bug fixes, improvements, & extra features.","The NO UI counterpart is mainly preferred due to being more stable compared with the UI version.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"*Learn more*","p":["Automatic vocal extraction.","Song mixing tool.","Has Mangio-Crepe.","Automatic model upload.","Input audio with YouTube links.","Can get the stems files.","More stable.","Usage limit for free users.","Takes 6 mins to load.","UI is incovenient.","No control over the stem separation.","The extraction will always run, you'll waste time if you input clean vocals.","Little control of the mixing tools.","Limited pitch control."]},{"i":"section-3","l":"‎"},{"l":"Setting Up"},{"l":"1. Enter the space","p":["Access the Colab space here. Then Sign in to your Google account."]},{"i":"section-4","l":"‎"},{"l":"2. Clone and Install","p":["Execute the Clone and Install. This will install RVC.","‎‎","It will take around 15 minutes. It'll be done when you see a check symbol (✔️) on the corner.","Don't worry if red text appears, it's normal."]},{"i":"section-5","l":"‎"},{"l":"Inference"},{"l":"1. Download model","p":["Go to Model Download Function cell. Paste the model's link in the url bar.","In dir_name name the model. Don't include spaces/special characters.","Then execute the cell.","‎","Downloaded models will be saved until the Colab session ends."]},{"i":"section-6","l":"‎"},{"l":"2. Input the audio","p":["Input the vocals/song in the Generate Cover cell.","You can go about it with either a YouTube link or a Google Drive file:","Copy a YouTube link and paste it in the SONG_INPUT bar.","‎","Execute the Mount Drive cell below.‎‎","Click Connect to Google Drive& select your Account.‎","Click the folder symbol ( ) on the left.(For mobile users: tap the three lines on the top left & Show file browser)","Go to drive& you'll find your GD storage. Right-click your audio & press Copy path.‎","Paste the path in the SONG_INPUT bar.‎"]},{"i":"section-10","l":"‎"},{"l":"3. Select model","p":["In RVC_DIRNAME insert the model's name you assigned before."]},{"i":"section-11","l":"‎"},{"i":"4-modify-settings-optional","l":"4. Modify settings (optional)","p":["Below RVC_DIRNAME until Audio Mixing Options you'll find the inference settings. Tweak them accordingly for better results if you wish.","‎"]},{"i":"section-12","l":"‎"},{"i":"5-modify-mix--reverb-optional","l":"5. Modify mix & reverb (optional)","p":["In Audio Mixing Options you can modify the values to define the volume of main/backing vocals & instrumental.","‎‎","In Reverb Control you can add reverb to the output vocals.‎‎‎"]},{"i":"reverb-control-options","l":"*Reverb Control options:*","p":["How \"wide\" the reverb sounds, like the size of a room.","Volume of the reverb itself.","Volume of the vocals.","Level of absorption of the reverb's high frequencies:","Higher values yield a warmer, natural-sounding reverb.","Lower ones sound brighter & more present."]},{"i":"section-13","l":"‎"},{"l":"6. Begin inferring","p":["Execute the Generate Cover cell to begin the conversion.","It'll be done when the logs say Cover generated at followed by the file path."]},{"i":"section-14","l":"‎"},{"l":"7. Download output","p":["Click the folder symbol ( ) on the left.(For mobile users: tap the three lines on the top left & Show file browser)","Open song_output folder & the one inside it. Right-click the first file & press Download. The other audios are the stems. Download them too if you wish.","‎"]},{"i":"section-15","l":"‎"},{"i":"section-16","l":"‎"},{"i":"section-17","l":"‎"},{"l":"Description","p":["This is the version that's built with the premade user interface. Port by Hina. Original repo by SociallyIneptWeeb.","It's characterized & preferred due to its intuitive UI, ideal for beginners.","But on the downside, it may be more buggy, so consider using the NO UI version if issues arise.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"*Learn more*","p":["Automatic vocal extraction.","Song mixing tool.","Has Mangio-Crepe.","Automatic model upload.","Input audio with YouTube links","Great UI.","Can get the stems files.","Quicker audio file upload.","Usage limit for free users.","Takes 6 mins to load.","No control over the stem separation.","The extraction will always run, you'll waste time if you input clean vocals.","Little control of the mixing tools.","Inconvenient pitch control.","More unstable."]},{"i":"section-18","l":"‎"},{"l":"Setting Up"},{"i":"1-enter-the-space-1","l":"1. Enter the space","p":["Access the Colab space here.","Then login to your Google account."]},{"i":"section-19","l":"‎"},{"l":"2. Define pitch","p":["In the Clone Repository cell, select the pitch change.","‎‎","If you're going to use models of the same gender as the vocals, use 1.","If they're of opposite gender, use 12","To change this, you'll have to start the Colab from scratch."]},{"i":"section-20","l":"‎"},{"l":"3. Run cells","p":["Then go to Runtime on top & press Run all."]},{"i":"section-21","l":"‎"},{"l":"4. Open UI","p":["After a moment the Run WebUI cell will show two links. Open the public URL one.","‎"]},{"i":"section-22","l":"‎"},{"l":"Inference"},{"l":"1. Upload model","p":["You can upload it using its link or manually inputting its files.","Go to the Download model tab & paste the model link in the bar.","Name it in Name your model. Don't introduce spaces/special characters.","Click Download.","Zip the model into a .ZIP file, if you haven't already.","Go to the Upload model tab, press the upload box & submit the ZIP.","Name it in Model name. Don't introduce spaces/special characters.","Press Upload model."]},{"i":"section-23","l":"‎"},{"l":"2. Select model","p":["Return to the Generate tab & press Refresh Models. Then select it in the Voice Models dropdown."]},{"i":"section-24","l":"‎"},{"l":"3. Select audio","p":["On its right, input the YouTube link.","‎‎","Or, press Upload file instead, click Upload& input the audio file."]},{"i":"section-25","l":"‎"},{"i":"4-modify-settings-optional-1","l":"4. Modify settings (optional)","p":["Unfold Voice conversion options to modify the inference settings for better results."]},{"i":"section-26","l":"‎"},{"l":"5. Select output format","p":["Unfold Audio mixing options& set Output file type as wav, for a better quality output.","‎‎","Modify the mix too if you wish."]},{"i":"section-27","l":"‎"},{"l":"6. Convert","p":["Press Generate. The audio will begin processing.","Once it's done, you can hear the results in the AI Cover output box.","To download it, press the download symbol ( ) on its right."]},{"i":"section-28","l":"‎"},{"i":"7-download-stems-optional","l":"7. Download stems (optional)","p":["To download the stems, go to Colab & click the folder symbol ( ) on the left.(For mobile users, tap the three lines ( ) on the top left & Show File Explorer)","Go to Hina_RVC, song_output, open the new folder, right-click the stem you wish & click Download.","‎‎"]},{"i":"section-29","l":"‎"}],[{"l":"Paperspace","p":["Last update: Feb 10, 2024"]},{"i":"section","l":"‎"},{"l":"Introduction","p":["Paperspace is a cloud-based platform for using AI apps, powered by virtual machines with powerful GPU's.","It's a great alternative for training RVC voice models through the cloud, since it's even faster than Google Colab.","Making this platform one of the most competent counterparts to Colab, if you don't mind paying a monthly subscription."]},{"i":"section-1","l":"‎"},{"l":"Important Notes","p":["Although Paperspace has a free plan, you can't do much with it, it's more convenient to buy its Pro or Growth plan.","There have been people who had to try a couple of times before Paperspace accepted their card. Be patient if that happens to you.","Aditionally, you can pay hourly for faster GPU's instead of using the free ones by default. This is optional, the paid plans are fast enough."]},{"i":"section-2","l":"‎"},{"l":"How to Use"},{"i":"section-3","l":"‎"},{"i":"1-set-up-account","l":"1. Set up account.","p":["Start by making an account here.","Buy a plan in the Platform Plans section on the right here."]},{"i":"section-4","l":"‎"},{"i":"2-create-notebook","l":"2. Create notebook.","p":["Make sure you are in the Gradient tab, and click the CREATE button."]},{"i":"section-5","l":"‎","p":["Make sure there are free GPU's available, and below select the number of hours you want the notebook to remain active."]},{"i":"section-6","l":"‎","p":["Then click START NOTEBOOK. You'll find yourself in a screen like this:"]},{"i":"section-7","l":"‎"},{"i":"3-install-mangio","l":"3. Install Mangio.","p":["Copy this, paste it in the Terminal and hit enter:","‎","Once it's done installing, open the paper.ipynb file.","‎‎","Execute the INSTALL EVERYTHING cell.","Once that one is done, execute the START GUI one. Then you can start using Mangio.","‎‎‎","1. To create the dataset folder, open the notebook, right click the Mangio-RVC-Fork folder, click New folder, name it dataset, and put your dataset there.‎ 2. If you get an error when you click Process data, don't worry, it's a visual glitch. Keep working as usual."]},{"l":"Opening TensorBoard","p":["To run TensorBoard while using RVC you'll have to do it on a separate terminal.","Go to your notebook and open a new terminal by clicking the Terminal symbol ( ) on the right.","Then introduce this:"]},{"i":"section-8","l":"‎"},{"i":"section-9","l":"‎","p":["‎‎\"The main difference lies in the model training process, as the GPUs available on Paperspace are more powerful. ‎ You can achieve training speeds that are approximately 3 times faster compared to Colab, which translates to saving a significant amount of time. ‎ So, if you were to train a model with a dataset that takes around an hour and a half (1:30) on Paperspace, it would take approximately three and a half hours (3:30). ‎ On the other hand, on Colab, it might take around 7 hours (without considering the account switching).\"","- Picture quote by LollenApe","‎‎"]},{"i":"section-11","l":"‎"}],[{"i":"epochs--tensorboard","l":"Epochs & TensorBoard","p":["Last update: Feb 10, 2024"]},{"i":"section","l":"‎","p":["\"Epoch\" is a unit of measuring the training cycles of an AI model.","In other words, the amount of times the model went over its dataset and learned from it."]},{"i":"section-1","l":"‎"},{"i":"how-many-epochs-should-i-use-for-my-dataset","l":"How many epochs should I use for my dataset?","p":["There isn't a way to know the right amount previous to training. It depends on the size, length & quality of the dataset.","If you aim towards a quality model, it's not convenient to input a semi-arbitrary amount of epochs, as it makes it prone to underfitting/overtraining. (explained later)","So it's best to use TensorBoard. WIth it you can determine exactly for how long you should train. (explained later)"]},{"i":"section-2","l":"‎"},{"i":"do-more-epochs-equal-a-better-model","l":"Do more epochs equal a better model?","p":["It doesn't, since using a disproportionate amount will overtrain the model, which will affect the quality of it."]},{"i":"section-3","l":"‎"},{"i":"section-4","l":"‎","p":["In the field of AI, is when an AI model learns its dataset too well, to the point where it centers too much around it & starts replicating undesired data.","The model performs very well with data of the dataset, but poorly with new data, as it has lost its ability to replicate anything that deviates from it.","It happens when the model is trained for too long/is too complex. So to avoid this, RVC users use a tool called TensorBoard."]},{"i":"section-6","l":"‎","p":["TensorBoard is a tool that allows you to visualize & measure the training of an AI model, through graphs & metrics.","It's specially useful for determining when to stop training a voice model, since with it you can detect when the overtraining point begins.","Because of this, TB is the most convenient tool for RVC users for perfecting a voice model."]},{"i":"section-7","l":"‎"},{"i":"installing-opening","l":"Installing & Opening","p":["For RVC Disconnected users, ignore this, it opens up by itself when you start training."]},{"i":"section-8","l":"‎","p":["Download this file & move it inside RVC's folder. Ensure the file path doesn't contain spaces/special characters.","Epochs & TensorBoard"]},{"i":"section-9","l":"‎","p":["Now execute it. It will open a console window & create some folders inside RVC.","If you get the Windows protected your PC issue, click More info& Run anyway.‎","Once it's done, your default browser should open with TensorBoard app.‎","If it doesn't, copy the address of the console at the bottom, and paste it in your browser. Said address will say \" https://localhost\" followed by some numbers.‎"]},{"i":"section-10","l":"‎"},{"l":"Usage Guide","p":["‎‎","‎","‎~ Work in progress.~","Activate Ignore outliers in chart scaling.","And the right one is to center the view.‎‎‎","Click the gear () in the top left corner & turn on Reload data. You can always manually refresh with the refresh symbol (\uD83D\uDD04) in the top right.","Each graph has three buttons in the corner:","First ensure auto-refresh is on, so the graphs update constantly.","Go to the SCALARS tab.‎‎","If it reaches a low point, let it run for longer until it's very clear it's OT.","If you get the No dashboards are active issue, select SCALARS in the top right corner dropdown.","In the search bar, type \" g/total\". This will be the graph you'll monitor.‎‎‎‎","Left one is for going fullscreen.","Middle one to disable Y axis, for a fuller view.","Now let the training go for some time.","Open TB & begin training in RVC.","Select your model in the Runs section below. The models you tick will show in the graphs. (untick /eval if you want)‎‎‎","Set Smoothing to 0.987.","There will be various low points, one after the other, so don't get too anxious if it's OT or not. You can always use a previous checkpoint either way.","To zoom in & out the graphs, press the ALT key + mouse wheel. Remember to center the view after moving around, and after the graph updates.","Use the model that was closest to before the OT point. For more information, check the guide for your RVC in this website.","When you detect OT, zoom in & place your mouse over the lowest point. Note down the Step number.","You'll detect OT(overtraining) when the graph hits the lowest point, then stay flat/ rising indefinitely.‎ Example of OT for hours:"]},{"i":"section-12","l":"‎"}],[{"l":"Vocal Isolation","p":["Last update: Feb 29, 2024"]},{"i":"section","l":"‎","p":["A vocal isolation app is a software designed to extract a person's vocals from an audio file, usually through the use of AI models.","They can remove undesired noises, like background noise, reverb, echo, music, etc.","The goal is to get an audio sample with clean vocals, which is what RVC needs to give the most accurate & quality results.","For RVC users, the best app is Ultimate Vocal Remover 5 (or UVR). It can be used either locally or through the cloud."]},{"i":"section-1","l":"‎","p":["You'll require great specs & GPU to run it effectively. Otherwise, use the cloud version."]},{"l":"Installation","p":["Go to their official website& press Download UVR."]},{"i":"section-2","l":"‎","p":["It will redirect you their GitHub page. Click the download link for your operating system. UVR is available both on Windows & Mac."]},{"i":"section-3","l":"‎","p":["Once the installer finishes downloading, execute it & follow the instructions. Make sure to tick \uD83D\uDDF9 Create a desktop shortcut for an easier access to UVR."]},{"i":"section-4","l":"‎"},{"i":"section-5","l":"‎"},{"l":"How to Use","p":["If an issue arises, read the Troubleshooting chapter."]},{"i":"extracting-vocals-from-songs","l":"*Extracting Vocals From Songs \uD83C\uDFB6*","p":["Click Select input to select your audio/s. Or just drag the files to it.‎","In Select output you can define the folder for the results.","‎","For better results, have the audio in a lossless format( WAV or FLAC), & not MP3.","At the right you can select the output format. We recommend picking FLAC. Learn why here.‎","If your GPU is compatible with CUDA, toggle GPU Conversion on for a faster process.","This step is not mandatory, but recommended for better results.","In CHOOSE PROCESS METHOD select MDX-Net, and select the MDX23C model.","Now click the long Start Processing button.","TIP: To test models/options more efficiently, tick Sample Mode to only process 30 seconds of your sample.","Usually songs include reverb & backing vocals. These negatively impact the results in RVC.","So if the output has any undesired noises, follow the procedure on Cleaning Vocals.‎"]},{"i":"cleaning-vocals","l":"*Cleaning Vocals \uD83D\uDDE3️*","p":["Click Select input to input the vocals. Or just drag the files to it.‎","In Select output you can define the folder for the results.","‎","For better results, have the audio in a lossless format( WAV or FLAC), & not MP3.","At the right you can select the output format. We recommend picking FLAC. Learn why here.‎","If your GPU is compatible with CUDA, toggle GPU Conversion on for a faster process.‎‎","This step is not mandatory, but recommended for better results.","In Process Method select VR.‎","Set Window Size to 320. (optional) Lower Window Size yield a higher output quality, but will take longer to process.‎","Check the model list. In Select VR Model pick the one according to what you need to remove.‎ If you need to remove multiple noises, follow this pipeline for the best results: Remove instrumental - Remove reverb - Extract main vocals - Remove noise","TIP: To test models/options more efficiently, tick Sample Mode to only process 30 seconds of your sample.","Click the Start processing button at the bottom. And that will be all."]},{"i":"section-23","l":"‎"},{"i":"section-24","l":"‎"},{"l":"Troubleshooting"},{"i":"a-model-isn-t-there","l":"*A model isn't there.*","p":["Click the wrench (\uD83D\uDD27) on the left & go to Download Center","Select the category of the model (MDX-NET or VR)","Unfold its dropdown & select the model that you need","Then click the download button (\uD83D\uDCE5). The model will download, which will take a few minutes"]},{"i":"uvr-extracted-too-little-too-much","l":"*UVR extracted too little/too much.*","p":["Modify the Aggression Setting value on the right.","This determines the depth of the extraction. Only the VR method has it.","A higher value will deepen the extraction, and a lower one will soften it.","Each audio is different, so you'll have to test the ideal value."]},{"i":"i-can-t-remove-some-of-the-backing-vocals","l":"*I can't remove some of the backing vocals.*","p":["Run the audio through MDX23C or DeNoise. Modify the Aggression Setting if necessary."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-29","l":"‎"},{"i":"section-30","l":"‎"},{"l":"How to Use","p":["If an issue arises, read the Troubleshooting chapter."]},{"i":"extracting-vocals-from-songs","l":"*Extracting Vocals From Songs* \uD83C\uDFB6","p":["First access the Colab space here. This Colab only uses WAV audios. If yours isn't, convert it to WAV or use MVSEP.‎","Then Log in to your Google account.‎","Execute the Setup cell by pressing the play button . Grant all the permissions.‎‎‎","It'll finish once the logs say \"Ready!\".‎","‎","In Google Drive, make two folders, named Separar& Vocales.‎‎‎","Name them as you want, as long as the input/output folders match the paths.‎","Select the MDX23C 8KFFT InstVoc HQ 2 model & run the Separation cell.‎‎‎‎","Download the result located in the output folder.","Usually songs include reverb & backing vocals. These negatively impact the results in RVC.‎","So if the output has any undesired noises, follow the procedure on Cleaning Vocals.‎"]},{"i":"cleaning-vocals","l":"*Cleaning Vocals* \uD83D\uDDE3️","p":["Access the Colab space here& Log in to your Google account. Credits to Eddy for the Colab.‎","Execute the Install cell. This will take around 5 - 10 minutes.‎‎‎","It'll finish once the logs say \"Installation Completed\".‎‎","‎","Then below run the WebUI cell. This will take around 3 minutes. For advanced users, tick VIP_MODELS if you wish to use them.‎‎‎‎","Open the public URL. That Gradio link contains the UVR app.‎‎","Don't close Colab until you're done using it, and don't press buttons continuously too quickly, as it may cause errors.","Tap the Input Audio box & select your audio, or simply drag & drop.‎‎‎‎","Once it's done uploading, in CHOOSE PROCESS METHOD, select VR Arc.‎‎‎‎","On the left, tick GPU Conversion& set WINDOW SIZE to 320. Lower Window Size yield a higher output quality, but will take longer to process.‎‎","Check the model list& in CHOOSE VR MODEL pick the one according to what you need to remove.‎ If you need to remove multiple noises, follow this pipeline for the best results: Remove instrumental - Remove reverb - Extract main vocals - Remove noise","Click Start Processing below. Wait a moment for the audio to process.‎","Playable audios will then appear in the output boxes below. To download the output, click the three dots on the right and Download.","If you're extracting lead vocals, remember to download the backing ones if you wish to keep them.","TIP: To test models/options more efficiently, tick Sample Mode to only process 30 seconds of your sample."]},{"i":"section-43","l":"‎"},{"i":"section-44","l":"‎"},{"l":"Troubleshooting"},{"i":"uvr-extracted-too-little-too-much","l":"*UVR extracted too little/too much.*","p":["Modify the Aggression Setting value on the right.","This determines the depth of the extraction. Only the VR method has it.","A higher value will deepen the extraction, and a lower one will soften it.","Each audio is different, so you'll have to test the ideal value."]},{"i":"i-can-t-remove-some-of-the-backing-vocals","l":"*I can't remove some of the backing vocals.*","p":["Run the audio through MDX23C or DeNoise. Modify the Aggression Setting if necessary."]},{"i":"i-get-a-red-error-message","l":"*I get a red error message.*","p":["This is normal. Try repeating your action.","If it persists, reload the Gradio page."]},{"i":"cannot-connect-to-gpu-backend","l":"*Cannot connect to GPU backend.*","p":["You have exhausted the GPU runtime of Colab."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-48","l":"‎"},{"i":"section-50","l":"‎"},{"i":"important-notes","l":"Important Notes ‎","p":["MVSEP is a website for isolating vocals, that works similarly as UVR.","The UVR Colab is much faster & convenient for this task. Use MVSEP if you run out of GPU runtime or feel lazy to convert your audio to WAV.","For free users, you can't convert audios in batches or longer than 10 minutes. If that's your case, trim it into different pieces."]},{"i":"section-51","l":"‎"},{"i":"section-52","l":"‎"},{"i":"how-to-use","l":"How to Use ‎","p":["If an issue arises, read the Troubleshooting chapter."]},{"i":"extracting-vocals-from-songs","l":"*Extracting Vocals From Songs* \uD83C\uDFB6","p":["First, make an account here.‎","Once logged in, go to the main page.","Logging in is not mandatory, but recommended for shorter waiting lists.","‎","Click Browse File& select your audio, or simply drag & drop. The audio will begin to upload.","In Separation type select MDX23C‎","In Output encoding select FLAC. We recommend selecting FLAC from now on. Learn more here.‎","Once the audio is done uploading, click Separate","When it's done converting it will redirect you to a page where you can listen the results.","Tap the three buttons of the Vocals audio and then Download.‎","Same thing for the Instrumental, if you wish to keep it.","Usually songs include reverb & backing vocals. These negatively impact the results in RVC.‎","So if the output has any undesired noises, follow the procedure on Cleaning Vocals.‎"]},{"i":"cleaning-vocals","l":"Cleaning Vocals \uD83D\uDDE3️","p":["First, make an account here.‎","Once logged in, go to the main page.","Logging in is not mandatory, but recommended for shorter waiting lists.","‎","Click Browse File& select your audio, or simply drag & drop. The audio will begin to upload.‎‎‎‎","In Output encoding select FLAC. We recommend selecting FLAC from now on. Learn more here.","In Separation Type, select Ultimate Vocal Remover 5 HQ.‎","Check the model list. In Select VR Model pick the one according to what you need to remove.‎ If you need to remove multiple noises, follow this pipeline for the best results: Remove instrumental - Remove reverb - Extract main vocals - Remove noise","Click Separate& when it's done converting it will redirect you to a page, where you can listen the results.‎","Tap the three dots of the audio you need and then Download. If you wish to keep the backing vocals stem, remember to download it too."]},{"i":"section-64","l":"‎"},{"i":"section-65","l":"‎"},{"i":"troubleshooting","l":"Troubleshooting ‎"},{"i":"mvsep-extracted-too-much-too-little","l":"*MVSEP extracted too much/too little.*","p":["Using the Separation Type of Ultimate Vocal Remover HQ, you can modify the Aggressiveness value. This determines the depth of the extraction.","A higher value will deepen the extraction, and a lower one will soften it.","Each audio is different, so you'll have to test the ideal value."]},{"i":"i-can-t-remove-some-of-the-backing-vocals","l":"*I can't remove some of the backing vocals.*","p":["Try running the audio through MDX23C or DeNoise. Modify the Aggression Setting if necessary."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-69","l":"‎"},{"i":"section-70","l":"‎","p":["-","Extraction","Main Vocals","MDX-Net","MDX23C","Model","Noise","Process Method","Reverb","Separation Type","Ultimate Vocal Remover 5 HQ","UVR-BVE-4B_SN-44100-1","UVR-DeEcho-DeReverb","UVR-DeNoise","Vocals/Instrumental","VR"]},{"i":"section-72","l":"‎"}],[{"l":"Datasets","p":["Last update: Mar 8, 2024"]},{"i":"section","l":"‎","p":["In the field of AI, it's the collection of data used to train an AI model. It contains examples of the inputs the model is expected to handle, along with the correct outputs.","In the context of RVC, it's an audio file that's given to RVC, containing the voice the model is going to replicate. It can be either a speaking or singing voice.","The quality& length of the dataset are the biggest determining factors of the final quality of the model. Let's explain."]},{"i":"section-1","l":"‎","p":["For beginners we recommend sticking with 10 minutes, or 20 if you want it very high quality.","If you wish to go for more, keep in mind, usually anything further than 40 minutes isn't necessary.","With modern versions of RVC, the dataset can be just a single audio file, no need to split it in multiple files."]},{"i":"section-2","l":"‎"},{"i":"section-3","l":"‎"},{"i":"range","l":"Range.","p":["Vocals must be clear, hit low/high notes, & pronounce every vowel correctly.‎"]},{"i":"clean-vocals","l":"Clean vocals.","p":["Ensure there isn't background noise, reverb, overlapping voices, music, distortion, or small silences. You'll learn more in the Cleaning section below.‎"]},{"i":"audio-quality","l":"Audio quality.","p":["The higher the audio quality, the better. If possible have it in a lossless format like WAV or FLAC, not a lossy one like MP3.‎"]},{"i":"no-sibilance-popping","l":"No sibilance/popping.","p":["Additionally, don't include harsh sibilance (loud \"S\" & \"SH\" pronunciation) or popping sounds (loud \"P\" sound).‎"]},{"i":"section-4","l":"‎","p":["First, clean the undesired noises explained before using a vocal isolation software.","Then, to remove silences, distortion & minimize (even more) noise, we'll use tools from Audacity. A free, simple & very light-weighted DAW.‎","First input your dataset by dragging the audio file into the app.","Press CTRL + A to select the whole audio.","Navigate to the Effect menu at the top, go to Noise removal and Repair and select Noise Gate.","Use these values & apply the changes:‎","Go to Effects -> Special -> Truncate Silence","Use the following values:‎","Go go to Effects -> Volume and Compression -> Normalization","Use these values:‎","On the upper right corner go to File and click Export Audio.‎‎‎","And finally, introduce these values:","Format: FLAC","Bit depth: 24 bit","Level: 8"]},{"i":"section-7","l":"‎"},{"i":"section-8","l":"‎","p":["Record while reading anything, like a book.","Warm up your voice. Clear your throat & read out loud before starting.","Make it natural, not robotic.","Pronounce every vowel correctly.","Hit low & high notes. Don't have to exaggerate it if you don't need to.","Get close to the mic, not too much to avoid sibilance/popping","Avoid background noise. Close windows, door, turn off the computer, unplug fridge, etc.","Don't be in a room with reverb. It's best if it's in a small-to-medium sized room with lots of stuff in it, specially soft like beds, couches, pillows, etc.","Have a good posture, it's good for breath support.","Have a drink at your side to not dehydrate."]},{"i":"section-9","l":"‎","p":["This is a unit in that defines the total amount of samples(data) that can fit within 1 second of an audio. They are measured in kilohertz (kHz).","The most common sample rates are 32, 40, 44.1, & 48. The higher the sample rate, the more information it stores, therefore the higher the quality.","While training in RVC, you'll have to set the target sample rate as your dataset's. This value affects the final quality.","Enter the HF space here.","Press the upload box & select your audio. Or just drag & drop. Then use it's done uploading, click Create Spectrogram and Get Info.","In Samples per second you'll see the audio's full sample rate. Insert that value in RVC.","If the frequencies don't reach the top of the spectrogram, see at which number peaks & multiply it by 2.","‎‎","Here it reached 20 kHz. Doubling it gives 40kHz. Therefore the ideal target sample rate would be 40k"]},{"i":"section-11","l":"‎"}],[{"l":"Artifacting","p":["Last update: Feb 10, 2024‎"]},{"i":"section","l":"‎"},{"l":"Introduction","p":["In RVC, artifacting refers to an anomaly where the output voice sounds \"robotic\" & glitchy. This occurs after the inference or model training process."]},{"i":"section-1","l":"‎"},{"l":"Causes","p":["It usually occurs when the dataset/vocal sample meets any of these criteria:","‎ ‎ ‎ • ‎ Audio is low-quality‎ ‎ ‎ • ‎ Voice model was overall poorly trained‎ ‎ ‎ • ‎ There are overlapping voices‎ ‎ ‎ • ‎ There is reverb‎ ‎ ‎ • ‎ There is noise","As you noticed, most of the issues boil down to the audio sample not being properly clean. RVC is built for purely working with voices, not other sounds.","Remember that the cleaner your input audio is, the better the results."]},{"i":"section-2","l":"‎"},{"l":"Solutions"},{"i":"1-use-a-lossless-format","l":"1. Use a lossless format:","p":["If possible, it's best if your audio is in a lossless format like WAV or FLAC, preserving its original quality.","Avoid using lossy ones like MP3 or OGG.‎"]},{"i":"2-if-doing-inference","l":"2. If doing inference:","p":["Remove undesired noises with an vocal isolation software.","Lowering the search feature ratio can also minimize this issue.","If breathing sounds produce it, lower the Protection value.‎"]},{"i":"3-if-training-models","l":"3. If training models:","p":["Ensure to clean your dataset properly, this includes removing silences and distortions."]},{"i":"section-3","l":"‎"}],[{"l":"Inference Settings","p":["Last update: Feb 25, 2024"]},{"i":"section","l":"‎","p":["When doing inference in RVC, you'll come across to quite a few options that you can tweak, that influence the conversion process.","Configuring them accordingly can improve the output quality by a lot, as well as reduce artifacting, so we highly recommend learning them.","There are some of them that are either obsolete or not important. So if a setting is not explained here, you can ignore it."]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎"},{"i":"also-known-as-pitch-it-adjusts-the-tone-of-voice","l":"Also known as Pitch, it adjusts the tone of voice.","p":["Negative values lower the tone (e.g -2).","Positive ones raise it (e.g 5).","You can use decimals if necessary (e.g -4.3).","You'll usually have to modify this for the pitch to sound perfect. Modify it until it matches the tone of the model."]},{"i":"section-4","l":"‎"},{"i":"also-known-as-index-rate-it-determines-the-level-of-influence-of-model-s-index-file","l":"Also known as Index Rate, it determines the level of influence of model's .INDEX file:","p":["Higher values will apply more of the .INDEX's characteristics.","Lowering it can reduce artifacting.","Remember, if the dataset had other sounds like background noise, there will be noise in the .INDEX too."]},{"i":"section-5","l":"‎"},{"i":"also-known-as-f0-they-re-the-algorithms-for-converting-the-vocals","l":"Also known as f0, they're the algorithms for converting the vocals.","p":["*Crepe*","*Mangio-Crepe*","*RMVPE*","As the majority of them are obsolete, we'll focus on the 3 best ones: RMVPE, Crepe, & Mangio-Crepe.","Decent quality","Each one works in its own way, and has its pros & cons.","Fast","Has higher quality","Inference only. Allows you to set the maximum/minimum frequency, to reduce small distortions. Recommended for advanced users.","It determines the time it takes the voice to hit a note","It's crepe, but you can adjust its hop_length","Lowering it too much might lead to voice cracks.","More prone to noise & artifacting. Switch to RMVPE if you can't fix it","Only use it with high quality datasets/samples","Recommended for more realistic results","Should be your go-to algorithm, due to its convenience","Slower","Some forks include RMVPE_GPU& RMVPE+. Same algorithm, but with a modification:","The lower the value, the more detailed results you'll get, but will take longer to process","They also work the same for training models.","Training only. Uses more GPU power, making you train faster.","Useful when the audio/model performs drastic note shifts","Usually sounds a little harsh"]},{"i":"section-10","l":"‎"},{"i":"also-known-as-protection-they-suppress-breath-sounds","l":"Also known as Protection, they suppress breath sounds:","p":["Decrease the value to remove more breath sounds, as they cause some artifacting.","A value of 0.5 disables this feature.‎","Be careful, lowering it too much will make it voice sound \"inhumane\" & suppress part of the words."]},{"i":"section-11","l":"‎"},{"i":"also-known-as-remix-mix-rate-controls-the-loudness-of-the-output","l":"Also known as Remix Mix Rate, controls the loudness of the output:","p":["The closer to 0, the more the output will match the loudness of the input audio.","The closer to 1, the more it will match the loudness of the dataset the model was trained on.","Basically, leave it at 0 if you want the audio to try to keep its original volume."]},{"i":"section-12","l":"‎"},{"i":"gives-a-faster-inference-more-consistent-output-volume","l":"Gives a faster inference & more consistent output volume:","p":["In RVC sometimes there's an error where the volume of the output lowers in some parts.","To prevent this, Split Audio divides the audio & infers them one by one. Then unites them at the end.","Doing it this way is faster too."]},{"i":"section-13","l":"‎"}],[{"l":"TTS Tools","p":["Last update: Mar 4, 2024"]},{"l":"Introduction","p":["TTS is an abbreviation of Text To Speech, an AI that converts any given text into vocal speech.","The ones listed here offer a decent variety of features & options, such as model training, fine-tuning, 0 shot training, or being mixed with RVC.","Here's an index of the best TTS tools out there:‎"]},{"i":"elevenlabs11labs","l":"ElevenLabs/11Labs","p":["ElevenLabs is a freemium service (only one in this guide) that offers TTS, training TTS models & translating videos from different languages.‎"]},{"l":"Bark TTS","p":["Bark is a multilingual TTS model created by Suno AI.","It’s characterized by its great ability to express emotions& non-speech sounds.","Examples are laughter, laughs, sighs, gasps, clearing throat, hesitations ( - or … ), emphasis of words, etc.","It can be used both locally or in the cloud:","Official Guide","Fixed Fork(with UI & fine-tuning)","Voice Cloning","Bark TTS Colab","GUI Version(with fine-tuning)","0 Shot Voice Cloning","Official HF Space","0 Shot Voice Cloning HF Space","For training you'll need a paid GPU. Otherwise you can only TTS."]},{"i":"section","l":"‎"},{"l":"Edge TTS","p":["\uD83D\uDCD2 Google Colab","\uD83E\uDD17 Hugging Face","Applio Colab","Download the browser.","Ilaria RVC","In the TTS input the text you want & click Generate. Stop recording when the voice is done.","It can only be used online via their API, through their web browser, a HF/Colab space or mixed with RVC.","Local Applio‎","Open Microsoft Edge & drag the .html to it.","Open your Notepad & paste the following code:","Rename it to “Microsoft Edge TTS.html”","Save it as “Microsoft Edge TTS.txt”","These being mixed with RVC means it generates the speech & runs the output through RVC, applying the voice model.","This is Microsoft Edge TTS, which is good quality, multilingual & works great on long sentences.","Use Audacity to record the audio. Set the recording mode to loopback to record the internal audio (Realtek driver might be needed).","You can then select Voice Options in the toolbar & change the speed to a faster/slower speech."]},{"i":"section-2","l":"‎"},{"l":"StyleTTS2","p":["StyleTTS 2 aims to achieve human-level TTS synthesis only in English.‎","It works better on full sentences, is both available locally & online, and you can fine-tune it with your own dataset.‎","It has 2 versions:‎","LJSpeech: Its dataset should only be of single-speaker recordings. Suitable for training models with a consistent voice.‎","LibriTTS: Its dataset can be of multispeaker recordings. Allows StyleTTS 2 to adapt to different voices.‎","Official StyleTTS2 Guide","LJSpeech Colab","LibriTTS Colab","StyleTTS2 Finetuning Colab","StyleTTS2 HF Space(Duplicate the space to skip queue. Without GPU you can only infer)"]},{"i":"section-3","l":"‎"},{"l":"Tortoise TTS","p":["Expressive but a little slow. Available both locally & online.","Official Github Repository","Colab Space","HF Space"]},{"i":"section-4","l":"‎"},{"l":"XTTS2","p":["Built on \uD83D\uDC22 Tortoise TTS & developed by Coqui AI, which has been discontinued unfortunately.","Has important model changes that make cross-language 0 Shot voice cloning& multilingual speech generation super easy.","You need less training data. Just least a 2 minute audio.","Can use it either online or locally:","Official XTTS 2 Guide","XTTS 2 UI Fork","Inference 0 Shot Training UI Colab(Run it & click the Public Link)","Training & Inference UI Colab","Inference 0 Shot Training HF Space"]},{"i":"section-5","l":"‎"},{"l":"OpenVoice","p":["Has Versatile Instant Voice Cloning (aka 0 Shot Training)","Contains cross-lingual & flexible voice style control","Available both locally & online:","Official GitHub repo","Inference GUI Colab","Official Demo Part 1 Colab","Official Demo Part 2 Colab","Official HF Space"]},{"i":"section-6","l":"‎"},{"l":"MetaVoice-1B","p":["MetaVoice-1B is a 1.2B parameter base model, trained on 100k hours of speech for TTS.‎","It has been built with the following priorities:","Emotional speech rhythm and tone in English.","Zero-shot cloning for American & British voices, with 30s reference audio.‎","Available both locally & online:","Model Github Repo","TTS with 0 Shot Training Demo| Easier Version","TTS with 0 Shot Training HF Space","Freemium MetaVoice Studio(Only premade voices)"]},{"i":"section-7","l":"‎"},{"l":"MeloTTS","p":["MeloTTS is a high-quality multilingual TTS library, made by MyShell.ai","Includes almost real-time inference.","It can be used both locally and online:","Official GitHub Repo","UI Colab","NO UI Colab","HF Space"]},{"i":"section-8","l":"‎"},{"l":"GPT-SoVITS","p":["GPT-SoVITS has cross language inference, but there could be some noises.","It's very good with Chinese, but also with English.","Most parts are in japanese & not deeply tested. Expect some instability.","Can be used both locally & online:","Official GitHub Repo","Colab Space(with fine-tuning, inference & UI)"]},{"i":"section-9","l":"‎"},{"l":"gTTS","p":["It's Google Text To Speech, which is the same one used in Google Translate.‎","It has very few voices in different languages, is a little robotic& doesn’t let you choose the gender of the voice (except in the Colab, but it's not that great).‎","It can be used only online (API):‎","Colab Space","HF Space","Official Guide","Google Translate"]},{"i":"section-10","l":"‎"}],[{"l":"GPT-SoVITS","p":["Last update: Mar 8, 2024"]},{"i":"section","l":"‎","p":["See original guide","GPT-SoVITS is an open-source repository focused on TTS & cross-language inference, with a Colab port coming soon. Credits to RVC-Boss.","Currently it only supports Chinese, English & Japanese. More languages are coming soon.","You'll require great specs & a NVIDIA GPU with >=6G VRAM to run it smoothly. Otherwise, use the Colab.","This guide is a translation of the original one with a few tweaks, made by Delik. [Discord: @delik - Wechat: Dellikk ]‎"]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎"},{"l":"1. Download prezip","p":["Download the prezip of the latest version here."]},{"i":"section-3","l":"‎"},{"l":"2. Extract","p":["Unzip the folder. It's advisable to use 7-ZIP to do so."]},{"i":"section-4","l":"‎"},{"l":"3. Launch","p":["Open the folder & run go-web.bat to open WebUI."]},{"i":"section-5","l":"‎"},{"i":"section-6","l":"‎"},{"l":"1. Prepare dataset","p":["The dataset should be between 1 - 30 minutes. But you must prioritize quality over quantity.","For the best results, ensure the audio is properly cleaned, free of undesired noises & distortions.","GPT-So-VITS is made for TTS only, so it's also best to remove any singing/muffly voice parts."]},{"i":"section-7","l":"‎"},{"l":"2. Audio Slicer","p":["Copy the path file of your dataset & paste it in the Audio slicer input bar.","Create a new folder somewhere. Copy its path folder & paste in Audio slicer output. This is where the outputs are getting stored.","Adjust the parameters if needed.","Finally, click Start Audio Slicer to complete this step."]},{"i":"section-8","l":"‎"},{"l":"3. ASR","p":["The Input folder path should be the same as Audio slicer output. Jst copy the path & paste it inside the bar.","If the dataset is in English/Japanese, use Faster-Whisper large v3.","If it's in Chinese, use 达摩ASR.","Then click Start batch ASR.","If you run GPT-SoVITS for the first time, you might need to wait for a few minutes for it to download the ASR model you select.","Finally, locate the .list file & copy the path. It will be in output/asr_opt, if you didn't change the folder for Output folder path."]},{"i":"section-9","l":"‎"},{"i":"4-text-labelling-optional","l":"4. Text Labelling (optional)","p":["Paste the .list file path into .list annotation file path.","Tick Open labelling WebUI to open Text Labelling WebUI. A new tab will open.","Listen to each clip & edit the text if it's not transcribed properly.","The functions are self-explanatory. Use next index& previous index to check the next/previous page.","If you make changes, remember to save file& submit text."]},{"i":"section-10","l":"‎"},{"l":"5. Formatting","p":["Click 1-GPT-SOVITS-TTS& 1A-Dataset formatting to enter the training page.","Input the name of your model in Experiment/model name, & the .list file path to Text labelling file.","Scroll down to the end & start One-click formatting to begin formatting."]},{"i":"section-11","l":"‎"},{"l":"6. SoVITS Training","p":["Scroll up then click 1B-Fine-tuned training.‎‎"]},{"i":"section-12","l":"‎","p":["2| Use 1 if the GPU has 6GB VRAM.","8","<= 0.4","4","After that, click Start SoVITS training"]},{"i":"section-13","l":"‎"},{"l":"7. GPT Training","p":["2 (1 if your gpu has 6G vram)","10","5","disabled (explained later)","‎","After that, click Start GPT training"]},{"i":"section-14","l":"‎"},{"i":"dpo-training-optional","l":"DPO training (optional)","p":["DPO training greatly improves the performance (not audio quality) & stability of the model.","It can infer more text at once without slicing & it's less prone to errors (like repeating/skipping words) when inferring.","A GPU with 12G VRAM or more.","A very high quality dataset (you need to do text labelling) to enable this.","Using a batch size of 1. Keep the other settings same as above.","Otherwise, this will worsen the model."]},{"i":"section-15","l":"‎","p":["Go to the 1C-inference tab.","Press refreshing model paths& select your models from the dropdowns respectively.","Tick Open TTS inference WEBUI.","Upload a clip for reference audio ( must be 3-10 seconds). Then fill-in the Text for reference audio, which is what does the character say in the audio. Choose the language on the right.","The reference audio is very important as it determines the speed & emotion of the output. Try different ones to polish your output.","You can reopen the text proofreading tool to download the reference audio, and copy & paste the text for reference audio.","Hover above the \"duration\" to adjust the length of the reference audio, & hover above \"it\" to delete the current reference audio.","No reference text mode exists, but it's not advisable to use it. It affects the quality a lot.‎","Fill the Inference text& set the Inference language, then click Start inference.","If the text is too long choose the options in How to slice the sentence.","If you did not get your desired output, you can infer it again or change reference audio and/or adjust GPT parameters."]},{"i":"section-16","l":"‎"}],[{"l":"Glossary","p":["‎","A technology developed by NVIDIA, that uses the power of graphics cards to perform calculations that require great processing power.","Any software or application that's stored, managed, and available through the provider's virtual servers, and is accessed through a web browser.","Audio formats that compress(lose) the original quality. They're built to be space-efficient.","Audio formats that don't compress(lose) the original quality.‎","Basically the speed at which RVC/UVR will work will depend on how good your GPU is.","Basically, higher bit depths represent more accurately the loudness of an audio.","Both formats give the same results & don't have an audible difference. Converting a lossy audio to a lossless one won't restore the lost quality.","Common lossy formats are MP3, OGG, OPUS, M4A, etc.","CUDA is downloaded automatically as a part of the NVIDIA driver.","Different from making a dataset & doing the long training process, based on lots of criteria such as epochs.","Doesn't do any kind of compression. It's purely the original data.","Doing inference on an AI model without explicitly training on it.","Example: G_70.pth and D_70.pth","Example: Tyler_e60_s120.pth‎","FLAC:","For basic audio editing, we recommend Audacity.","For example, in RVC is when a voice model is used to transform an audio, to make it sound like the model.","For example, in TTS you do inference by cloning a voice with an audio, a data it hasn't seen before.","For professional mixing, FL Studio.","For this, using the GPU is more convenient as it's faster. Though normally you can still use CPU, which takes longer.","Further improving an AI model, training it with a another dataset.","G and D:","Google Colaboratory is a product of Google that allows anybody to write & execute arbitrary python code through websites.","Higher bitrate equals a higher quality.","In AI training, is used for quick parallel independent computations, which increases the speed substantially.","In RVC, these are files of a model that generate over the course of training, that can be very useful.‎","In some cases you can do it on GPU, some in CPU.","In the context of AI, it's using an AI model to complete any task.","In the field of AI, is the process where an AI model is fed with its dataset & learns from it.","In the field of digital audio, it defines the dynamic range of each sample.","It refers to a computer's specifications. Hardware like GPU, CPU, RAM, etc.","It stands for Digital Audio Workstation, and it's any software used for making and mixing music.","It stands for Graphics Processing Unit. It's designed to rapidly manipulate and alter memory to accelerate creation of images.","It's a copy of a main GitHub project. It aims to make a different version of the project with improvements, changes & new features.","It's especially useful for AI tools, such as RVC and UVR, which greatly optimizes the process.","It's faster but with less quality, and you won't be able to save the model.","It's free version is slower & with a usage time of their GPUs of around 3 hours a day. Once you exhaust it, you'll have to wait 12 - 24 hours.","It's more accurate to describe it as an uncompressed format","It's recommended over WAV since it's space-efficient.‎","Its algorithm compresses the data without losing quality.","Last update: Mar 8, 2024","Learn how to bypass their limitations here.","Named G_ and D_, followed by the step number & .pth.","Running locally is a process that involves running apps in your own machine, using its resources.","So by getting rid of some data (in this case, quality), they achieve a smaller file size.","The amount of data processed per certain unit of time, usually in kilobits per second (KBPS).","The main ones are WAV & FLAC:‎","The opposite of cloud-based.","The opposite of local running.","The performance of the hardware of a computer directly correlates to the performance of all its software.","The rate at which they're saved is determined by the save frequency value (or save rate or similar names). For newbies, it's recommended use a value of 15.‎","Therefore it has a much bigger file size.","These allow you to resume training, if G and D's numbers match.","These are actual models.","They are divided by two types:‎","They're organized with this format: modelname_epoch_step.pth","They're recommended for RVC, as the more quality an audio has, the more accurate results they'll offer.‎","This determines the difference between the quietest & loudest sound.","Vocal lines that contribute to the sound of the lead vocals in a song.","WAV:","Weights:","You can think of it as video resolution (240, 480, 1080, etc.)."]}],[{"l":"Model Maker Role","p":["Last update: Mar 7, 2024"]},{"i":"section","l":"‎"},{"i":"section-1","l":"‎","p":["A bad model sounds:","A Hugging Face account.","At least 1 audio sample of the model WITH NO MUSIC.","Concerns over copyright.","Don't add reverb, equalize, or alter the demo in any way, as that won't be a faithful representation of the model. It must be the raw, unmodified output from RVC.","Don't include ANY music on the audio demo, even if it's not copyrighted. This is due to:","General information about its training process.","General information about the model.","Harvest, Dio, Crepe-Tiny, PM, etc. are obsolete.","In many cases, the music can \"hide\" the flaws of the voice models, making it harder to judge the quality of the model.","Inaccurate to the source.","Incapable of hitting certain notes.","Model's .INDEX file.","Model's .PTH file.","Muffled.","Only Mangio-Crepe& RMVPE are allowed. Learn about them here","Scratchy/screechy.","The .ZIP file must contain both the correct.INDEX& .PTH file. Learn about them here.","Trimming silences at the beginning/end of the audio is valid.","Unable of pronouncing words correctly in its intended language.","With artifacting.","With slurred speech."]},{"i":"step-1-zip-the-model","l":"Step 1: Zip the model.","p":["Gather the .PTH& .INDEX file and zip them into a .ZIP file.","It must be a .ZIP file, not .7ZIP or .RAR."]},{"i":"section-8","l":"‎"},{"i":"step-2-upload-it","l":"Step 2: Upload it.","p":["The ZIP must be stored in Hugging Face in a public repo of openrail license.","Learn how here."]},{"i":"section-9","l":"‎"},{"i":"step-3-prepare-the-submission","l":"Step 3: Prepare the submission.","p":["Once your model is ready, head over to the #get-model-maker channel.","Type the /submit command of QCBot and click the command.","‎‎","Its name.","Version of RVC it was trained on (will almost always be v2).","The extraction method you used.","Total epochs amount.","Its download link from Hugging Face.","Image of what it represents (person/character).","Audio sample of it talking/singing.","Optional. Add more context about the model if you want.","You can attach more samples when you repost the model to #voice-models."]},{"i":"section-10","l":"‎"},{"i":"step-4-send-submission","l":"Step 4: Send submission.","p":["Once you are done filling the information, send the message.","If everything went fine, your submission will be added to the queue & the bot will send a confirmation message, containing your submission ID. With the ID you can:","Check your submission's number in queue with the command /queue followed by the ID. (e.g /queue 251).","Cancel your submission with the command /cancel followed by the ID.‎","Now wait for a Model QC(quality checker) to verify your model. You'll be notified once it has been reviewed.","If your model gets approved, the bot will notify you with something like this:","‎‎","You can then repost the model (& future models) to the #voice-models forum."]},{"i":"section-11","l":"‎"}],[{"l":"Illusion Diffusion","p":["Last update: Mar 9, 2024"]},{"i":"section","l":"‎"},{"i":"section-1","l":"‎"},{"l":"1. Upload","p":["Go to the Illusion Diffusion Hugging Face Space.","Click on Input Illusion.","Upload the image you wish to blend.‎"]},{"l":"2. Illusion Strength","p":["Modify the \"Illusion Strength\" slider.","Higher values will make the picture more visible.","Lower ones will hide it more.‎"]},{"l":"3. Prompt","p":["Describe the characteristics of the output.","These can be environments (medieval castle - flowery meadow), traits (high quality - a specific image style), etc.‎"]},{"i":"4-negative-prompt-optional","l":"4. Negative Prompt (optional)","p":["Specify what the AI should NOT do when creating the image (e.g., low quality, specific styles to avoid, etc.).‎"]},{"l":"5. Run","p":["Press Run to begin processing.","Be patient; there might be a queue.","If you encounter an error, try clicking again until it works."]},{"i":"section-2","l":"‎"}],[{"l":"License"},{"i":"license-cc-by-nc-sa-40","l":"License CC BY-NC-SA 4.0","p":["This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License."]},{"i":"you-are-free-to","l":"You are free to:","p":["Share: Copy and redistribute the material in any medium or format.","Adapt: Remix, transform, and build upon the material.","The licensor cannot revoke these freedoms as long as you follow the license terms."]},{"i":"under-the-following-terms","l":"Under the following terms:","p":["Attribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.","NonCommercial: You may not use the material for commercial purposes.","ShareAlike: If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."]},{"i":"you-are-not-required-to-comply-with-the-license-for-elements-of-the-material-in-the-public-domain-or-where-your-use-is-permitted-by-an-applicable-exception-or-limitation","l":"You are not required to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation."},{"i":"no-warranties-are-given-the-license-may-not-give-you-all-the-permissions-necessary-for-your-intended-use-for-example-other-rights-such-as-publicity-privacy-or-moral-rights-may-limit-how-you-use-the-material","l":"No warranties are given. The license may not give you all the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.","p":["Read the full text of the license."]}]]
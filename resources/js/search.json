[[{"l":"Home","p":["Last update: Oct 21, 2024"]},{"i":"section-2","l":"‎"},{"l":"Introduction","p":["This site is a documentation of AI tools, mostly RVC-related apps. Made by members of AI HUB.","See simple & convenient guides regarding model training, inference, audio isolation, datasets, TensorBoard, & more. Verified by the experts & for all devices."]},{"i":"section-3","l":"‎"},{"l":"Contributions","p":["We'll appreciate any feedback, big or small. You can directly contact us in AI Hub: @eddycrack864- @ailen2091","Leave suggestions in the #suggestions channel. To report issues, use #help-forum.","You can also send an issue/pull request to our GitHub page."]},{"i":"section-4","l":"‎"},{"l":"Credits","p":["Lead by: Julia & Eddy","General Help: Poopmaster Raid, Light, Faze Masta, Alexolotl, Delik, Razer, Nick","Reviewing: Faze Masta, Alexolotl, SimplCup, Delik, Litsa, Lyery, Razer","OG Guides: Litsa, Angetyde, LollenApe, Faze Masta, MrM0dz, FDG, Eddy, Julia, Nick","Backend: Eddy & Yui","Branding: Grvyscale & Cthulhu"]},{"i":"section-5","l":"‎"},{"l":"To-Do","p":["Nothing \uD83D\uDE04"]}],[{"l":"How to Make AI Cover"},{"i":"--simple-ai-cover-tutorial-using-rvc--","l":"- Simple AI cover tutorial, using RVC -"},{"i":"section","l":"‎"},{"l":"1. Extract vocals","p":["Have the audio file of your song ready, & let's extract the vocals from it with an audio isolation software.","RVC is designed to work with voices only, so to get the best results the sample must be clean, with no undesired noises."]},{"i":"section-1","l":"‎"},{"l":"2. Get voice model","p":["Learn about them & how to search one here. Be sure to leave credits to the model maker.","In case the model doesn't exist, click here."]},{"i":"section-2","l":"‎"},{"l":"3. Convert the vocals","p":["After obtaining the vocals & model, it's time to set up RVC & do inference.","There are plenty of versions of RVC, but these are the best ones for beginners. Pick according to your needs:"]},{"i":"section-3","l":"‎","p":["For local users, first ensure you meet the minimum requirements."]},{"i":"section-4","l":"‎"},{"l":"Tips","p":["‎","Add delay if the original vocals had it.","Add reverb to the vocals (not to the instrumental), to the same level as the original one.","Congratulations, you've made it to the final part. Now it's to mix the song.‎","Convert them using Mangio-Crepe with a higher hop length.","For presence and clarity, increase the high range a bit.","Last update: Mar 1, 2024","Make vocals from scratch using a voice synthesizer (like SynthV) & convert them with RVC.","Match the volume of the vocals to the same level as the original ones.","Normalize the audio.","Recommendations for the mix:","Record yourself singing them & convert the audio with RVC.","Regarding what to do with the backing vocals, you have 4 options:","Remove the very low frequencies, ranging from 20 to 100.","Simply leave the original ones in.","Use compressor on vocals.‎","You're free to use any DAW, but we recommend FL Studio or BandLab, as they are beginner-friendly. You can start by searching some of their mixing tutorials on YouTube.‎"]}],[{"l":"How to Make Voice Models"},{"i":"--simple-model-training-tutorial-using-rvc--","l":"- Simple model training tutorial, using RVC -"},{"i":"section","l":"‎"},{"l":"1. Prepare dataset","p":["In the context of RVC, the dataset is an audio file containing the voice the model will replicate. It can be either speaking or singing.","For the best results, having a clean dataset is crucial, so take the time to remove any undesired noises."]},{"i":"section-1","l":"‎"},{"l":"2. Set up RVC","p":["With your dataset ready, it's time to set up RVC to train the model.","There are plenty of versions of RVC, but these are the best ones for beginners. Pick according to your needs:"]},{"i":"section-2","l":"‎","p":["For local users, first ensure you meet the minimum requirements."]},{"i":"section-3","l":"‎"},{"l":"3. Train the model","p":["Before you start training, we inform you that the training guides are oriented around using TensorBoard. Read about it & install it after setting up RVC.","Good luck & remember to be patient! As this won't be an instant process.","Last update: Mar 10, 2024","‎"]}],[{"l":"Voice Models","p":["Last update: Apr 01, 2024","‎","In the field of AI, is a program that was trained to recognize certain patterns or make certain decisions.","In this case, voice models are models trained to replicate a voice, and with AI they apply it to the input audio.","There are plenty of them uploaded to the internet, made by the public. And the best way to make them is with RVC."]},{"i":"section","l":"‎"},{"l":"Voice Model Files"},{"i":"they-are-made-up-of-two-files","l":"*They are made up of two files:*","p":["Contains data regarding the voice's accent and speech manner.","File is additional, but usually crucial for the quality of the model.","While training, RVC generates two .INDEX file, but the right one will be named added_ by default.","This file is the model itself.","Contains data regarding pitch.","While training, RVC generates other .PTHs named D_ and G_, but these are the checkpoints, not usable models.","As people sometimes upload them incorrectly."]},{"i":"section-3","l":"‎"},{"i":"section-4","l":"‎","p":["‎‎","‎ ‎ ‎ ‎ ‎ ‎ ‎","\uD83D\uDC40‎ If there are multiple models, click the Select a result bar to see the others.","\uD83D\uDC4D‎ Press the Like to support the creator & offer feedback.","\uD83D\uDCBE‎ With the Save one the bot will DM you said search result.","\uD83D\uDCE4‎ Click Download to download it.","\uD83D\uDD17‎ To get its link, right-click Download Model& tap Copy link.","Access guides, the HF space, and the Applio API featuring 21k+ free models.","Access the website here& login by clicking the icon on the top right corner.","Check the description, likes or tags, this can give you a slight idea of how good the model is.","Check the description, likes, comments, & audio sample. Feedback can help you know how great the model is.","Click on Download model. This will download a .ZIP file of it.‎‎‎","Click the Hugging Face link to download the model, or copy it if that's what you need.","Click the model & go to the Files and versions tab.","Download the correct files of the model. Then if you need its link, upload it to HF.","Go to the models page& search the model in the Filter by name bar.","Head over to the #search-models channel.","Here's where people usually store their RVC models.","If it only exists in weights.gg, download the .ZIP & upload it to HF.","If you get models from different years, remember, the person's voice changes overtime.","If you haven't already, join AI Hub here.","If you need a link for it, use the other methods.","If you're curious about the epochs, learn more here.","If you're curious about the epochs, you can learn more here.","In the upper search bar, search your model & click the post.","It searches the models uploaded on every RVC/AI Hub Discord server.","Models uploaded in AI Hub& AI Hub France get automatically stored here too.","Reminder: Models from kits.ai can't be downloaded.","Searching here is specially useful if you need the model as a link, as the posts include one.","Select the Applio command","Send the message","Share, favorite, and integrate with Applio (RVC) for direct model downloads to your PC.","Tap the three dots & Download model. It will download a .ZIP file of it.‎‎‎","The sample of the gender & vocal style according to the model gives the most accurate representation.","Then go to the #voice-models channel.","There's also its web version. Has less models but offers direct download & the Hugging Face link.","This a website where people can upload voice models.","This is a Discord bot developed by the IA Hispano team.","This is a forum channel in AI Hub where people upload their own voice models.","This is a free & open-source platform for storing AI models, interactive AI apps, & datasets.","This is a website where people can upload voice models.","This step is especially useful if you get multiple results from the same model.","This step is specially useful if you get multiple results of the same model.","To download it, click the download symbol ( ) on the right of the .ZIP file. If you need its link, right-click it and copy the address.","Type /search","Type the model","Type the name of the model in the Search bar & click a result.","User-friendly UI","Users can read/share feedback about the models through comments & likes.","You can listen to the audio sample to get a preview of the it."]},{"i":"section-21","l":"‎"},{"i":"if-you-couldnt-find-one-you-have-3-options","l":"If you couldn't find one, you have 3 options:","p":["Make the model yourself","Pick a different one","Comission a model maker to make it for you"]},{"i":"section-22","l":"‎"},{"l":"1. Zip the model","p":["Select the correct .PTH & .INDEX& zip them into a .ZIP file.","Ensure it's .ZIP & not .RAR or .7ZIP."]},{"i":"section-23","l":"‎"},{"l":"2. Log in","p":["If you haven't already, create an account& log in."]},{"i":"section-24","l":"‎"},{"l":"3. Make repository","p":["Once logged in, tap your profile on the upper right corner, & then New Model.","‎","In Model name you name the repo as you want.","Make sure License is set as openrail& the repo is set as Public.","Once done, hit Create model."]},{"i":"section-25","l":"‎"},{"l":"4. Upload model","p":["It will redirect you to the repo. Go to the Files and versions tab on the center, click + Add file on the right & then Upload files.","‎‎","Tap the upload box & submit the ZIP. Or just drag & drop.","Tap on Commit changes to main& the model will begin to upload."]},{"i":"section-26","l":"‎"},{"i":"5-copy-link-optional","l":"5. Copy link (optional)","p":["Once it's done, it will redirect you to the files list.","So if you need its link, right-click the download button ( ) of the .ZIP file on the right, and click Copy Link."]},{"i":"section-27","l":"‎"}],[{"i":"whats-rvc","l":"What's RVC","p":["Last update: Oct 21, 2024"]},{"l":"Introduction","p":["RVC ( Retrieval-Based Voice Conversion) is an advanced AI voice cloning software, developed by the RVC-Project team. It's considered the best free & open-source one to date.","It was designed for desktop, requiring great specs to run it effectively, specially GPU for training models.","Though it can be executed through the cloud& be used in any device, in case you don't meet the previous requirement.‎"]},{"l":"Forks","p":["A fork is a copy of a main GitHub project. It aims to make a different version of the project, with improvements, new features & modifications.","RVC has quite a few forks made by the community, each one meeting different needs for the user, and with its pros & cons.","These are the main ones, along with their cloud-based counterparts:","‎"]},{"l":"FAQ"},{"i":"frequently-asked-questions","l":"Frequently asked questions."},{"i":"what-s-the-best-fork","l":"*What's the best fork?*","p":["As explained before, it depends on your needs. It's best to try them yourself.","For local users, Applio is a great starting point. For cloud users you can use either the Applio Colab or mainline kaggle."]},{"i":"what-are-the-requirements-for-rvc-locally","l":"*What are the requirements for RVC locally?*","p":["The minimum specs vary depending if it's for training models or inference.","SPEC","REQUIREMENT","GPU","NVIDIA RTX 2060ti / AMD RX5700","RAM","6GB","Storage","30 GB","NVIDIA GTX 1050ti / AMD RX5700","6 GB","For inference, the storage requirement varies depending on the fork. It can be around 5 to 9 GB","If you don't meet these requirements, it's more convenient to use RVC on the cloud."]},{"i":"can-i-use-it-on-my-amd-gpu","l":"*Can I use it on my AMD GPU?*","p":["You can, but it's going to be slower, as they don't have CUDA cores.","So it's more convenient using RVC through the cloud.","If you're willing to use a slower version you can go ahead and follow this guide on how to get zluda working with Applio."]},{"i":"how-long-does-it-take-to-train","l":"*How long does it take to train?*","p":["The total time depends on a lot of factors, like dataset length, batch size, pretrains, specs, etc.","A 10 min dataset with RMVPE may take around 1 to 2 hours."]},{"i":"can-i-run-it-on-a-mac","l":"*Can I run it on a Mac?*","p":["Yes, on Macs of recent generations.","But you can only do inference& it's a little unstable."]},{"i":"do-i-need-internet-to-use-it","l":"*Do I need internet to use it?*","p":["If you're using RVC locally, no.","If you're using it through the cloud, then yes."]},{"i":"section-10","l":"‎"}],[{"l":"Mainline","p":["Last update: Mar 8, 2024"]},{"i":"section","l":"‎","p":["Mainline RVC is the base, original, & unmodified version of RVC. Made by the RVC-Project team.","It has less features compared to other forks, but still has the necessary tools to do a decent job.","It's specially liked because it's a little faster than other forks, as it's less bloated in a way.","Its actual name is not \"Mainline\", but it was given by the public to properly distinguish it from the other versions.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"unfold","l":"***Unfold***","p":["Easy to install.","Simpler to use.","A bit faster compared w/ other forks.","Has less features.","Doesn't include Mangio-Crepe.","Manual model upload."]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎","p":["Go to their download page here","Click the Download word. RVC will begin to download.‎‎","Once it's done, unzip the folder.","Open RVC's folder, find the \" go-web.bat\" file and execute it.‎‎ It will then open a console, & after a moment your default web browser with RVC ready to be used.‎‎‎‎","(Optional) To access RVC more easily, make a shortcut of the go-web file.‎"]},{"i":"section-3","l":"‎","p":["If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-4","l":"‎"},{"i":"1-upload-voice-model","l":"1. Upload voice model.","p":["Open RVC's folder, go to the assets folder and put your model's .PTH file inside the weights folder.‎‎","Return to the previous folder & put the model's .INDEX file in the logs folder."]},{"i":"section-5","l":"‎"},{"i":"2-select-voice-model","l":"2. Select voice model.","p":["In RVC, click the Refresh voice list and index path button.","‎","In its left, click Inferencing voice& select your model."]},{"i":"section-6","l":"‎"},{"i":"3-select-vocals","l":"3. Select vocals.","p":["In Enter the path of the audio file paste the path file of your audio. Ensure the path doesn't include spaces or special characters."]},{"i":"section-7","l":"‎"},{"i":"4-modify-settings-optional","l":"4. Modify settings. (optional)","p":["If you wish, modify the inference settings on display accordingly for better results."]},{"i":"section-8","l":"‎"},{"i":"5-convert","l":"5. Convert.","p":["Click the long Convert button at the bottom & it will begin to convert.","The processing time will mainly depend on your specs, length of audio, & the algorithm picked."]},{"i":"section-9","l":"‎"},{"i":"6-download-output","l":"6. Download output.","p":["Once it's done processing, a playable audio will pop up in the Export audio box. To download, click the three dots on the right & hit Download.","‎"]},{"i":"section-10","l":"‎","p":["The training guide will be centered around using TensorBoard. Read about it first if you haven't already.","If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-12","l":"‎"},{"i":"section-13","l":"‎"},{"i":"1-go-to-training-area","l":"1. Go to training area.","p":["Open RVC & head over to the Train tab."]},{"i":"section-14","l":"‎"},{"i":"2-name-the-model","l":"2. Name the model.","p":["In Enter the experiment name you insert a name for your model. Don't include special characters or spaces."]},{"i":"section-15","l":"‎"},{"i":"3-select-target-sample-rate","l":"3. Select Target Sample Rate.","p":["In Target sample rate select the number that matches your datasets' sample rate. Inputting an incorrect one might screw up the final quality."]},{"i":"section-16","l":"‎"},{"i":"section-17","l":"‎"},{"i":"4-select-dataset","l":"4. Select dataset.","p":["In Enter the path of the training folder paste the path file of your dataset. Ensure the path doesn't include special characters/spaces.","‎","If there's any text in the bar, delete it beforehand."]},{"i":"section-18","l":"‎"},{"i":"5-process-data","l":"5. Process data.","p":["Click the Process Data button on the center.","RVC will process the previous criteria for the training. But also the dataset file, which might take a moment depending on how big it is.","‎","It'll finish when the output box on the right says end preprocess."]},{"i":"section-19","l":"‎"},{"i":"section-20","l":"‎"},{"i":"6-select-gpus","l":"6. Select GPUs.","p":["In Enter the GPU index(es) determine which GPU(s) you'll use for training, by indicating the index followed by the dash (e.g: 0)."]},{"i":"section-21","l":"‎"},{"i":"7-select-pitch-extraction-algorithm","l":"7. Select pitch extraction algorithm.","p":["At the right select the Pitch extraction algorithm. Only use RMVPE_GPU or Crepe, as the rest are obsolete.","‎"]},{"i":"section-22","l":"‎","p":["Now click the Feature extraction button on the right.","‎‎‎ It'll finish when the output says all-feature-done."]},{"i":"section-23","l":"‎"},{"i":"8-create-index","l":"8. Create .INDEX.","p":["Press Train feature index at the bottom center. This will create the .INDEX file.","‎‎ It'll finish when the output box says something like this:"]},{"i":"section-24","l":"‎"},{"i":"section-25","l":"‎"},{"i":"9-select-save-frequency","l":"9. Select save frequency.","p":["Frequency of the saving checkpoints, based on the epochs.","If you are a newbie, simply leave it at 15.","E.g: with a value of 10, they will be saved after the epoch 10, 20, 30, etc.","‎"]},{"i":"section-26","l":"‎"},{"i":"10-input-epochs-amount","l":"10. Input epochs amount.","p":["In Total training epochs you determine the total amount of epochs(training cycles) for the model.","But since we'll use TensorBoard, use an arbitrarily large value like 2000."]},{"i":"section-27","l":"‎"},{"i":"11-select-batch-size","l":"11. Select batch size.","p":["Leave Batch size per GPU at 8 if you aren't familiar with it.","If your dataset is short (around 2 minutes or less), use 4 instead."]},{"i":"section-28","l":"‎"},{"i":"12-launch-tensorboard","l":"12. Launch TensorBoard.","p":["Now before you start training, open TB.","If you haven't already, start reading about it here here."]},{"i":"section-29","l":"‎"},{"i":"13-begin-training","l":"13. Begin training.","p":["Start training the model by clicking Train model.","‎‎‎ Remember to monitor TB, & also the console just in case. The latter will show you errors if they happen, and information about the epochs & checkpoints.‎"]},{"i":"section-30","l":"‎"},{"i":"14-stop-training","l":"14. Stop training.","p":["When you are very sure of overtraining, you can stop training by pressing the Stop training button where Train model used to be."]},{"i":"section-31","l":"‎"},{"i":"15-gather-models-files","l":"15. Gather model's files.","p":["Create a new folder anywhere named as your model.","Open RVC's folder, go to logs, and open the folder named with the model. Select the .INDEX named added_& move it to your newly made folder.","‎","Now go to the weights folder. Here you'll find the model's checkpoints.","Select the one closest to before the overtraining point, and move it to the new folder","These files will be organized with this format: ModelName_Epoch_Step.pth Example: kalomaze_e60_s120.pth","‎‎","And that's all. Have fun with your model. To test the model, do a normal inference as usual."]},{"i":"section-32","l":"‎"},{"i":"section-33","l":"‎","p":["If the training finished but the model still needed training, you don't have to start from scratch. Follow this procedure:","Simply enter the same settings and criteria that you previously inserted. Model name, sample rate, dataset, batch size, etc. You don't have to press Process Data or train the .INDEX again.","You can change the save frequency, or increase the epochs amount in case you didn't input enough before.","Begin training again & remember to monitor TB & console like before."]},{"i":"section-34","l":"‎"},{"i":"section-35","l":"‎"},{"i":"there-s-no-option-for-my-sample-rate","l":"*There's no option for my sample rate.*","p":["If it's lower than 32k: select 32k.‎","If it's 32k: on the right in Version, press v1& press v2 again. Ensure you leave it as v2. You should be able to see a 32k option now.‎","If it's 44.1k: select 40k.‎","If i'ts higher than 48k: select 48k."]},{"i":"the-voice-glitches-out","l":"*The voice glitches out.*","p":["This a phenomenon called artifacting. To fix it, read here."]},{"i":"i-don-t-see-the-stop-training-button","l":"*I don't see the Stop Training button.*","p":["This is a common bug. Close the console to stop RVC entirely."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-39","l":"‎"}],[{"l":"Applio","p":["Last update: Apr 01, 2024"]},{"i":"section","l":"‎","p":["Applio is a VITS-based Voice Conversion Tool developed by the IA Hispano team.","It's liked for its great UI& lots of extra features, such as TTS (with RVC models too), plugins, automatic model upload, customizable theme & more.","Because of its user-friendly experience & active development, it's considered to be one of the best forks.","It also has a cloud version, in case you don't meet the requirements to run it locally.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"*Learn more*","p":["Very complete","Has an active development","Currently stable","Faster interface","Faster Training","TTS features","Automatic model upload","Has Mangio-Crepe","User-friendly UI","TensorBoard included","Extra features: (plugins, model fusion, etc)","Issues when downloading to external drives"]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎","p":["Make sure that you place Applio inside a folder on C drive.","Don't put it in a folder with privileged access.","Don't run the run-install.bat as an administrator.","Make sure the path does not contain any spaces or special characters.","Deactivate your antivirus and firewall to avoid missing dependencies.","The easiest way to download Applio is by going to Applio's Hugging Face repo, and clicking the [download] button on the right-hand side.","Unzip the folder. It may take a few minutes.","Open Applio's folder & execute run-applio.bat.","‎‎","A console tab will appear, and after a moment your default browser, with Applio ready to use.‎"]},{"i":"section-3","l":"‎"},{"i":"section-4","l":"‎","p":["If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-5","l":"‎"},{"i":"section-6","l":"‎"},{"i":"1-upload-voice-model","l":"1. Upload voice model.","p":["Go to the Download tab. You have two ways of uploading it: through its link or manually inputting its files.","Go to the Download tab & paste the link of the model in the Model Link bar. It must be from Hugging Face or Google Drive.‎‎","Press Download Model.","Drag & drop the model's .PTH in the Drop files box below.‎‎","Then drag the .INDEX.","‎"]},{"i":"2-select-voice-model","l":"2. Select voice model.","p":["Return to the Inference tab & click the Refresh button on the right.","‎","Select your model in the Voice Model dropdown."]},{"i":"section-7","l":"‎"},{"i":"3-input-vocals","l":"3. Input vocals.","p":["With Applio you can convert audios individually or in batches:","Drag & drop the audio or click the upload box to search it.‎‎","Then select it in the dropdown below.‎","Go to the Batch tab.‎","In the Input Folder bar, paste the path folder containing the audios.","In Output Folder you can paste a path folder for the results.","Ensure the paths don't contain spaces/special characters.","‎"]},{"i":"4-modify-settings-optional","l":"4. Modify settings. (optional)","p":["Unfold Advanced Settings if you wish to modify the inference settings for better results, or to determine the output folder.","‎"]},{"i":"section-8","l":"‎"},{"i":"5-convert","l":"5. Convert.","p":["Click Convert at the bottom. The audio will begin to process. The processing time will mainly depend on your specs, length of audio & the algorithm picked.","Once it's done, you can hear the results in the Export Audio box below.","By default the output files will be in the \" audios\" folder: \\ApplioV3.0.7\\assets\\audios"]},{"i":"section-9","l":"‎"},{"i":"section-10","l":"‎","p":["The training guide will be centered around using TensorBoard. Read about it first if you haven't already. If you encounter an issue, be sure to read the Troubleshooting chapter."]},{"i":"section-12","l":"‎"},{"l":"1. PREPROCESS","p":["Go to the Train tab. Input a name for your model in Model Name. Don't include spaces/special characters.","‎","Paste the path file of your dataset in the Dataset Path bar. Ensure the path doesn't contain spaces/special characters.","Select your dataset's sample rate. If you don't know the amount, click here.","Ensure RVC Version is set as V2& click Preprocess Dataset.","It'll finish when the output box says preprocessed successfully."]},{"l":"2. EXTRACT","p":["Select the algorithm you want. Use either Crepe or RMVPE, as the rest are outdated.","If you chose Crepe, you can modify its hop length.","Press Extract Features. It'll finish when it says extracted successfully."]},{"l":"3. TRAIN","p":["If you are a newbie, use 8. But in case your dataset is short (around 2 minutes or less), use 4.","Frequency of the saving checkpoints, based on the epochs.‎","If you are a newbie, simply leave it at 15, but if you wish to be percise set it to 1.","‎‎‎","E.g: with a value of 10, they will be saved after the epoch 10, 20, 30, etc.","Input the total amount of epochs(training cycles) for the model.‎","But since we'll use TensorBoard, use an arbitrarily large value like 1000","‎","Sync graphs trains a single epoch and sets the log interval to the amount of steps that epoch trained for.‎","Doing this makes the Tensor Board's graphs accurate.","If you have multiple GPUs, tick GPU Settings to use a specific one for the training.","Click Generate Index. This will create the model's .INDEX file.","Press Start Training to begin the training process.‎","To open TB, execute run-tensorboard in Applio's folder. Remember to monitor it, as well as the console just in case.‎","The latter will show you errors if they happen, and information about the epochs & checkpoints."]},{"l":"4. FINAL STEP","p":["When you're very sure of overtraining, you can stop training by going to the Settings tab & press Restart Applio.","‎","Create a new folder anywhere named as the model.‎","Open Applio's folder, go to logs, and open the folder named as the model.‎","Select the .INDEX named added_& move it to your newly made folder.‎‎‎","In said folder you'll also find all the checkpoints.‎","Select the one closest to before the overtraining point, and move it to the new folder.","The checkpoints will be organized with this format: ModelName_Epoch_Step.pth Example: arianagrande_e60_s120.pth","‎‎","And that's all, have fun with your model. To test it, do a normal inference as usual."]},{"l":"5. RESUMING","p":["In case the training finished but the model still needed training, you don't have to start from scratch.‎","Simply enter the same settings & criteria that you've previously inserted. You don't have to do the preprocess or train the .INDEX again.‎","You can change the save frequency, or increase the Total Epoch amount in case you didn't input enough before.‎","Begin training again & remember to monitor TB & console like before."]},{"i":"section-47","l":"‎"},{"i":"section-48","l":"‎"},{"i":"section-49","l":"‎","p":["+ with any RVC model"]},{"i":"section-50","l":"‎","p":["Applio is also known for having one TTS tool by default, with plenty of voices to choose for.","You can also use it with RVC models& apply the inference settings if you wish.","Aditionally, you can download the Eleven Labs TTS plugin."]},{"i":"section-51","l":"‎"},{"i":"instructions","l":"Instructions:","p":["Go to the TTS tab.","‎"]},{"i":"section-52","l":"‎","p":["If you want to use an RVC model, download it, go to TTS, click Refresh& select it in Voice Model& Index File.","‎‎","To modify the inference settings or the output folder for the TTS/RVC audio, unfold Advanced Settings."]},{"i":"section-53","l":"‎","p":["In TTS Voices select the voice of your desired language, accent & gender.","In Text to Synthesize input your text. Then click Convert.","‎‎","If you are using an RVC model, select a voice that matches the model the most, to guarantee great results."]},{"i":"section-54","l":"‎","p":["Once it's done, you'll be able to hear the result in the Export Audio box. By default, the output audio will be in the \" audios\" folder. < \\ApplioV3.0.7\\assets\\audios>"]},{"i":"section-55","l":"‎"},{"i":"section-56","l":"‎"},{"i":"section-57","l":"‎","p":["Applio has an Extra menu, containing an audio analyzer, originally made by Ilaria.","Making it convenient for determining the sample rate of datasets when training models.","It also contains the model fusion tool, ideal for advanced users."]},{"i":"section-58","l":"‎"},{"i":"audio-analyzer","l":"Audio Analyzer:","p":["Go to the Extra tab & press the upload box to input your audio. Or simply drag & drop.","‎"]},{"i":"section-59","l":"‎","p":["Once it's done uploading, click Get information about the audio."]},{"i":"section-60","l":"‎","p":["In Sampling rate you'll see the audio's full sample rate. Use said value for training."]},{"i":"section-61","l":"‎","p":["If the frequencies don't reach the top of the spectrogram, see at which number peaks & multiply it by 2."]},{"i":"section-62","l":"‎","p":["‎‎","Here it reached 20 kHz. Doubling it gives 40kHz. Therefore the ideal target sample rate would be 40k"]},{"i":"section-63","l":"‎"},{"i":"section-64","l":"‎","p":["Plugins are components that you can add to Applio, that add new features & enhance your experience.","These are made by the public, and are free & easy to install.","You can find them on their GitHub page. More will be added in the future."]},{"i":"section-65","l":"‎"},{"i":"installation","l":"Installation:","p":["Access their GitHub page & click on the name of the plugin you want.","‎"]},{"i":"section-66","l":"‎","p":["Click on the ZIP file.","‎‎","Click on the download button on the right. This will download the ZIP file of the plugin."]},{"i":"section-67","l":"‎","p":["Open Applio & head over to the Plugins tab. Drag & drop the ZIP file to the upload box.","‎‎","You will be able to see its installation process in the console."]},{"i":"section-68","l":"‎","p":["Go to the settings tab & click Restart Applio at the bottom. Then you'll be able to see the plugin in the Plugins tab."]},{"i":"section-69","l":"‎"},{"i":"section-70","l":"‎"},{"i":"section-71","l":"‎"},{"i":"there-s-no-option-for-my-sample-rate","l":"*There's no option for my sample rate.*","p":["If it's lower than 32k: select 32k.‎","If it's 44.1k: select 40k.‎","If i'ts higher than 48k: select 48k."]},{"i":"the-voice-glitches-out","l":"*The voice glitches out.*","p":["This a phenomenon called artifacting. To fix it, read here."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-75","l":"‎"}],[{"l":"Codename Fork","p":["Last update: Dec 17, 2024"]},{"i":"section","l":"‎","p":["The codename fork is a fork of Applio made by Codename.","This fork has more features compared to others and changes to increase quality.","This guide will be only talking about the new features since everything else has been covered in the Applio guide."]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"unfold","l":"***Unfold***","p":["All of the pros of Applio.","Supports MRF HiFi-GAN","Supports RefineGAN","Has a Warmup Phase option","Uses the Ranger2020 optimizer","Avg running loss","44.1k Sample rate support","Mel similarity metric","SoX resampler","Checkpointing","Improved inplace","More complicated features."]},{"i":"section-1","l":"‎","p":["Go to the github repo here. Then find the releases tab and click it.","‎‎","Click on the zip file and download it. Then go into your C drive and extract it.","Go into the codename fork folder and run the run-install.bat file then once it's done run go-fork.bat."]},{"i":"section-2","l":"‎"},{"i":"441k-sample-rate","l":"44.1k Sample Rate:","p":["Under Training there is the option to use 44.1k as your trainng sample rate, however there are currently no pretrains for it."]},{"i":"mrf-hifigan--refinegan","l":"MRF HifiGAN & RefineGAN:","p":["In the training section you are given the option to choose your vocoder","HiFi-GAN: the default vocoder for RVC.","MRF HiFi-GAN: a version of HiFi-GAN with MRF instead of MPD and new loss functions. This has higher fidelity but only works with this fork and the MRF branch of Applio.","RefineGAN: an entirely new GAN which is in a very experimental phase, this is for for devs only."]},{"i":"warmup-phase","l":"Warmup Phase:","p":["In the training section there is an option to enable a warmup phase and a slider to choose how long it lasts.","The warmup phase is where the learning rate (lr) linearly increased for a certain amount of epochs, this can be used to prevent large destabilizing updates in the early stages of training.","There isn't much testing on what using a warmup in RVC does so expect varying results."]},{"i":"avg-running-loss","l":"Avg Running Loss:","p":["In the training section you can find the avg running loss settings.","The avg running loss averages the loss per X steps / mini-batches. This is a better indicator for per epoch performence.","To use the avg loss you need to know the total number of steps per epochs, you can train one epoch to find the step count. Choosing an averaging factor depends on the user, however Codename recommends experimenting with a window that accounts for around 15% to 25% of total steps in an epoch. If you choose to not use 15-25% of total steps be sure that the logging frequency isn't to small because the losses can vary a ton and it can end up confusing you, and make sure for big loss frequency it isn't to big because it may smoothen the noise to much and not give you accurate results."]},{"i":"ranger2020--optimizer","l":"Ranger2020 Optimizer:","p":["This fork uses the Ranger2020 optim as the default optim instead of the AdamW optim. The Ranger2020 optim is much more complex optim that combines multiple techniques from other optims to be able to provide a more stable and faster convergence then other optims.","The three key components are:","RAdam: An adaptive learning rate method that dynamically adjusts the learning rate based on the variance of the gradients.","LookAhead: A method that improves convergence by interpolating between the current weights and a set of \"lookahead\" weights.","Gradient Centralization: A technique that normalizes gradients to stabilize training and potentially improve generalization."]},{"i":"checkpointing","l":"Checkpointing:","p":["Checkpointing reduces the vram usage, requirement of computation and training speed by 20-30 percent. Enable it If you're an user of a 4GB GPU or if you intend to use a bigger batch size than your gpu can handle."]},{"i":"upcoming-features","l":"Upcoming Features:","p":["More / different configurable optimizers.","Adjustable hop length for RMVPE.","Custom initial learning rate per Generator and Discriminator.","Custom gradient norm value ( from the ui level )","Ability to delay / headstart the Generator or Discriminator.","More warmup options ( Cosine anneal and so on ).","Toggleable mute files.","And more..."]},{"i":"section-3","l":"‎"}],[{"l":"Mainline Colab","p":["Last update: Oct 23, 2024","Mainline colab is a port of mainline RVC to Google Colab, for exclusively training.","It's free, includes all the necessary tools for a quality model, the TensorBoard.","‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"***Learn more***","p":["Has TensorBoard.","Inconvenient.","Takes some time to set up.","You can't leave training unsupervised.","Doesn't have Mangio-crepe.","For free users:","It's slower compared to local RVC.","Can't train long datasets without pausing the process."]},{"i":"section","l":"‎"},{"l":"How to Setup"},{"i":"section-1","l":"‎"},{"i":"1-running-cells","l":"1. Running cells.","p":["Start by accessing the colab here.","Then run the first two cells to install all the requirements."]},{"i":"2-installing-pretrains","l":"2. Installing Pretrains.","p":["If you wish to install a custom pretrain go to the 'Download Custom Pretrains' cell and go into the dropdown menu and find the pretrain you want.","If the pretrain you want isn't there go to the top left and click '+ Code'.","Then in the new cell type in !wget LINK TO PRETRAIN"]},{"i":"section-3","l":"‎"},{"i":"3-ngrok","l":"3. Ngrok.","p":["Scroll down to the fifth cell and you should see a section where you put your ngrok token. If you don't have a ngrok acount sign up here.‎ 2. Once you have an acount you can authenticate your ngrok tunnel agent here: https://dashboard.ngrok.com/get-started/your-authtoken‎","put the Ngrok token in like so:","‎","There is a monthly limit rate with Ngrok so don't be supprised if training is suddenly interrupted."]},{"i":"#","p":["The interface should look like this with your D and G files being located here. Here you can manage your files. Whenever you want to download files from the Imjoy GUI just double click. Downloading files uses up the Ngrok bandwith data."]},{"i":"section-5","l":"‎"},{"l":"Starting RVC"},{"i":"section-6","l":"‎"},{"i":"1-click-the-rvc-link","l":"1. Click the RVC link.","p":["It should take you to the GUI where you can then go to the top and click the 'Train' tab."]},{"i":"2-setup","l":"2. Setup.","p":["Run through the normal RVC setup with setting your model name, sample rate and such. If you are unable to see the 32k sample rate click on V1 then swap back to V2.","Only use V2 Don't use V1 or you will get an error.","In google drive create a folder named training and inside it make another folder named dataset then drag and drop your dataset in it. Then continue with normal RVC setup and training","Make sure you use WAV or Flac files inside. Do not zip the folder."]},{"i":"3-syncing-graphs","l":"3. Syncing Graphs.","p":["For syncing graphs you need to train however many epochs you have set you save frequency then go into the file manager and find your model which should be in training/weights, in its name it should have a step count and epoch count like this: model_name_e(number)_s(number).","E means epochs and S means steps.","Once you know how many steps the model trained for stop training the model by stopping the cell.","Then start the same cell and open then navigate to assest/weights in google colab and delete all of your previous models.","Then navigate to the 32k.json file which is located in the V2 folder of /configs and edit log_interval to the amount of steps your model took, save it.","Now go to your /logs/ folder and do the same thing. Modify the log interval of the config.json with your step count.","Now delete Eval folder, tf-events file, G D_23333333 files and train log file in /logs/ folder."]},{"i":"4-resuming-training","l":"4. Resuming Training.","p":["Do not process and feature extract again because those files are already in the /logs/ folder. Use the same model name, sample rate, batch size, pretrain, and save frequency to train the model again in the RVC GUI."]},{"i":"---","l":"‎ ‎"}],[{"l":"Applio Colab","p":["Last update: June 15, 2024"]},{"i":"section","l":"‎","p":["Applio is a VITS-based Voice Conversion Tool developed by the IA Hispano team.","It's liked for its great UI& lots of extra features, such as TTS (with RVC models too), plugins, automatic model upload, customizable theme & more.","Because of its user-friendly experience & active development, it's considered to be one of the best forks.","As this cloud version is hosted in Google Colab, remember that you have a runtime of 4 hours.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"*Learn more*","p":["Very complete","Has an active development","Currently stable","Very fast","TTS features","Automatic model upload","Has Mangio-Crepe","User-friendly UI","TensorBoard included","Extra features: (plugins, model fusion, etc)","Usage limit for free users"]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎","p":["Access the Colab space here. Then log in to your Google account."]},{"i":"section-3","l":"‎","p":["Execute the Install Applio cell. This will take around 2 minutes.","‎‎","It'll finish when you see a tick symbol on the left."]},{"i":"section-4","l":"‎","p":["If you are going to train models, upload your dataset to your Google Drive storage & run the Extra cell.","‎‎","To save time, unfold it & cancel the custom pretrain download, if you aren't going to use them."]},{"i":"section-5","l":"‎","p":["Grant the permissions to Google Drive.‎‎"]},{"i":"section-6","l":"‎","p":["Execute Start Applio.","‎‎","Then open the public URL."]},{"i":"section-7","l":"‎","p":["Be sure to read the Troubleshooting chapter if any issue arises."]},{"i":"section-8","l":"‎"},{"i":"1-upload-voice-model","l":"1. Upload voice model.","p":["Go to the Download tab. You have two ways of uploading it: through its link or manually inputting its files.","Go to the Download tab & paste the link in the Model Link bar. It must be from Hugging Face or Google Drive.‎‎","Press Download Model.","Below in Drop files, press the upload box & input the model's .PTH.‎‎","Then input the .INDEX.","‎"]},{"i":"2-select-voice-model","l":"2. Select voice model.","p":["Return to the Inference tab & click Refresh on the right.","‎","Select the model in the Voice Model& Index File dropdown."]},{"i":"section-9","l":"‎"},{"i":"3-input-vocals","l":"3. Input vocals.","p":["With Applio you can convert audios individually or in batches:","Press the upload box & input your audio.‎‎‎‎","Then select it in the dropdown below.‎","Go to the Batch tab.‎‎‎","Go to the file explorer in Colab. Go to drive, right-click the folder containing the audios & click Copy Path.","Paste the path in the Input Folder bar.","In Output Folder you can define the path folder for the results.","Ensure the paths don't contain spaces/special characters.","‎"]},{"i":"4-modify-settings-optional","l":"4. Modify settings. (optional)","p":["Unfold Advanced Settings if you wish to modify the inference settings for better results.","‎"]},{"i":"section-10","l":"‎"},{"i":"5-convert","l":"5. Convert.","p":["Click Convert at the bottom to process the audio.","Once it's done, you can hear the results in the Export Audio box below. To download it, press the download symbol on its right.","‎"]},{"i":"section-11","l":"‎"},{"i":"section-12","l":"‎"},{"l":"1. PREPROCESS","p":["Go to the Train tab. Input a name for your model in Model Name. Don't include spaces/special characters.","‎","Upload your dataset to your GD storage if you haven't already.‎","In Colab click the folder on the left ( ) & click the reload button.‎‎‎(For mobile users: tap the three lines on the top left & Show file browser)‎","Open drive, localize your dataset, right-click it & click Copy path.‎‎‎‎","Then paste it on the Dataset Path bar.‎‎","Select your dataset's sample rate. If you don't know the amount, click here.","Ensure RVC Version is set as V2& click Preprocess Dataset.","It'll finish when the output box says preprocessed successfully."]},{"l":"2. EXTRACT","p":["Select the algorithm you want. Use either Crepe or RMVPE, as the rest are outdated.","If you chose Crepe, you can modify its hop length.","Press Extract Features. It'll finish when it says extracted successfully."]},{"l":"3. TRAIN","p":["‎‎‎","‎","But since we'll use TensorBoard, use an arbitrarily large value like 1000","Click Generate Index. This will create the model's .INDEX file.","Disconnect from your Internet.","Don't solve the captchas that (might) pop up occasionally.","E.g: with a value of 10, they will be saved after the epoch 10, 20, 30, etc.","Frequency of the saving checkpoints, based on the epochs.‎","If after around 2:30 hours of training you don't detect OT download the model of the lowest point, in case it's already OT, and the .INDEX.‎","If you are a newbie, simply leave it at 15.","If you are a newbie, use 8. But in case your dataset is short (around 2 minutes or less), use 4.","Input the total amount of epochs(training cycles) for the model.‎","Press Start Training below to begin the training process.‎‎","Run out of GPU runtime.","Stay AFK for a long time.","TB will be available in the Colab. Remember to monitor it, as well as the cell's logs just in case.","The latter will show you errors if they happen, and information about the epochs & checkpoints.‎‎‎‎","Then once your GPU runtime resets, begin the retraining procedure.","Tick Save Only Latest"]},{"l":"4. DOWNLOAD","p":["When you're very sure of overtraining, you can stop training by going to the Settings tab & press Restart Applio.","‎‎","Come back to the Colab & open the new public URL.","Open the file explorer, go to logs, and open the folder named as the model.‎","Download the .INDEX named added_.‎‎‎","In said folder you'll also find all the checkpoints.‎","Select the one closest to before the overtraining point, and move it to the new folder.","The checkpoints will be organized with this format: ModelName_Epoch.pth Example: arianagrande_60e.pth‎‎‎‎","You can determine the Step number of the checkpoints by looking at its epoch number on the logs.","‎‎‎","And that's all, have fun with your model. To test it, do a normal inference as usual."]},{"l":"5. RESUMING","p":["In case the training finished but the model still needed training, you don't have to start from scratch.","Simply enter the same settings & criteria that you had previously inserted. You don't have to do preprocess, extract feature or train the .INDEX again.‎","You can change the save frequency or increase the Total Epoch amount, in case you didn't input enough before.‎","If you're resuming from a new session, unfold the Extra cell in Colab & input the model name you assigned before.‎‎‎","For this, the Auto Backup cell must've ran in the previous session.‎‎","Begin training again & remember to monitor [TB]https://docs.ai-hub.wtf/rvc/resources/training/#tensorboard) as before."]},{"i":"section-47","l":"‎"},{"i":"section-48","l":"‎","p":["+ with any RVC model"]},{"i":"section-49","l":"‎","p":["Applio is also known for having one TTS tool by default, with plenty of voices to choose for.","You can also use it with RVC models& apply the inference settings if you wish.","Additionally, you can download the Eleven Labs TTS plugin."]},{"i":"section-50","l":"‎"},{"i":"instructions","l":"Instructions:","p":["Go to the TTS tab.","‎"]},{"i":"section-51","l":"‎","p":["If you want to use an RVC model, download it, go to TTS, click Refresh& select it in Voice Model& Index File.","‎‎","To modify the inference settings or the output folder for the TTS/RVC audio, unfold Advanced Settings."]},{"i":"section-52","l":"‎","p":["In TTS Voices select the voice of your desired language, accent & gender.","In Text to Synthesize input your text. Then click Convert.","‎‎","If you are using an RVC model, select a voice that matches the model the most, to guarantee great results."]},{"i":"section-53","l":"‎","p":["Once it's done, you'll be able to hear the result in the Export Audio box. To download it, click the download button on its right ( )."]},{"i":"section-54","l":"‎"},{"i":"section-55","l":"‎"},{"i":"section-56","l":"‎","p":["Applio has an Extra menu, containing an audio analyzer, F0 Curve and Model Information.","Making it convenient for determining the sample rate of datasets when training models.","It also contains the model fusion tool, ideal for advanced users."]},{"i":"section-57","l":"‎"},{"i":"audio-analyzer","l":"Audio Analyzer:","p":["Go to the Extra tab & press the upload box to input your audio.","‎"]},{"i":"section-58","l":"‎","p":["Once it's done uploading, click Get information about the audio."]},{"i":"section-59","l":"‎","p":["In Sampling rate you'll see the audio's full sample rate. Use said value for training."]},{"i":"section-60","l":"‎","p":["If the frequencies don't reach the top of the spectrogram, see at which number peaks & multiply it by 2."]},{"i":"section-61","l":"‎","p":["‎‎","Here it reached 20 kHz. Doubling it gives 40kHz. Therefore the ideal target sample rate would be 40k"]},{"i":"section-62","l":"‎"},{"i":"section-63","l":"‎","p":["Plugins are components that you can add to Applio, that add new features & enhance your experience.","These are made by the public, and are free & easy to install.","You can find them on their GitHub page. More will be added in the future."]},{"i":"section-64","l":"‎"},{"i":"installation","l":"Installation:","p":["Access their GitHub page & click on the name of the plugin you want.","‎"]},{"i":"section-65","l":"‎","p":["Click on the ZIP file.","‎‎","Click on the download button on the right. This will download the ZIP file of the plugin."]},{"i":"section-66","l":"‎","p":["Open Applio & head over to the Plugins tab. Press the upload box & upload the ZIP."]},{"i":"section-67","l":"‎","p":["Go to the Settings tab & click Restart Applio at the bottom. Go back to the Colab & open the new public URL.","Then you'll be able to see the plugin in the Plugins tab."]},{"i":"section-68","l":"‎"},{"i":"section-69","l":"‎"},{"i":"section-70","l":"‎"},{"i":"there-s-no-public-url","l":"*There's no public URL.*","p":["In case the public URL doesn't show up, there might be a problem with Gradio, you can check if it's down here.","To fix this, instead of waiting until Gradio is back online, just check the share_tunnel* checkbox on the Start Applio cell.","‎","Applio will use localtunnel instead of the Gradio Public Share Link now, copy paste the Password IP(Don't worry, it's the Google PC's IP, not yours).","Then open the Share Link given by the colab and paste the \"Password IP\" in \"Tunnel Password\", finally click Submit."]},{"i":"there-s-no-option-for-my-sample-rate","l":"*There's no option for my sample rate.*","p":["If it's lower than 32k: select 32k.‎","If it's 44.1k: select 40k.‎","If i'ts higher than 48k: select 48k."]},{"i":"the-voice-glitches-out","l":"*The voice glitches out.*","p":["This a phenomenon called artifacting. To fix it, read here."]},{"i":"cannot-connect-to-gpu-backend","l":"*Cannot connect to GPU backend.*","p":["You have exhausted the GPU runtime of Colab."]},{"i":"i-couldn-t-find-my-answer","l":"*I couldn't find my answer.*","p":["Report your issue here."]},{"i":"section-76","l":"‎"}],[{"l":"Ilaria RVC Zero","p":["Last update: Oct 25, 2024"]},{"l":"Introduction","p":["This is a fork of mainline RVC running on Hugging Face Spaces, it’s called this way because it runs on Hugging Face’s ZeroGPU, which currently is an A100 GPU.","Here is the link to the space Ilaria RVC Zero.","This space is only for inference which means you can not train a model here."]},{"l":"Model Downloader","p":["Go to any RVC Hugging Face Models and get the Download link by going to the “Files and versions” tab, then right click the Download icon next to the .zip file, and click copy address link, like in the image","‎","Then go to the “Model Loader” tab in the space and click on “Model Downloader”, paste the link into the Model URL give the model a name and click “download model”."]},{"l":"Inference","p":["After you finally uploaded the model, go to the “Inference” tab, and upload the audio which vocals you want to convert to the model’s voice. Click “Refresh Models” and in the “Model” dropdown menu choose yours then click “Convert”.","Then after you get your output, just click on the Download Icon at the top right of the audio file."]},{"l":"Inference Settings","p":["Settings (Inference) While converting, you might have issues of the output pitch may not be the same as the model one, but that’s a thing you can easily fix with the settings!","Go to the “Inference” tab, click on “Settings”, i will explain you the important settings that you may wanna change:","Pitch level: if the output pitch seems different than the model’s pitch, you need to play around with this:","Lower value = male, deeper.","Higher value = female, higher voice tone.","Index influence: How much accent (the one from the .index file) is applied:","Lower value = Less accent of the model’s voice, but helps to reduce artifacting (noises).","Higher value = More accent of the model’s voice, but could have artifacting (depends on the model’s dataset, as the index file depends on it).","For the rest of the settings, you don’t need to change them, leave them as they are."]},{"l":"Ilaria TTS","p":["Go to the “Inference” tab, click on “Ilaria TTS” write all the text you want in “Text”, choose an Edge TTS Model in “Language and Model”, it’s suggested to use one that has the same language and gender of the RVC mode.","b Click on “Speak”, it will generate a TTS audio with the original Edge TTS Model, and then automatically using it as an input"]},{"l":"Errors","p":["ZeroGPU HuggingFace Spaces have a max inference time duration, it’s the time it takes to do an Inference (use the model, not the time of your audio file itself), on default it’s around 1 minute which is what Ilaria RVC uses. You need to retry with a shorter audio, you could also split your audio.","ZeroGPU HuggingFace Spaces have a quota per account, if you aren’t signed in you will get less quota so it’s better to login for more quota. You could get the ‘Sign-up’ part even if you are logged in. The ZeroGPU Quota can’t be seen but it isn’t unlimited. You can either:","Login so you get more quota","Wait","Pay to be an HuggingFace PRO Member to get X5 times more quota","As all ZeroGPU Spaces share this hardware, there might be times where ZeroGPU is busy, if you ever go through this error, you just need to wait a bit and retry.","Ilaria RVC Zero got a limit for the Model Upload Size, if you run into this either use another model."]},{"i":"---","l":"‎ ‎"}],[{"l":"Mainline Kaggle","p":["Last update: Oct 23, 2024"]},{"l":"Introduction","p":["Kaggle is a cloud platform for using AI apps, powered by virtual machines with powerful GPU's.","It's a great alternative for training RVC voice models through the cloud, since it has the best GPUs.","You only get 30 free GPU hours per week."]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"***Learn more***","p":["Has good GPU's","Has 30 GPU hours","Fast","TensorBoard included","You can leave training unsupervised.","Takes some time to set up.","Doesn't have Mangio-Crepe"]},{"i":"section","l":"‎"},{"l":"How to Setup"},{"i":"section-1","l":"‎"},{"i":"1-set-up-account","l":"1. Set up account.","p":["Start by making an account here.","Verify your acount with a phone number so you can turn on the \"internet\" option."]},{"i":"2-clone-notebook-and-setup","l":"2. Clone notebook and setup.","p":["Go to Hina's mainline notebook and click \"Copy and Edit\"","Under session settings in the sidebar turn on \"internet\". Make sure persistance is on for both files and varibles.","Turn on T4 X2 GPUs in accelerator.","d: (Optional) Turn on headless mode so you can run so you can run the GPU on all sessions and save your progress. Go to the top right and click \"Save version\" then open the advanced dropdown.","‎","Your runtime will continue draining when you're not running any cells with this option on."]},{"i":"section-3","l":"‎"},{"i":"3-ngrok","l":"3. Ngrok.","p":["Scroll down to the fifth cell and you should see a section where you put your ngrok token. If you dont have a ngrok acount sign up here.‎ 2. Once you have an acount you can authenticate your ngrok tunnel agent here: https://dashboard.ngrok.com/get-started/your-authtoken‎","put the Ngrok token in the quotation marks like so:","There is a monthly limit rate with Ngrok so dont be supprised if training is suddenly interrupted."]},{"i":"3-starting-the-cells","l":"3. Starting the Cells.","p":["From top to bottom execute all the cells. With first being:","The second cell will take ~ 5 minutes to load.","when its finished it will look like this:","If you want to use a pretrain now is the time to download it. Add a new code cell and type this in then run it:"]},{"i":"#","p":["!wget LINK TO PRETRAIN","Run the third cell.","Once you run the final cell it will give you three links.","RVC url: is to open RVC's gui.","File url: is to open Imjoy Elfinder gui.","Tensorboard: is to open the Tensorboard.","The interface should look like this with your D and G files being located here. Here you can manage your files within Kaggle. Whenever you want to download files from the Imjoy GUI just double click. Downloading files uses up the Ngrok bandwith data."]},{"i":"section-6","l":"‎"},{"l":"Starting RVC"},{"i":"section-7","l":"‎"},{"i":"1-click-the-rvc-link","l":"1. Click the RVC link.","p":["It should take you to the GUI where you can then go to the top and click the 'Train' tab."]},{"i":"2-setup","l":"2. Setup.","p":["Run through the normal RVC setup with setting your model name, sample rate and such. If you are unable to see the 32k sample rate click on V1 then swap back to V2.","Only use V2 Don't use V1 or you will get an error.","In the file manager create a folder named dataset anywhere then drag and drop your dataset in it. Then continue with normal RVC setup and training"]},{"i":"3-syncing-graphs","l":"3. Syncing Graphs.","p":["For syncing graphs you need to train however many epochs you have set you save frequency then go into the file manager and find your model which should be in assest/weights, in its name it should have a step count and epoch count like this: model_name_e(number)_s(number).","E means epochs and S means steps.","Once you know how many steps the model trained for stop training the model by stopping the cell.","Then start the same cell and open the file manager and navigate to assest/weights and delete all of your previous models.","Then navigate to the 32k.json file which is located in the V2 folder of /configs and download it by double clicking it, then delete it.","Open the file you have just downloaded in notepad and edit log_interval to the amount of steps your model took, save it then replace the old 32k.json file.","Now go to your /logs/ folder and do the same thing. Modify the log interval of the config.json with your step count. Delete the config.json that's already in the /logs/ folder and replace it with your copy.","Now delete Eval folder, tf-events file, G D_23333333 files and train log file in /logs/ folder."]},{"i":"4-resuming-training","l":"4. Resuming Training.","p":["Do not process and feature extract again because those files are already in the /logs/ folder. Use the same model name, sample rate, batch size, pretrain, and save frequency to train the model again in the RVC GUI."]},{"i":"---","l":"‎ ‎"}],[{"l":"RVC Disconnected","p":["Last update: Mar 8, 2024"]},{"i":"section","l":"‎"},{"i":"section-1","l":"‎","p":["RVC Disconnected (or RVC-D) is a port of Mangio to Google Colab, for exclusively training. Notebook made by Kit Lemonfoot.","It's free, includes all the necessary tools for a quality model, the TensorBoard, & it's the fastest Colab space for training.","Making it the go-to method for training for cloud RVC users. Pretty much the only big downside is the time limit (but you can switch to another account & continue).‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"***Learn more***","p":["Has TensorBoard.","Has Mangio-Crepe.","Option to save model to HF.","Includes the latest pretrains.","Inconvenient I.","Takes some time to set up.","You can't leave training unsupervised.","For free users:","It's slower compared to local RVC.","Can't train long datasets without pausing the process."]},{"i":"section-2","l":"‎","p":["1.‎ The guide is centered around the TensorBoard. Read it first if you haven't already. 2. Turn on third-party cookies, or TB might not work."]},{"i":"section-4","l":"‎"},{"l":"1. Prepare dataset","p":["Make a folder named after your model & move the dataset inside of it. Don't include spaces/special characters.","‎‎","Then zip the folder as a .ZIP file. .7ZIP and .RAR aren't compatible with RVC-D.","REMINDER: With modern versions of RVC, the dataset can be a single audio file. No need to split it."]},{"i":"section-5","l":"‎"},{"l":"2. Set up Colab","p":["Head over to the Colab space& Sign in to your Google account.","Execute the Dependencies cell & press Run anyways","‎‎","When this appears, press Connect to Google Drive& select your account.","Once the cell is done loading, in GD go to the rvcDisconnected folder, and place the dataset's .ZIP inside of it.","‎"]},{"i":"section-6","l":"‎"},{"i":"section-7","l":"‎"},{"i":"section-8","l":"‎"},{"l":"1. Training variables","p":["Go to the Set Training Variables cell.","‎‎","Name your model. Don't include spaces/special characters.","If you aren't familiar with pretrains, select original.","Select your dataset's sample rate.","The extraction method. Don't use Harvest, as it's obsolete.","If you chose Mangio-Crepe, this defines the Hop Length."]},{"i":"section-9","l":"‎"},{"l":"2. Set the environment","p":["‎ ‎ ‎ ‎ ‎ ‎ ‎ ‎‎","Go to Load Dataset cell. In the dataset bar type the dataset's .ZIP name followed by .zip, then execute the cell. Example: kalomaze.zip","Below, execute Preprocessing, Feature Extraction, & Save preprocessed dataset files to Google Drive.","‎"]},{"i":"section-10","l":"‎"},{"l":"3. Train Index","p":["Run Index Training to create the model's .INDEX file.","‎‎","To download it, in GD open rvcDisconnected& the folder named after the model. Download the .INDEX named added.","‎"]},{"i":"section-11","l":"‎"},{"l":"4. Set Training","p":["Go to the Training cell.","‎‎","Frequency of the saving checkpoints, based on the epochs. If you're a newbie, simply leave it at 15. E.g: with a value of 10, it will be saved after the epoch 10, 20, 30, etc.","The total amount of epochs for the model. But since we'll use TensorBoard, use an arbitrarily large number like 2000.","Use 8 if you are a newbie. But if your dataset is small (around 2 minutes or less), use 4."]},{"i":"section-12","l":"‎"},{"l":"5. Begin training","p":["Execute the Training cell to begin training. TB will open up after a few seconds, & the graphs will take a minute to appear.‎","Remember to monitor it, as well as the cell's logs. The latter will show you errors if they happen, and information about the epochs & checkpoints.‎","While training, you might get disconnected if you:","Stay AFK for a long time.","Disconnect from your Internet.","Don't solve the captchas that (might) pop up occasionally.","Run out of GPU runtime."]},{"i":"section-13","l":"‎"},{"l":"6. Export model","p":["If after around 2:30 hours of training you don't detect overtraining, you must save the files so you can resume later, before the GPU runtime ends.","For this, first download the model of the lowest point ( Step 7b) in case you are already overtraining.","Stop training by pressing the stop button of the Training cell.","Run the Export Model from Notebook to Drive cell.","‎‎","Once your GPU runtime resets, begin the retraining procedure.","After exporting, you are free to resume training until runtime is exhausted or close the session."]},{"i":"section-14","l":"‎"},{"i":"7-download-model","l":"7. Download model.","p":["When you're very sure of overtraining, you can stop training by pressing the stop button of the Training cell.","Click the folder symbol on the left.(For mobile users: tap the three lines on the top left & Show file browser)","Open the Mangio-RVC-Fork folder, then weights. You'll find the checkpoints.","‎‎","Right-click the one that's closest to before the overtraining point, and press Download.","The models will be organized with this format: Name_Epoch_Step.pth. E.g: arianagrande_e60_s120.pth‎","And that's all. To test it, do a normal inference as usual."]},{"i":"section-17","l":"‎","p":["If the training stops but the model still needed training, you don't have to start from scratch.","You can resume from the latest checkpoint. But for this, the cell Save preprocessed dataset files to Google Drive must have executed prior to training.","And if you're resuming from a new session, you should've ran the Export Model from Notebook to Drive cell in the previous session."]},{"i":"section-18","l":"‎"},{"i":"instructions","l":"Instructions:","p":["Go to the Colab space, input the same criteria as before & execute the cells like normal, except Preprocessing & Feature Extraction.","Execute the Load preprocessed dataset files cell.","‎","Go to the Import Model from Drive to Notebook cell. In STEPCOUNT introduce 2333333& execute it.","You can change the save frequency or increase the total epochs, in case you didn't input enough before.","Run the Training cell to retrain. Remember to monitor TB as before."]},{"i":"section-19","l":"‎"}],[{"l":"AICoverGen","p":["Last update: Mar 4, 2024‎"]},{"i":"section","l":"‎","p":["The AICoverGen Colabs are a port of the AICoverGen RVC fork to Google Colab.","These are ideal for users who want ' quick & dirty' AI covers, as the whole process of inputting audio, vocal isolation & song mixing is automated.","The pitch control is limiting & inconvenient, so if you want a Colab with more control over it, use Ilaria RVC instead."]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎"},{"l":"Description","p":["This is the version of the port that doesn't have the premade user interface. Credits to Eddy & Raid. Base notebook by Ardha27.","It's an upgrade from the original Colab space, bringing bug fixes, improvements, & extra features.","The NO UI counterpart is mainly preferred due to being more stable compared with the UI version.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"*Learn more*","p":["Automatic vocal extraction.","Song mixing tool.","Has Mangio-Crepe.","Automatic model upload.","Input audio with YouTube links.","Can get the stems files.","More stable.","Usage limit for free users.","Takes 6 mins to load.","UI is incovenient.","No control over the stem separation.","The extraction will always run, you'll waste time if you input clean vocals.","Little control of the mixing tools.","Limited pitch control."]},{"i":"section-3","l":"‎"},{"l":"Setting Up"},{"l":"1. Enter the space","p":["Access the Colab space here. Then Sign in to your Google account."]},{"i":"section-4","l":"‎"},{"l":"2. Clone and Install","p":["Execute the Clone and Install. This will install RVC.","‎‎","It will take around 15 minutes. It'll be done when you see a check symbol (✔️) on the corner.","Don't worry if red text appears, it's normal."]},{"i":"section-5","l":"‎"},{"l":"Inference"},{"l":"1. Download model","p":["Go to Model Download Function cell. Paste the model's link in the url bar.","In dir_name name the model. Don't include spaces/special characters.","Then execute the cell.","‎","Downloaded models will be saved until the Colab session ends."]},{"i":"section-6","l":"‎"},{"l":"2. Input the audio","p":["Input the vocals/song in the Generate Cover cell.","You can go about it with either a YouTube link or a Google Drive file:","Copy a YouTube link and paste it in the SONG_INPUT bar.","‎","Execute the Mount Drive cell below.‎‎","Click Connect to Google Drive& select your Account.‎","Click the folder symbol ( ) on the left.(For mobile users: tap the three lines on the top left & Show file browser)","Go to drive& you'll find your GD storage. Right-click your audio & press Copy path.‎","Paste the path in the SONG_INPUT bar.‎"]},{"i":"section-10","l":"‎"},{"l":"3. Select model","p":["In RVC_DIRNAME insert the model's name you assigned before."]},{"i":"section-11","l":"‎"},{"i":"4-modify-settings-optional","l":"4. Modify settings (optional)","p":["Below RVC_DIRNAME until Audio Mixing Options you'll find the inference settings. Tweak them accordingly for better results if you wish.","‎"]},{"i":"section-12","l":"‎"},{"i":"5-modify-mix--reverb-optional","l":"5. Modify mix & reverb (optional)","p":["In Audio Mixing Options you can modify the values to define the volume of main/backing vocals & instrumental.","‎‎","In Reverb Control you can add reverb to the output vocals.‎‎‎"]},{"i":"reverb-control-options","l":"*Reverb Control options:*","p":["How \"wide\" the reverb sounds, like the size of a room.","Volume of the reverb itself.","Volume of the vocals.","Level of absorption of the reverb's high frequencies:","Higher values yield a warmer, natural-sounding reverb.","Lower ones sound brighter & more present."]},{"i":"section-13","l":"‎"},{"l":"6. Begin inferring","p":["Execute the Generate Cover cell to begin the conversion.","It'll be done when the logs say Cover generated at followed by the file path."]},{"i":"section-14","l":"‎"},{"l":"7. Download output","p":["Click the folder symbol ( ) on the left.(For mobile users: tap the three lines on the top left & Show file browser)","Open song_output folder & the one inside it. Right-click the first file & press Download. The other audios are the stems. Download them too if you wish.","‎"]},{"i":"section-15","l":"‎"},{"i":"section-16","l":"‎"},{"i":"section-17","l":"‎"},{"l":"Description","p":["This is the version that's built with the premade user interface. Port by Hina. Original repo by SociallyIneptWeeb.","It's characterized & preferred due to its intuitive UI, ideal for beginners.","But on the downside, it may be more buggy, so consider using the NO UI version if issues arise.‎"]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"*Learn more*","p":["Automatic vocal extraction.","Song mixing tool.","Has Mangio-Crepe.","Automatic model upload.","Input audio with YouTube links","Great UI.","Can get the stems files.","Quicker audio file upload.","Usage limit for free users.","Takes 6 mins to load.","No control over the stem separation.","The extraction will always run, you'll waste time if you input clean vocals.","Little control of the mixing tools.","Inconvenient pitch control.","More unstable."]},{"i":"section-18","l":"‎"},{"l":"Setting Up"},{"i":"1-enter-the-space-1","l":"1. Enter the space","p":["Access the Colab space here.","Then login to your Google account."]},{"i":"section-19","l":"‎"},{"l":"2. Define pitch","p":["In the Clone Repository cell, select the pitch change.","‎‎","If you're going to use models of the same gender as the vocals, use 1.","If they're of opposite gender, use 12","To change this, you'll have to start the Colab from scratch."]},{"i":"section-20","l":"‎"},{"l":"3. Run cells","p":["Then go to Runtime on top & press Run all."]},{"i":"section-21","l":"‎"},{"l":"4. Open UI","p":["After a moment the Run WebUI cell will show two links. Open the public URL one.","‎"]},{"i":"section-22","l":"‎"},{"l":"Inference"},{"l":"1. Upload model","p":["You can upload it using its link or manually inputting its files.","Go to the Download model tab & paste the model link in the bar.","Name it in Name your model. Don't introduce spaces/special characters.","Click Download.","Zip the model into a .ZIP file, if you haven't already.","Go to the Upload model tab, press the upload box & submit the ZIP.","Name it in Model name. Don't introduce spaces/special characters.","Press Upload model."]},{"i":"section-23","l":"‎"},{"l":"2. Select model","p":["Return to the Generate tab & press Refresh Models. Then select it in the Voice Models dropdown."]},{"i":"section-24","l":"‎"},{"l":"3. Select audio","p":["On its right, input the YouTube link.","‎‎","Or, press Upload file instead, click Upload& input the audio file."]},{"i":"section-25","l":"‎"},{"i":"4-modify-settings-optional-1","l":"4. Modify settings (optional)","p":["Unfold Voice conversion options to modify the inference settings for better results."]},{"i":"section-26","l":"‎"},{"l":"5. Select output format","p":["Unfold Audio mixing options& set Output file type as wav, for a better quality output.","‎‎","Modify the mix too if you wish."]},{"i":"section-27","l":"‎"},{"l":"6. Convert","p":["Press Generate. The audio will begin processing.","Once it's done, you can hear the results in the AI Cover output box.","To download it, press the download symbol ( ) on its right."]},{"i":"section-28","l":"‎"},{"i":"7-download-stems-optional","l":"7. Download stems (optional)","p":["To download the stems, go to Colab & click the folder symbol ( ) on the left.(For mobile users, tap the three lines ( ) on the top left & Show File Explorer)","Go to Hina_RVC, song_output, open the new folder, right-click the stem you wish & click Download.","‎‎"]},{"i":"section-29","l":"‎"}],[{"l":"Applio Lighting Ai","p":["Last update: Nov 21, 2024"]},{"l":"Introduction","p":["Lighting.Ai is a cloud platform for using AI apps, powered by virtual machines with powerful GPU's.","It's a great alternative for training RVC voice models through the cloud, since it has the best GPUs with tons of VRAM.","Lighting doesn't have the best GPU hours but it does have the best GPUs out of all the other cloud options."]},{"i":"pros-cons","l":"Pros & Cons"},{"i":"learn-more","l":"***Learn more***","p":["Has good GPU's.","Has lots of VRAM","TensorBoard included.","You can leave training unsupervised.","Takes some time to set up.","Needs a phone number.","Low GPU time depending on what GPU you choose.","2-3 Day verification wait time."]},{"i":"section","l":"‎"},{"l":"How to Setup"},{"i":"section-1","l":"‎"},{"i":"1-set-up-account","l":"1. Set up Account.","p":["First make an acount with Lighting Ai","‎","Make sure you verify yourself with a phone number. Once you've done that you will get an email that looks like this:","You will need to wait 2-3 business days to become fully verified","Once you are verified Lighting Ai will send you a email that conatins this:"]},{"i":"2-notebook-and-setup","l":"2. Notebook and Setup.","p":["Once you have become verified click this link and it will take you to the Applio notebook. Once you're there click Open in Studio","‎","Once you're there wait for it to finish duplicating the notebook and installing everything it needs, which will be showen at the top.","After it's all done click on this on the left:","Once you have clicked that it will take you to a screen which has the install and run cells on it, run the Install cell by clicking on it then clicking the run button on the top.","After that run the Run cell and once it is done it will look like this:"]},{"i":"section-3","l":"‎"},{"l":"Using Applio"},{"i":"section-4","l":"‎"},{"i":"1-open-the-gardio-link","l":"1. Open the Gardio link.","p":["To access Applio's UI click on the link next to Running on public URL:, after that it is basically the same as using Applio locally or on other cloud platforms."]},{"i":"2-accessing-files","l":"2. Accessing Files.","p":["To upload a dataset, upload audio or anything else find the Teamspace Drive button on the right and click it.","‎","The path to Applio is Studio this_studio Applio Applio","Once you're there you can just drag and drop files.","To download files click on the file then click the three dots on the right of it and click download"]},{"i":"3-opening-the-tensor-board","l":"3. Opening the Tensor Board.","p":["Find the Tensor board icon on the right side bar and click it.","‎","Once you've done that it will open the Tensor board. To learn how to use it go here"]},{"i":"4-opening-the-notebook","l":"4. Opening the notebook.","p":["If you want to go back to the notebook simply click on the Jupyter icon on the right.","‎"]},{"i":"section-5","l":"‎"},{"l":"How to use Better GPUs"},{"i":"section-6","l":"‎"},{"i":"1-swapping-gpus","l":"1. Swapping GPUs.","p":["To swap GPUs go to the GPU icon the the righ and click it.","‎","Then click on GPU and it will show you a list of GPUs you can use by clicking on them and then clicking request.","22 hours monthly of T4 16gb","21 hours monthly of L4 24gb","8 hours monthly of A10G 24gb","6 hours monthly of L40 48gb"]},{"i":"---","l":"‎ ‎"}],[{"l":"Dataset Making","p":["Last update: Dec 24, 2024","‎","In this massive guide it will be explained how to properly prepare a dataset to make a RVC model.","In the field of AI, it's the collection of data used to train an AI model. It contains examples of the inputs the model is expected to handle, along with the correct outputs.","In the context of RVC, it's an audio file that's given to RVC, containing the voice the model is going to replicate. It can be a speaking, singing voice drums, sound effects or noise.","The quality, variety& length of the dataset are the biggest determining factors for the final quality of the model. Let's explain Length and Variety.","For beginners we recommend sticking with a dataset length of 15 minutes of pure data not counting silence, or if you desire a natural sounding model go for 40+ minutes of dataset. Just remember quality over quantity.","Variety in your dataset is also important because without it RVC lacks the ability to generate diverse audio.","Some things to increase the generalization abilities of RVC and increase the diversity in your dataset include:","Removing repeated words. ( If you want you can be extreme you can do this and remove every single repeated word that's fine, but generally there is no need to do this. )","Include speech in many ranges and pitches.","Longer datasets.","Expressive speech","A quality dataset is super important for RVC since without one RVC will struggle to make anything good or believable."]},{"i":"section","l":"‎"},{"i":"clean-vocals","l":"Clean vocals.","p":["Ensure there isn't much background noise, reverb, overlapping voices, music, distortion, or small silences. Some quiet natural background noise is fine and won't ruin your model since the original pretrains for RVC were made with a noisy dataset, so RVC knows how to deal with noise. You'll learn more on cleaning vocals in the Vocal Isolation & Cleaning section below.‎"]},{"i":"audio-quality","l":"Audio quality.","p":["The higher the audio quality, the better. If possible have it in a lossless format like WAV or FLAC, not a lossy one like MP3. No converting a MP3 to a FLAC or WAV won't remove the compression.‎"]},{"i":"no-harsh-sibilance-popping","l":"No harsh sibilance/popping.","p":["Additionally, don't include harsh sibilance (loud \"S\" & \"SH\" pronunciation) or popping sounds (loud \"P\" sound)","Robotic sibilances are due to your dataset being short. You can fix this by making your dataset larger","Harsh sibilances are due to your dataset having harsh sibilants. You can fix this by de-essing or making your dataset larger‎"]},{"i":"no-audio-damage","l":"No Audio Damage.","p":["The most inportant part of a clean dataset, if your audio is damaged RVC will struggle with it causing it to overall sound worse because RVC will create synthetic data and try to learn from it, so make sure your audio isn't damged.‎"]},{"l":"Artifacts","p":["In RVC, artifacting refers to an anomaly where the output voice sounds \"robotic\" & glitchy. This occurs after the inference or model training process."]},{"l":"Causes","p":["It usually occurs when the dataset/vocal sample meets any of these criteria:","• Audio is low-quality• Voice model was overfitted, undertrained or overtrained• There are overlapping voices• There is reverb• There is noise","As you noticed, most of the issues boil down to the audio sample not being properly clean. RVC is built for purely working with voices, not other sounds.","Remember that the cleaner your input audio is, the better the results."]},{"l":"Solutions"},{"i":"1-use-a-lossless-format","l":"1. Use a lossless format:","p":["If possible, it's best if your audio is in a lossless format like WAV or FLAC, preserving its original quality.","Avoid using lossy ones like MP3 or OGG.‎"]},{"i":"2-if-doing-inference","l":"2. If doing inference:","p":["Remove undesired noises with an vocal isolation software.","Lowering the search feature ratio can also minimize this issue.","If breathing sounds produce it, lower the Protection value.‎"]},{"i":"3-if-training-models","l":"3. If training models:","p":["‎","‎‎‎","*A model isn't there.*","*Cleaning Vocals \uD83D\uDDE3️*","*Cleaning Vocals* \uD83D\uDDE3️","*Extracting Vocals From Songs \uD83C\uDFB6*","*Extracting Vocals From Songs* \uD83C\uDFB6","*Extrating Vocals From Songs* \uD83C\uDFB6","*I can't remove some of the backing vocals.*","*I couldn't find my answer.*","*MVSEP extracted too much/too little.*","*UVR extracted too little/too much.*","A higher value will deepen the extraction, and a lower one will soften it.","A vocal isolation app is a software designed to extract a person's vocals from an audio file, usually through the use of AI models.","Access the space here, you don't need an account to use this.","Aggresive","At the right you can select the output format. We recommend picking FLAC. Learn why here.‎","BS Roformer","BS Roformer-Viper-X 1296 / 1297","Check the model list. In Select VR Model pick the one according to what you need to remove.‎ If you need to remove multiple noises, follow this pipeline for the best results: Remove instrumental - Remove reverb - Extract main vocals - Remove noise","Check the model list. Pick the one according to what you need to remove.‎ If you need to remove multiple noises, follow this pipeline for the best results: Remove instrumental - Remove reverb - Extract main vocals - Remove noise","Check the model list& in CHOOSE MODEL pick the one according to what you need to remove.‎ If you need to remove multiple noises, follow this pipeline for the best results: Remove instrumental - Remove reverb - Extract main vocals - Remove noise‎","Chunk Size: 485100","Cleaning Vocals \uD83D\uDDE3️","Click Browse File& select your audio, or simply drag & drop. The audio will begin to upload.","Click Browse File& select your audio, or simply drag & drop. The audio will begin to upload.‎‎‎‎","Click Select input to input the vocals. Or just drag the files to it.‎","Click Select input to select your audio/s. Or just drag the files to it.‎","Click Separate& when it's done converting it will redirect you to a page, where you can listen the results.‎","Click Spererate! below. Wait a moment for the audio to process.‎","Click the Start processing button at the bottom. And that will be all.","Click the wrench (\uD83D\uDD27) on the left & go to Download Center","De-Noise","De-Reverb","DeNoise by aufr33","Download the result located in the output folder.","Each audio is different, so you'll have to test the ideal value.","Ensure to clean your dataset properly, this includes removing silences and distortions.","Errors","Execute the Gdrive Connection cell by pressing the play button . Grant all the permissions.‎‎‎","Extract Backing Vocals","Extract from vocals","Extract vocals","Extraction","First access the Colab space here.‎","First go to X-minus's website and click the \"Vocal Remover\" at the top right.","First, make an account here.‎","For better results, have the audio in a lossless format( WAV or FLAC), & not MP3.","For free users, you can't convert audios in batches or longer than 10 minutes. If that's your case, trim it into different pieces.","For RVC users, the best app is Ultimate Vocal Remover 5 (or UVR). It can be used either locally or through the cloud.","Go to their official website& buy it or sail the seven seas and find a treasure box which contains RX 11.","Go to their official website& press Download UVR. And if you want to use BS Roformer you are going to need to install this.","If you want to remove noise manually to avoid ai artifacts you can use RX 11, which is mentioned in this guide.","If you're extracting lead vocals, remember to download the backing ones if you wish to keep them.","If your GPU is compatible with CUDA, toggle GPU Conversion on for a faster process.","If your GPU is compatible with CUDA, toggle GPU Conversion on for a faster process.‎‎","In \"De-Noise\" select \"Mel-Roformer De-Noise\". You can also check the model list to see what is the best model for your needs.","In CHOOSE PROCESS METHOD select MDX-Net, and select either the BS Roformer-Viper-X 1296 or MDX23C model.","In Google Drive, make two folders, named input& output.‎‎‎","In Output encoding select FLAC. We recommend selecting FLAC from now on. Learn more here.‎","In Output encoding select FLAC. We recommend selecting FLAC from now on. Learn more here.","In Process Method select VR.‎","In Select output you can define the folder for the results.","In Separation type select BS Roformer‎","In Separation Type, select DeNoise by aufr33.‎","It will redirect you their GitHub page. Click the download link for your operating system. UVR is available both on Windows & Mac.","It'll finish once the logs say Mounted at /content/drive‎","Logging in is not mandatory, but recommended for shorter waiting lists.","Login so you get more quota","MDX-Net","MDX23C (De-Reverb)","Mel Roformer De-Noise","MelBand Karaoke","MelBand Roformer","Model","Modify the Aggression Setting value on the right.","Most of the extraction model are behind a pay wall.","MVSEP is a website for isolating vocals, that works similarly as UVR.","Now click the long Start Processing button.","Once it's done it will look like this:","Once it's done uploading, in CHOOSE PROCESS METHOD, select BS/Mel Roformer. Under that you can change Segment Size and Overlap, the defaults are fine.‎‎","Once logged in, go to the main page.","Once the audio is done uploading, click Separate","Once the installer finishes downloading, execute it & follow the instructions. Make sure to tick \uD83D\uDDF9 Create a desktop shortcut for an easier access to UVR.","Overlap: 8","Pay to be an HuggingFace PRO Member to get X5 times more quota","Playable audios will then appear in the output boxes below. To download the output, click the little download icon in the top right.","Process Method","Report your issue here.","Reverb Removal","Reverb removal by anvuew V2 (MelRoformer)","Run the audio through BVE. Modify the Aggression Setting if necessary.","Same thing for the Instrumental, if you wish to keep it.","Select the category of the model (MDX-NET or VR)","Select your model of choice and run the Separation cell. You can look here for the best models","Separation Type","Set Window Size to 320. (optional) Lower Window Size yield a higher output quality, but will take longer to process.‎","So if the output has any undesired noises, follow the procedure on Cleaning Vocals.‎","Tap the Input Audio box & select your audio, or simply drag & drop.‎‎‎‎","Tap the three buttons of the Vocals audio and then Download.‎","Tap the three dots of the audio you need and then Download. If you wish to keep the backing vocals stem, remember to download it too.","The goal is to get an audio sample with clean and natural vocals, which is what RVC needs to give the most accurate & quality results.","The UVR Colab is much faster & convenient for this task. Use MVSEP if you run out of GPU runtime or feel lazy to convert your audio to WAV.","Then click \"select a file\" and choose a audio file, or you can drag and drop a file. And when it's done it will look like this:","Then click the download button (\uD83D\uDCE5). The model will download, which will take a few minutes","Then Log in to your Google account.‎","Then run the Install cell.","Then select \"Music and vocals\" and choose \"Bs Roformer\"","There is a queue so make sure you make an account to skip most of it.","These are the best settings:","They can remove undesired noises, like background noise, reverb, echo, music, etc.","This determines the depth of the extraction. Only the VR method has it.","This step is not mandatory, but recommended for better results.","TIP: To test models/options more efficiently, tick Sample Mode to only process 30 seconds of your sample.","To use RX 11 it is STONGLY recommended that you read this guide on RX 11.","Try running the audio through MelBand Karaoke or BVE. Modify the Aggression Setting if necessary.","Unfold its dropdown & select the model that you need","Using the Separation Type of DeNoise by aufr33, you can modify the Aggressiveness. This determines the depth of the extraction.","Usually songs include reverb & backing vocals. These negatively impact the results in RVC.","Usually songs include reverb & backing vocals. These negatively impact the results in RVC.‎","UVR BVE 2","UVR-BVE-4B_SN-44100-1","UVR-DeEcho-DeReverb","UVR-DeNoise","ver 2024.10","Vocals/Instrumental","VR","Wait","When it's done converting it will redirect you to a page where you can listen the results.","You can now click \"Vocals\" to download the vocals and \"Other\" to download the instrumentals.","You have exhausted the GPU runtime of Colab.","You'll require great specs & GPU to run it effectively. Otherwise, use either the google colab version or the Huggingface space.","ZeroGPU HuggingFace Spaces have a max inference time duration, it’s the time it takes to do an Inference (use the model, not the time of your audio file itself), on default it’s around 1 minute which is what Ilaria RVC uses. You need to retry with a shorter audio, you could also split your audio.","ZeroGPU HuggingFace Spaces have a quota per account, if you aren’t signed in you will get less quota so it’s better to login for more quota. You could get the ‘Sign-up’ part even if you are logged in. The ZeroGPU Quota can’t be seen but it isn’t unlimited. You can either:"]},{"i":"step-1-find-the-sample-rate","l":"Step 1: Find the Sample Rate","p":["‎","And finally, introduce these values:","Bit depth: 24 bit","Download and install Spek here.","Download this: Dataset Making","for example it would look something like this python split_audio.py C:\\Users\\dawnm\\Downloads\\dataset.wav C:\\Users\\dawnm\\Desktop\\split\\ 32000 3 0.3.","Format: FLAC","Go go to Effects -> Volume and Compression -> Loudness Normalization","Go to Effects -> Special -> Truncate Silence","If the frequencies don't reach the top of the spectrogram, see at which number peaks & multiply it by 2. Here it reached 20 kHz. Doubling it gives 40kHz. Therefore the ideal target sample rate would be 40k","If you get an error saying something is missing simply type pip install librosa numpy scipy tqdm.","If you use this method you have to disable the slicer and post processing in Applio.","Level: 8","LUFS are used over db because hifigan needs perceptual quality and db doesnt offer that.","On the upper right corner go to File and click Export Audio.‎‎‎","Open spek and just drag & drop audio into it.","The most common sample rates are 32, 40, 44.1, & 48. The higher the sample rate, the more information it stores, therefore the higher the quality.","Then once it's done go into the folder where you told it to export all of the slices to, then copy / cut all of the files there are place them into your dataset folder.","Then place it in Applio's root folder. Then type cmd into the top bar where it shows your location.","Then type this into the cmd line python split_audio.py wavfilelocationhere exportfolderhere sampleratehere 3 0.3.","This is a unit in that defines the total amount of samples(data) that can fit within 1 second of an audio. They are measured in kilohertz (kHz).","Use the following values:‎","Use these values:‎","While training in RVC, you'll have to set the target sample rate as your dataset's. This value affects the final quality."]}],[{"l":"Training","p":["Last update: Dec 24, 2024","In this guide it will be explained how to properly train a model from start to finish.","Properly training a model is just as important as having a great dataset.","It won't be explained how to prosess a dataset and how to acutally train a model since that is difference from fork to fork, please look at the guide for your fork to find this info.","\"Epoch\" is a unit of measuring the training cycles of an AI model.","In other words, the amount of times the model went over its dataset and learned from it."]},{"i":"how-many-epochs-should-i-use-for-my-dataset","l":"How many epochs should I use for my dataset?","p":["There isn't a way to know the right amount previous to training. It depends on the size, length & quality of the dataset.","If you aim towards a quality model, it's not convenient to input a semi-arbitrary amount of epochs, as it makes it prone to underfitting/overtraining. (explained later)","So it's best to use TensorBoard. WIth it you can determine exactly for how long you should train. (explained later)"]},{"i":"do-more-epochs-equal-a-better-model","l":"Do more epochs equal a better model?","p":["It doesn't, since using a disproportionate amount will overtrain the model, which will affect the quality of it.","In the field of AI, is when an AI model learns its dataset too well, to the point where it centers too much around it & starts replicating undesired data.","The model performs very well with data of the dataset, but poorly with new data, as it has lost its ability to replicate anything that deviates from it.","It happens when the model is trained for too long/is too complex. So to avoid this, RVC users use a tool called TensorBoard."]},{"i":"what-is-overtraining","l":"What is overtraining?","p":["Overtraining also know as overfitting is where the model doesn't actually learn the underlying patterns of the data and memorizes them instead.","A sign of overfitting is when the sibilances are super robotic or when the graphs in the Tensorboard are going up."]},{"l":"Batch Size","p":["A batch size is the number of training examples used in one iteration before updaing the model's parameters.","A smaller batch size ( Less then 8 ) is better for smaller datasets, uses less memory, updates parameters more and has noisy gradients.","A larger batch size ( More then 8 ) is better for large datasets ( over an hour ) uses more memory, has smooth gradients and trains faster.","Usually a batch size of 8 is the best for most models with a dataset of around 30 minutes, anything less it is advisable that you use a smaller batch size and for a dataset of 1 hour or more you should increase the batch size."]},{"l":"Precision","p":["Exploding gradients","Faster then fp32","Finetune: Trained with a pretrain.","FP means floating point.","In RVC there are currently two precisions, FP16 and FP32. There is barely an audiable difference between the two so it is up to you on what precision setting you want to use.","Less VRAM needed","Lots of NaNs","Merge: Made by merging pretrains. (These are considered the worst)","More stable gradients","No NaNs","Pretrains are an integral part of making a model, they are basically models that have been trained with many different types of voices, genders, ages, languages, manor of speech and are much longer then normal models. The objective of pretrains is to reduce training time and increase the quality of your model.","Requires more VRAM","Scratch: Trained with no previous pretrain.","Slower then fp16","There are three types of pretrains:","Unable to train from scratch"]},{"i":"section","l":"‎"},{"i":"how-do-i-use-pretrains","l":"How do i use Pretrains?","p":["Go into the training tab and check the 'Custom Pretrained' box and use the drop down to select the pretrain's D and G file.","If you dont see a pretrain in the dropdown that means you need to download a pretrain, go into the 'Downloads' tab then go to 'Download Pretrained Models' then use the dropdown to select your sample rate and what pretrain you would like to download, then finally click download.","If you want to upload pretrains manually go into your Applio folder then go to rvc\\models\\pretraineds\\pretraineds_custom and place your D and G files there.","Asssuming you have the pretrain you want to use go into your mainline folder then go to assets\\pretrained_v2 and place you D and G files there.","Then in the 'Train' tab near the train button you can input the location of your pretrain, replace the ending so it's the name of the pretrain you put in pretrained_v2."]},{"i":"section-1","l":"‎"},{"i":"where-do-i-find-pretrains","l":"Where do i find Pretrains?","p":["-","32k","32k Download","40k","40k Downaload","48k","48k Download","DMR V1 by Razer","Here is a quick list of all publicly available pretrains:","IMA by Loren85","Itaila V1.0 by Ilaria","KLM 4.1 by SeoulStreamingStation","KLM 4.2 by SeoulStreamingStation","KLM BeatzForge by SeoulStreamingStation","Name","Nanashi Anime v1 by shiromiya","Nanashi V1.7 by shiromiya","Ov2 Super by SimplCup","Rigel by MUSTAR","RIN_E3 by MUSTAR","SingerPreTrain by Sztef","Snowie by MUSTAR","SnowieV3 X RIN_E3 by MUSTAR","SnowieV3.1 by MUSTAR","TITAN by blaise-tk","UKA by PlasmaTi","You can find all of the community made pretrains in the \"pretrain-models\" channel in AI HUB."]},{"i":"section-2","l":"‎"},{"i":"how-do-i-make-pretrain","l":"How do i make Pretrain?","p":["Creating a pretrain is pretty much the same as training a normal model but the dataset is bigger and longer.","There are two ways of making a pretrain the first being:","From scratch which means you don't use a pretrain when training this. To make a decent from scratch pretrain you are going to need at least 50 hours of low, mid and high quality speech with many different speakers. The second way being:","Finetuning which means you use a pretrain to train this pretrain. To make a good you are going to need at least 10 hours of high quality speech with many speakers.","The big pro of making a Finetune is that you can tailor it to anything, like you can tailor it to improve a certain language, improve accents, types of speech and more. It can even improve the graphs (like grads, g/total etc.) if trained properly."]},{"l":"Misc","p":["3060 (Ti)","3070 (Ti)","3080 (Ti)","3090 (Ti)","4060 (Ti) (8/16gb)","4070 (Ti)","4070 (Ti) (Super)","4080 (Super)","4090","A Tier:","A: There is no \"best pretrain\" it all depends on your needs and what you're ok with sacrificing to get those benefits.","A10, T4","A100 (80gb and 40gb)","A40","B Tier:","Batch size refers to the amount of samples used in one iteration. Batching is used to improve performence by using parallel processing instead of individual sample processing.","Because of this, TB is the most convenient tool for RVC users for perfecting a voice model.","C Tier:","Cons: Higher memory requirements, might lead to overtraining if the dataset is small.","Cons: Slower training due to reduced parallelism, potentially less stable gradient updates.","D Tier:","For RVC this means it can influence how well temporal dependencies are captured. A small batch size like 4 and below won't capture the variability in the audio, while a high batch size like 16 and above might smooth out these variations too much causing bad graphs.","H100","High Batch Size:","It's specially useful for determining when to stop training a voice model, since with it you can detect when the overtraining point begins.","L4","L40S","Low Batch Size:","P 100","Pros: Faster training due to increased parallelism, more stable gradient updates, potentially better convergence.","Pros: Less memory consumption, better generalization, less prone to overtraining.","Q: What is the best pretrain?","S Tier:","TensorBoard is a tool that allows you to visualize & measure the training of an AI model, through graphs & metrics.","This section contains miscellaneous information about pretrains.","To make a pretrain you are going to need a pretty good GPU, because without one it will take a very long time to train. Here is a GPU tier list for training pretrains:","V 100"]},{"i":"section-4","l":"‎"},{"i":"installing-opening","l":"Installing & Opening","p":["For RVC Disconnected users, ignore this, it opens up by itself when you start training."]},{"i":"section-5","l":"‎","p":["Download this file & move it inside RVC's folder. Ensure the file path doesn't contain spaces/special characters.","Training"]},{"i":"section-6","l":"‎","p":["Now execute it. It will open a console window & create some folders inside RVC.","If you get the Windows protected your PC issue, click More info& Run anyway.‎","Once it's done, your default browser should open with TensorBoard app.‎","If it doesn't, copy the address of the console at the bottom, and paste it in your browser. Said address will say \" https://localhost\" followed by some numbers.‎"]},{"i":"section-7","l":"‎"},{"l":"Usage Guide","p":["‎‎","‎","Activate Ignore outliers in chart scaling.","And the right one is to center the view.‎‎‎","Click the gear () in the top left corner & turn on Reload data. You can always manually refresh with the refresh symbol (\uD83D\uDD04) in the top right.","d/total shows how well the discriminator is able to differentiate between real and generated audio.","Each graph has three buttons in the corner:","First ensure auto-refresh is on, so the graphs update constantly.","FM shows how well the generator is able to make synthetic data that has similar features to the dataset.","Go to the SCALARS tab.‎‎","If it reaches a low point, let it run for longer until it's very clear it's OT.","If the graph is decreasing that indicates that the generator is able to make audio that has similar features to the dataset.","If the graph is decreasing that means the discriminator is becoming better at distinguishing between real and synthetic data which usually means that the generator is producing realistic audio.","If the graph is decreasing that shows that the generator is making audio with similar distribution of latent variables to real data.","If the graph is decreasing that shows that the generator is producing audio with similar spectral distribution to the dataset.","If you get the No dashboards are active issue, select SCALARS in the top right corner dropdown.","If you want you can just use the lowest mel point.","In the search bar, type \" g/total\". This will be the graph you'll monitor.‎‎‎‎","Is a mel spectrogram view of audio from your dataset.‎","Is a mel spectrogram view of audio that the generator created in attempt to make it match mel_org.‎","KL makes the generator create similar distribution of latest variables to real data. The KL loss ensures that the generator is not just memorizing real data but it's learning to capture the underlying patterns in the data.","Left one is for going fullscreen.","Middle one to disable Y axis, for a fuller view.","Now let the training go for some time.","Open TB & begin training in RVC.","Select your model in the Runs section below. The models you tick will show in the graphs. (untick /eval if you want)‎‎‎","Set Smoothing to 0.987.","The mel spectrogram loss compares both the real and synthetic mel spectrograms. This loss encourages the generator to produce audio that sounds similar to the dataset.","Then over your mouse over the local minimas and take note of the step counts. Find all of the epochs connected to those step counts and then use them all to find the one that sounds best to you.","Then zoom out & lower the smoothening to 0. Then look for low points named local minima.","There will be various low points, one after the other, so don't get too anxious if it's OT or not. You can always use a previous checkpoint either way.","To zoom in & out the graphs, press the ALT key + mouse wheel. Remember to center the view after moving around, and after the graph updates.","When you detect OT go into the search bar and look for mel,","While looking through the Tensor Board you may come across slice/mel_gen and slice/mel_org.","you can think of this as clarity / fidelity.","You can think of this as how well it can replicate the speakers style.","you can think of this as how well the model can match timbral, spetial, temporal characteristics.","You'll detect OT(overtraining) when the graph hits the lowest point, then stay flat/ rising indefinitely.‎ Example of OT:"]}],[{"l":"Inference Settings","p":["Last update: Feb 25, 2024"]},{"i":"section","l":"‎","p":["When doing inference in RVC, you'll come across to quite a few options that you can tweak, that influence the conversion process.","Configuring them accordingly can improve the output quality by a lot, as well as reduce artifacting, so we highly recommend learning them.","There are some of them that are either obsolete or not important. So if a setting is not explained here, you can ignore it."]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎"},{"i":"also-known-as-pitch-it-adjusts-the-tone-of-voice","l":"Also known as Pitch, it adjusts the tone of voice.","p":["Negative values lower the tone (e.g -2).","Positive ones raise it (e.g 5).","You can use decimals if necessary (e.g -4.3).","You'll usually have to modify this for the pitch to sound perfect. Modify it until it matches the tone of the model."]},{"i":"section-4","l":"‎"},{"i":"also-known-as-index-rate-it-determines-the-level-of-influence-of-model-s-index-file","l":"Also known as Index Rate, it determines the level of influence of model's .INDEX file:","p":["Higher values will apply more of the .INDEX's characteristics.","Lowering it can reduce artifacting.","Remember, if the dataset had other sounds like background noise, there will be noise in the .INDEX too."]},{"i":"section-5","l":"‎"},{"i":"they-re-the-algorithms-for-converting-the-vocals","l":"They're the algorithms for converting the vocals.","p":["*Mangio-Crepe*","*RMVPE*","As the majority of them are obsolete, we'll focus on the 2 best ones: RMVPE and Mangio-Crepe.","Better with harmonic-rich voices / fuller voices","Better with soft, whspery or voices with feminine timbres","Decent quality","Each one works in its own way, and has its pros & cons.","Fast","If you have really clean audio use this over RMVPE","Inference only. Allows you to set the maximum/minimum frequency, to reduce small distortions. Recommended for advanced users.","It determines the time it takes the voice to hit a note","It's crepe, but you can adjust its hop_length","Lowering it too much might lead to voice cracks so it's recommended to not lower it below 64.","Should be your go-to algorithm, due to its convenience","Some forks include RMVPE_GPU& RMVPE+. Same algorithm, but with a modification:","The lower the value, the more detailed results you'll get, but will take longer to process","They also work the same for training models.","Training only. Uses more GPU power, making you train faster.","Useful when the audio/model performs drastic note shifts","Usually sounds a little harsh"]},{"i":"section-9","l":"‎"},{"i":"also-known-as-protection-they-suppress-breath-sounds","l":"Also known as Protection, they suppress breath sounds:","p":["Decrease the value to remove more breath sounds, as they cause some artifacting.","A value of 0.5 disables this feature.‎","Be careful, lowering it too much will make it voice sound \"inhumane\" & suppress part of the words."]},{"i":"section-10","l":"‎"},{"i":"also-known-as-remix-mix-rate-controls-the-loudness-of-the-output","l":"Also known as Remix Mix Rate, controls the loudness of the output:","p":["The closer to 0, the more the output will match the loudness of the input audio.","The closer to 1, the more it will match the loudness of the dataset the model was trained on.","Basically, leave it at 0 if you want the audio to try to keep its original volume."]},{"i":"section-11","l":"‎"},{"i":"gives-a-faster-inference-more-consistent-output-volume","l":"Gives a faster inference & more consistent output volume:","p":["In RVC sometimes there's an error where the volume of the output lowers in some parts.","To prevent this, Split Audio divides the audio & infers them one by one. Then unites them at the end.","Doing it this way is faster too."]},{"i":"section-12","l":"‎"}],[{"l":"TTS Tools","p":["Last update: Dec 12, 2024"]},{"l":"Introduction","p":["TTS is an abbreviation of Text To Speech, an AI that converts any given text into vocal speech.","The ones listed here offer a decent variety of features & options, such as model training, fine-tuning, 0 shot training, or being mixed with RVC.","Here's an index of the best TTS tools out there:‎"]},{"i":"elevenlabs11labs","l":"ElevenLabs/11Labs","p":["ElevenLabs is a freemium service that offers TTS, training TTS models & translating videos from different languages.","‎"]},{"l":"Fish Speech","p":["Fish speech is a 0shot multilingual TTS model created by Fish Audio.","This is one of the best 0shot TTS as of now, it rarely hallucinates.","It can be used either locally or on the cloud.","Offical github repo","Offical site","HuggingFace Space"]},{"l":"F5 TTS","p":["F5 is the best 0shot TTS model.","F5 gives fairly high quality outputs that rarely hallucinate.","But it is limited with issue like: Reading to fast = you are using a reference audio that is more the six seconds long or 100 characters. Hallucinates on low voices.","It can be used either locally or on the cloud.","Offical github repo","HuggingFace Space"]},{"i":"section","l":"‎"},{"l":"Edge TTS","p":["\uD83D\uDCD2 Google Colab","\uD83E\uDD17 Hugging Face","Applio Colab","Download the browser.","Ilaria RVC","In the TTS input the text you want & click Generate. Stop recording when the voice is done.","It can only be used online via their API, through their web browser, a HF/Colab space or mixed with RVC.","Local Applio‎","Open Microsoft Edge & drag the .html to it.","Open your Notepad & paste the following code:","Rename it to “Microsoft Edge TTS.html”","Save it as “Microsoft Edge TTS.txt”","These being mixed with RVC means it generates the speech & runs the output through RVC, applying the voice model.","This is Microsoft Edge TTS, which is good quality, multilingual & works great on long sentences.","Use Audacity to record the audio. Set the recording mode to loopback to record the internal audio (Realtek driver might be needed).","You can then select Voice Options in the toolbar & change the speed to a faster/slower speech."]},{"i":"section-2","l":"‎"},{"i":"section-3","l":"‎"},{"l":"XTTS2","p":["Built on \uD83D\uDC22 Tortoise TTS & developed by Coqui AI, which has been discontinued unfortunately.","Has important model changes that make cross-language 0 Shot voice cloning& multilingual speech generation super easy.","You need less training data. Just least a 2 minute audio.","Can use it either online or locally:","Official XTTS 2 Guide","XTTS 2 UI Fork","Inference 0 Shot Training UI Colab(Run it & click the Public Link)","Training & Inference UI Colab","Inference 0 Shot Training HF Space"]},{"i":"section-4","l":"‎"},{"l":"OpenVoice","p":["Has Versatile Instant Voice Cloning (aka 0 Shot Training)","Contains cross-lingual & flexible voice style control","Available both locally & online:","Official GitHub repo","Inference GUI Colab","Official Demo Part 1 Colab","Official Demo Part 2 Colab","Official HF Space"]},{"i":"section-5","l":"‎"},{"l":"MeloTTS","p":["MeloTTS is a high-quality multilingual TTS library, made by MyShell.ai","Includes almost real-time inference.","It can be used both locally and online:","Official GitHub Repo","UI Colab","NO UI Colab","HF Space"]},{"i":"section-6","l":"‎"},{"l":"GPT-SoVITS","p":["GPT-SoVITS has cross language inference, but there could be some noises.","It's very good with Chinese, but also with English.","Most parts are in japanese & not deeply tested. Expect some instability.","Can be used both locally & online:","Official GitHub Repo","Colab Space(with fine-tuning, inference & UI)"]},{"i":"section-7","l":"‎"}],[{"l":"GPT-SoVITS","p":["Last update: Mar 8, 2024"]},{"i":"section","l":"‎","p":["See original guide","GPT-SoVITS is an open-source repository focused on TTS & cross-language inference, with a Colab port coming soon. Credits to RVC-Boss.","Currently it only supports Chinese, English & Japanese. More languages are coming soon.","You'll require great specs & a NVIDIA GPU with >=6G VRAM to run it smoothly. Otherwise, use the Colab.","This guide is a translation of the original one with a few tweaks, made by Delik. [Discord: @delik - Wechat: Dellikk ]‎"]},{"i":"section-1","l":"‎"},{"i":"section-2","l":"‎"},{"l":"1. Download prezip","p":["Download the prezip of the latest version here."]},{"i":"section-3","l":"‎"},{"l":"2. Extract","p":["Unzip the folder. It's advisable to use 7-ZIP to do so."]},{"i":"section-4","l":"‎"},{"l":"3. Launch","p":["Open the folder & run go-web.bat to open WebUI."]},{"i":"section-5","l":"‎"},{"i":"section-6","l":"‎"},{"l":"1. Prepare dataset","p":["The dataset should be between 1 - 30 minutes. But you must prioritize quality over quantity.","For the best results, ensure the audio is properly cleaned, free of undesired noises & distortions.","GPT-So-VITS is made for TTS only, so it's also best to remove any singing/muffly voice parts."]},{"i":"section-7","l":"‎"},{"l":"2. Audio Slicer","p":["Copy the path file of your dataset & paste it in the Audio slicer input bar.","Create a new folder somewhere. Copy its path folder & paste in Audio slicer output. This is where the outputs are getting stored.","Adjust the parameters if needed.","Finally, click Start Audio Slicer to complete this step."]},{"i":"section-8","l":"‎"},{"l":"3. ASR","p":["The Input folder path should be the same as Audio slicer output. Jst copy the path & paste it inside the bar.","If the dataset is in English/Japanese, use Faster-Whisper large v3.","If it's in Chinese, use 达摩ASR.","Then click Start batch ASR.","If you run GPT-SoVITS for the first time, you might need to wait for a few minutes for it to download the ASR model you select.","Finally, locate the .list file & copy the path. It will be in output/asr_opt, if you didn't change the folder for Output folder path."]},{"i":"section-9","l":"‎"},{"i":"4-text-labelling-optional","l":"4. Text Labelling (optional)","p":["Paste the .list file path into .list annotation file path.","Tick Open labelling WebUI to open Text Labelling WebUI. A new tab will open.","Listen to each clip & edit the text if it's not transcribed properly.","The functions are self-explanatory. Use next index& previous index to check the next/previous page.","If you make changes, remember to save file& submit text."]},{"i":"section-10","l":"‎"},{"l":"5. Formatting","p":["Click 1-GPT-SOVITS-TTS& 1A-Dataset formatting to enter the training page.","Input the name of your model in Experiment/model name, & the .list file path to Text labelling file.","Scroll down to the end & start One-click formatting to begin formatting."]},{"i":"section-11","l":"‎"},{"l":"6. SoVITS Training","p":["Scroll up then click 1B-Fine-tuned training.‎‎"]},{"i":"section-12","l":"‎","p":["2| Use 1 if the GPU has 6GB VRAM.","8","<= 0.4","4","After that, click Start SoVITS training"]},{"i":"section-13","l":"‎"},{"l":"7. GPT Training","p":["2 (1 if your gpu has 6G vram)","10","5","disabled (explained later)","‎","After that, click Start GPT training"]},{"i":"section-14","l":"‎"},{"i":"dpo-training-optional","l":"DPO training (optional)","p":["DPO training greatly improves the performance (not audio quality) & stability of the model.","It can infer more text at once without slicing & it's less prone to errors (like repeating/skipping words) when inferring.","A GPU with 12G VRAM or more.","A very high quality dataset (you need to do text labelling) to enable this.","Using a batch size of 1. Keep the other settings same as above.","Otherwise, this will worsen the model."]},{"i":"section-15","l":"‎","p":["Go to the 1C-inference tab.","Press refreshing model paths& select your models from the dropdowns respectively.","Tick Open TTS inference WEBUI.","Upload a clip for reference audio ( must be 3-10 seconds). Then fill-in the Text for reference audio, which is what does the character say in the audio. Choose the language on the right.","The reference audio is very important as it determines the speed & emotion of the output. Try different ones to polish your output.","You can reopen the text proofreading tool to download the reference audio, and copy & paste the text for reference audio.","Hover above the \"duration\" to adjust the length of the reference audio, & hover above \"it\" to delete the current reference audio.","No reference text mode exists, but it's not advisable to use it. It affects the quality a lot.‎","Fill the Inference text& set the Inference language, then click Start inference.","If the text is too long choose the options in How to slice the sentence.","If you did not get your desired output, you can infer it again or change reference audio and/or adjust GPT parameters."]},{"i":"section-16","l":"‎"}],[{"l":"Glossary","p":["‎","A optimizer is an algorithm used to minimize the loss function during the training of neural networks. It helps adjust the model's weights and biases.","A technology developed by NVIDIA, that uses the power of graphics cards to perform calculations that require great processing power.","Any software or application that's stored, managed, and available through the provider's virtual servers, and is accessed through a web browser.","Audio formats that compress(lose) the original quality. They're built to be space-efficient.","Audio formats that don't compress(lose) the original quality.‎","Basically the speed at which RVC/UVR will work will depend on how good your GPU is.","Basically, higher bit depths represent more accurately the loudness of an audio.","Both formats give the same results & don't have an audible difference. Converting a lossy audio to a lossless one won't restore the lost quality.","Common lossy formats are MP3, OGG, OPUS, M4A, etc.","CUDA is downloaded automatically as a part of the NVIDIA driver.","Different from making a dataset & doing the long training process, based on lots of criteria such as epochs.","Doesn't do any kind of compression. It's purely the original data.","Doing inference on an AI model without explicitly training on it.","Example: G_70.pth and D_70.pth","Example: Tyler_e60_s120.pth‎","FLAC:","For basic audio editing, we recommend Audacity.","For example, in RVC is when a voice model is used to transform an audio, to make it sound like the model.","For example, in TTS you do inference by cloning a voice with an audio, a data it hasn't seen before.","For professional mixing, FL Studio.","For this, using the GPU is more convenient as it's faster. Though normally you can still use CPU, which takes longer.","Further improving an AI model, training it with a another dataset.","G and D:","Google Colaboratory is a product of Google that allows anybody to write & execute arbitrary python code through websites.","Gradio is an open-source Python packag that makes it easy for developers to create user-friendly web interfaces for machine learning models and other applications, such as RVC.","Higher bitrate equals a higher quality.","In AI training, is used for quick parallel independent computations, which increases the speed substantially.","In RVC, these are files of a model that generate over the course of training, that can be very useful.‎","In some cases you can do it on GPU, some in CPU.","In the context of AI, it's using an AI model to complete any task.","In the field of AI, is the process where an AI model is fed with its dataset & learns from it.","In the field of digital audio, it defines the dynamic range of each sample.","It deploys the program on a Local URL, which is the one running locally on the machine, and a Public Share Link, which is a tunnel that exposes the Local URL. The Public Share Link is used, for example, in Google Colabs, powered by their Share API. Sometimes, the Share API goes down, you can check its status here.","It is a shorter way to say optimizer.","It refers to a computer's specifications. Hardware like GPU, CPU, RAM, etc.","It stands for Digital Audio Workstation, and it's any software used for making and mixing music.","It stands for Graphics Processing Unit. It's designed to rapidly manipulate and alter memory to accelerate creation of images.","It's a copy of a main GitHub project. It aims to make a different version of the project with improvements, changes & new features.","It's especially useful for AI tools, such as RVC and UVR, which greatly optimizes the process.","It's faster but with less quality, and you won't be able to save the model.","It's free version is slower & with a usage time of their GPUs of around 3 hours a day. Once you exhaust it, you'll have to wait 12 - 24 hours.","It's more accurate to describe it as an uncompressed format","It's recommended over WAV since it's space-efficient.‎","It's used in Google Colabs to expose the Local URL so that users on Cloud can access the program.","Its algorithm compresses the data without losing quality.","Last update: June 15, 2024","Learn how to bypass their limitations here.","Localtunnel is a tunnel made to expose a local url (like http://localhost:3000).","Named G_ and D_, followed by the step number & .pth.","Running locally is a process that involves running apps in your own machine, using its resources.","So by getting rid of some data (in this case, quality), they achieve a smaller file size.","The amount of data processed per certain unit of time, usually in kilobits per second (KBPS).","The main ones are WAV & FLAC:‎","The opposite of cloud-based.","The opposite of local running.","The performance of the hardware of a computer directly correlates to the performance of all its software.","The rate at which they're saved is determined by the save frequency value (or save rate or similar names). For newbies, it's recommended use a value of 15.‎","Therefore it has a much bigger file size.","These allow you to resume training, if G and D's numbers match.","These are actual models.","They are divided by two types:‎","They're organized with this format: modelname_epoch_step.pth","They're recommended for RVC, as the more quality an audio has, the more accurate results they'll offer.‎","This determines the difference between the quietest & loudest sound.","Vocal lines that contribute to the sound of the lead vocals in a song.","WAV:","Weights:","You can think of it as video resolution (240, 480, 1080, etc.)."]}],[{"l":"Model Maker Role","p":["Last update: October 20, 2024"]},{"i":"section","l":"‎"},{"i":"section-1","l":"‎","p":["‎‎","A bad model:","A Hugging Face or Weights.gg account.","An audio sample of it talking/singing.","At least 1 raw audio sample of the model WITH NO MUSIC.","Click the Submit Model button.","Concerns over copyright.","Don't add reverb, equalize, or alter the demo in any way, as it won't be a faithful representation of the model. It must be the raw, unmodified output from the inference.","Don't include ANY music in the audio demo, even if it's not copyrighted. This is due to:","General information about its training process.","General information about the model.","Harvest, Dio, Crepe-Tiny, PM, etc. are obsolete.","Has a muffled sound.","Has artifacting.","Has noise.","Has slurred speech.","However once you get model maker you will be able to post robotic, sound effect or drum models.","In many cases, the music can \"hide\" the flaws of the voice model, making it harder to judge its quality.","Is incapable of hitting certain notes.","Is unable of pronouncing words correctly in its intended language.","Its download link from Hugging Face or Weights.","Its name.","Model's .INDEX file.","Model's .PTH file.","Once your model is ready, head over to the #model-maker-role channel.","Only Mangio-Crepe& RMVPE are allowed. Learn about them here","Optional. Add more context about the model if you want.","Robotic, sound effect and drum models will also be rejected, because with these types of voices it is difficult to determine if you know how to clean a dataset properly.","Sounds inaccurate to the source.","Sounds scratchy/screechy.","The .pth contains the actual model and pitch data.","The .ZIP file must contain both the correct.INDEX& .PTH file.","The added index contains the voice's accent and speech manor.","The correct .index is the one named added_.","The correct .pth is the one that has your model's name, for example: TylerSwift_e60_s120.pth","The extraction method you used.","The technology used for its training.","Total epochs amount.","Trimming silences at the beginning/end of the audio demo is allowed.","You can attach more samples when you repost the model to #voice-models."]},{"i":"section-9","l":"‎"},{"i":"step-4-send-submission","l":"Step 4: Send submission.","p":["Once you are done filling the information it will send your model to get QCed","‎‎","Now, wait for a QC(quality checker) to verify your model. You'll be notified once it has been reviewed.","If you made a mistake in your submission or you want to change something you can cancel your submission by clicking on the cancel button that is attatched to the message you get when you send a submission.","‎","If your model gets approved, the bot will notify you with a message like this:","You can then repost the model (& future models) to the #voice-models forum."]},{"i":"section-10","l":"‎"}],[{"l":"Illusion Diffusion","p":["Last update: Mar 9, 2024"]},{"i":"section","l":"‎"},{"i":"section-1","l":"‎"},{"l":"1. Upload","p":["Go to the Illusion Diffusion Hugging Face Space.","Click on Input Illusion.","Upload the image you wish to blend.‎"]},{"l":"2. Illusion Strength","p":["Modify the \"Illusion Strength\" slider.","Higher values will make the picture more visible.","Lower ones will hide it more.‎"]},{"l":"3. Prompt","p":["Describe the characteristics of the output.","These can be environments (medieval castle - flowery meadow), traits (high quality - a specific image style), etc.‎"]},{"i":"4-negative-prompt-optional","l":"4. Negative Prompt (optional)","p":["Specify what the AI should NOT do when creating the image (e.g., low quality, specific styles to avoid, etc.).‎"]},{"l":"5. Run","p":["Press Run to begin processing.","Be patient; there might be a queue.","If you encounter an error, try clicking again until it works."]},{"i":"section-2","l":"‎"}],[{"l":"Contributions","p":["Last update: Dec 12, 2024"]},{"l":"Contributions","p":["We'll appreciate any feedback, big or small. If you wish to contact anyone who worked on this you can find them in AI Hub.","Leave suggestions in the #suggestions channel.","To report issues use #help-forum. You can also send issues to our GitHub repo.","If you would like to add to this doc please make a pull request in the GitHub repo."]},{"i":"section","l":"‎"}],[{"l":"License"},{"i":"license-cc-by-nc-sa-40","l":"License CC BY-NC-SA 4.0","p":["This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License."]},{"i":"you-are-free-to","l":"You are free to:","p":["Share: Copy and redistribute the material in any medium or format.","Adapt: Remix, transform, and build upon the material.","The licensor cannot revoke these freedoms as long as you follow the license terms."]},{"i":"under-the-following-terms","l":"Under the following terms:","p":["Attribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.","NonCommercial: You may not use the material for commercial purposes.","ShareAlike: If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."]},{"i":"you-are-not-required-to-comply-with-the-license-for-elements-of-the-material-in-the-public-domain-or-where-your-use-is-permitted-by-an-applicable-exception-or-limitation","l":"You are not required to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation."},{"i":"no-warranties-are-given-the-license-may-not-give-you-all-the-permissions-necessary-for-your-intended-use-for-example-other-rights-such-as-publicity-privacy-or-moral-rights-may-limit-how-you-use-the-material","l":"No warranties are given. The license may not give you all the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.","p":["Read the full text of the license."]}]]